{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f786336",
   "metadata": {},
   "source": [
    "# Demos for Talk Working with Large Models in ONNX IR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "1985be7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare environment\n",
    "\n",
    "# %pip install --upgrade onnxscript onnx-ir onnx-safetensors model-explorer-onnx onnxruntime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bedf1490",
   "metadata": {},
   "source": [
    "## Demo 1: Safetensors in ONNX\n",
    "\n",
    "**Q1: Is there a way to use the safetensors format as an external data format for ONNX?**\n",
    "\n",
    "**A1:** Yes. The data is contiguous, row-major, and little-endian (same as ONNX). Data offset can be found by parsing the json header.\n",
    "\n",
    "<img src=\"resources/safetensors-format.svg\" width=\"500\"/>\n",
    "\n",
    "Image source: https://huggingface.co/docs/safetensors/en/index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9337aa3c",
   "metadata": {},
   "source": [
    "**Q2: How do we do it efficiently?**\n",
    "\n",
    "**A2:** Use onnx_ir to replace the tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "a54e0bdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<\n",
      "    ir_version=10,\n",
      "    opset_imports={'': 21},\n",
      "    producer_name='onnx-safetensors-example',\n",
      "    producer_version=None,\n",
      "    domain=None,\n",
      "    model_version=None,\n",
      ">\n",
      "graph(\n",
      "    name=SimpleGraph,\n",
      "    inputs=(\n",
      "        %\"input\"<FLOAT,[1,3]>\n",
      "    ),\n",
      "    outputs=(\n",
      "        %\"output\"<FLOAT,[1,3]>\n",
      "    ),\n",
      "    initializers=(\n",
      "        %\"weights\"<FLOAT,[3]>{TensorProtoTensor<FLOAT,[3]>(array([1., 2., 3.], dtype=float32), name='weights')}\n",
      "    ),\n",
      ") {\n",
      "    0 |  # :anonymous_node:130470374283680\n",
      "         %\"output\"<FLOAT,[1,3]> ⬅️ ::Add(%\"input\", %\"weights\"{[1.0, 2.0, 3.0]})\n",
      "    return %\"output\"<FLOAT,[1,3]>\n",
      "}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import onnx_ir as ir\n",
    "\n",
    "model = ir.load(\"resources/model.textproto\")\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04626ef6",
   "metadata": {},
   "source": [
    "### Loading tensors from a safetensors file into an ONNX model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cecd56d8",
   "metadata": {},
   "source": [
    "Use `load_file_as_external_data` to load safetensors as external data and replace weights in the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "72d642a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<\n",
      "   ir_version: 10,\n",
      "   opset_import: [\"\" : 21],\n",
      "   producer_name: \"onnx-safetensors-example\"\n",
      ">\n",
      "SimpleGraph (float[1,3] input) => (float[1,3] output) \n",
      "   <float[3] weights = [\"location\": \"resources/weights.safetensors\", \"offset\": \"72\", \"length\": \"12\"], float[3] weights>\n",
      "{\n",
      "   output = Add (input, weights)\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "model_with_external_data = onnx_safetensors.load_file_as_external_data(\n",
    "    model,\n",
    "    \"resources/weights.safetensors\",  # weights containing [4, 5, 6]\n",
    ")\n",
    "\n",
    "print(onnx.printer.to_text(ir.to_proto(model_with_external_data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7ff107f",
   "metadata": {},
   "source": [
    "### Using safetensors as external data for ONNX\n",
    "\n",
    "We can similarly save external data file from an ONNX model to safetensors. By storing the tensor dtype in ONNX file, we can even use types safetensors doesn't yet support, like INT4.\n",
    "\n",
    "You can read more at https://github.com/justinchuby/onnx-safetensors/blob/main/examples/tutorial.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eb20a2e",
   "metadata": {},
   "source": [
    "### Inference with ONNX Runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "39c668a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.0, 2.0, 3.0]] + [4, 5, 6] = [array([[5., 7., 9.]], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "import onnxruntime as ort\n",
    "\n",
    "ir.save(model_with_external_data, \"model_with_external_data.onnx\")\n",
    "session = ort.InferenceSession(\"model_with_external_data.onnx\")\n",
    "output = session.run(None, {\"input\": np.array([[1.0, 2.0, 3.0]], dtype=np.float32)})\n",
    "print(\"[[1.0, 2.0, 3.0]] + [4, 5, 6] =\", output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c03361ce",
   "metadata": {},
   "source": [
    "## Demo 2: Fusion in onnxscript for ONNX Runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "160e2559",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b358607f",
   "metadata": {},
   "source": [
    "## Demo 3: Putting it together\n",
    "\n",
    "1. Build a model with the tape module.\n",
    "2. Replace some initializers\n",
    "3. Build a pass to modify the model (merge QKV weights)\n",
    "4. Use rewriter to do the same thing\n",
    "5. Show it on model explorer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07724b5a",
   "metadata": {},
   "source": [
    "### 1. Build a model with the tape module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "48ee05ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def build_model() -> ir.Model:\n",
    "    R\"\"\"\n",
    "      Input Embeddings  [batch_size, seq_len, hidden_size]\n",
    "          |\n",
    "          V\n",
    "      [Linear Layer: W_QKV]  <-- Single merged weight matrix  [hidden_size, 3 * hidden_size]\n",
    "          |\n",
    "          V\n",
    "      [QKV Tensor]  [batch_size, seq_len, 3 * hidden_size]\n",
    "       /    |    \\\n",
    "      /     |     \\\n",
    "     V      V      V\n",
    "    Query  Key   Value    <-- Q, K, V are now derived by splitting the QKV Tensor\n",
    "    # Each of these has shape [batch_size, seq_len, hidden_size]\n",
    "        \\   |   /\n",
    "         \\  |  /\n",
    "     [Scaled Dot-Product Attention]\n",
    "                |\n",
    "                V\n",
    "        [Attention Output]  [batch_size, seq_len, hidden_size]\n",
    "    \"\"\"\n",
    "    batch_size = 2\n",
    "    seq_len = 3\n",
    "    hidden_size = 16\n",
    "\n",
    "    # Initializer the Tape. It is simply a recorder of operations and initializers.\n",
    "    tape = ir.tape.Tape()\n",
    "\n",
    "    # Create initializers\n",
    "    q_weight = tape.initializer(\n",
    "        ir.tensor(np.random.rand(hidden_size, hidden_size).astype(np.float32)),\n",
    "        name=\"q_weight\",\n",
    "    )\n",
    "    k_weight = tape.initializer(\n",
    "        ir.tensor(np.random.rand(hidden_size, hidden_size).astype(np.float32)),\n",
    "        name=\"k_weight\",\n",
    "    )\n",
    "    v_weight = tape.initializer(\n",
    "        ir.tensor(np.random.rand(hidden_size, hidden_size).astype(np.float32)),\n",
    "        name=\"v_weight\",\n",
    "    )\n",
    "\n",
    "    # Create graph inputs\n",
    "    input = ir.Value(\n",
    "        name=\"input\",\n",
    "        type=ir.TensorType(ir.DataType.FLOAT),\n",
    "        shape=ir.Shape([batch_size, seq_len, hidden_size]),\n",
    "    )\n",
    "\n",
    "    query = tape.op(\"MatMul\", inputs=[input, q_weight])\n",
    "    key = tape.op(\"MatMul\", inputs=[input, k_weight])\n",
    "    value = tape.op(\"MatMul\", inputs=[input, v_weight])\n",
    "    attention_output = tape.op(\"Attention\", inputs=[query, key, value], attributes={\"q_num_heads\": 1, \"kv_num_heads\": 1})\n",
    "    attention_output.shape = ir.Shape([batch_size, seq_len, hidden_size])\n",
    "    attention_output.type = ir.TensorType(ir.DataType.FLOAT)\n",
    "\n",
    "    model = ir.Model(\n",
    "        graph=ir.Graph(\n",
    "            inputs=[input],\n",
    "            outputs=[attention_output],\n",
    "            nodes=tape.nodes,\n",
    "            initializers=tape.initializers,\n",
    "            opset_imports={\"\": 23},\n",
    "            name=\"main_graph\",\n",
    "        ),\n",
    "        ir_version=10,\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9da7a8dd",
   "metadata": {},
   "source": [
    "### 2. Replace some initializers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "053b163c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor<FLOAT,[16,16]>(array([[0.22905988, 0.3874115 , 0.91336787, 0.8247674 , 0.452753  , 0.08561618, 0.46014684, 0.10517686, 0.5707154 , 0.095474  , 0.02347428, 0.66710854, 0.02686424, 0.8105638 , 0.74326855, 0.8649134 ], [0.76789117, 0.97105217, 0.33251286, 0.16966474, 0.20250483, 0.8332452 , 0.37601286, 0.05630271, 0.5907952 , 0.11968726, 0.72545016, 0.12145851, 0.8399156 , 0.22498219, 0.60112005, 0.13663547], [0.19208397, 0.6625066 , 0.15974769, 0.6935774 , 0.00278074, 0.78849417, 0.56787276, 0.10148514, 0.32920736, 0.420652  , 0.13469286, 0.6388274 , 0.8723755 , 0.36908534, 0.13310821, 0.44636413], [0.31870523, 0.6175749 , 0.65616655, 0.5067202 , 0.5703408 , 0.2134051 , 0.13493541, 0.03369081, 0.07105451, 0.77901644, 0.00526058, 0.5322647 , 0.9586473 , 0.78136784, 0.4255794 , 0.8778006 ], [0.33890134, 0.8532674 , 0.43055433, 0.30667785, 0.12316153, 0.08410449, 0.4904734 , 0.36312613, 0.39875546, 0.9731011 , 0.8408935 , 0.75079614, 0.00918715, 0.97220236, 0.12703897, 0.01817925], [0.88223505, 0.89514434, 0.2560879 , 0.6718954 , 0.1637986 , 0.4375434 , 0.7708835 , 0.16486964, 0.7182939 , 0.7390612 , 0.90782106, 0.43096703, 0.01773081, 0.7453804 , 0.9845632 , 0.6551027 ], [0.7417657 , 0.10309959, 0.61287034, 0.48833516, 0.39307356, 0.5549656 , 0.31527936, 0.8773527 , 0.97184867, 0.880633  , 0.9277687 , 0.9243637 , 0.3747983 , 0.5128471 , 0.80484146, 0.8549614 ], [0.29388154, 0.80959594, 0.5729337 , 0.1440276 , 0.92267805, 0.63729703, 0.5117082 , 0.66175556, 0.9795392 , 0.36675116, 0.69219166, 0.39178446, 0.45390457, 0.69540495, 0.22331278, 0.36347637], [0.23680907, 0.8043114 , 0.5251351 , 0.8482676 , 0.26719168, 0.8238152 , 0.03067565, 0.8896691 , 0.11418314, 0.6127567 , 0.33319584, 0.37338865, 0.76951385, 0.3021151 , 0.23585528, 0.84020996], [0.46210092, 0.5800992 , 0.5181223 , 0.796209  , 0.59026533, 0.5809335 , 0.07806269, 0.18892622, 0.21935809, 0.8921899 , 0.59216356, 0.48403665, 0.76315165, 0.9914958 , 0.7243953 , 0.3272829 ], [0.08527025, 0.34709653, 0.17842007, 0.8810797 , 0.9750841 , 0.02566556, 0.0389467 , 0.72882783, 0.90697277, 0.62367153, 0.4224627 , 0.08161724, 0.9699071 , 0.48433965, 0.01631566, 0.85255516], [0.48090062, 0.01798997, 0.8053947 , 0.6264709 , 0.598662  , 0.7935025 , 0.7000048 , 0.3191885 , 0.26733574, 0.04509304, 0.13110337, 0.15348983, 0.7895793 , 0.25384986, 0.7027736 , 0.3028748 ], [0.73693895, 0.25028524, 0.02453393, 0.6475367 , 0.6899433 , 0.08311953, 0.7329914 , 0.5856983 , 0.3209572 , 0.2641604 , 0.5397088 , 0.7393048 , 0.27888575, 0.40811333, 0.803493  , 0.20823482], [0.65732175, 0.292816  , 0.9718875 , 0.859372  , 0.24258804, 0.6662064 , 0.44985855, 0.9190933 , 0.34392044, 0.7030315 , 0.5941884 , 0.13733692, 0.9106513 , 0.4570229 , 0.41044247, 0.08341227], [0.8274172 , 0.18490465, 0.55464107, 0.81002235, 0.4320066 , 0.5396061 , 0.39294216, 0.2903392 , 0.99920416, 0.9848568 , 0.14259003, 0.41854253, 0.4016204 , 0.71896666, 0.95557547, 0.6112448 ], [0.06048891, 0.7504189 , 0.4593903 , 0.88269347, 0.30164337, 0.08943203, 0.70710766, 0.03908281, 0.5733952 , 0.50166726, 0.23872682, 0.86796737, 0.40044263, 0.61326516, 0.3075837 , 0.6153218 ]], dtype=float32), name=None)\n",
      "\n",
      "Min: 0.0027807410806417465, Max: 0.999204158782959, NaN count: 0, Inf count: 0\n",
      "Sparsity (abs<1e-06): 0.00\n",
      "Histogram:\n",
      "       8 ┼╭╮   ╭╮\n",
      "       7 ┤││   ││                                                        ╭╮\n",
      "       6 ┤││   ││  ╭╮                        ╭╮                          ││    ╭╮     ╭╮\n",
      "       5 ┤││   ││  ││              ╭╮ ╭╮╭╮   ││       ╭╮╭╮   ╭╮ ╭╮  ╭╮   ││    ││     ││\n",
      "       4 ┤│╰╮  ││ ╭╯│      ╭╮   ╭──╯│ ││││╭─╮││╭╮╭╮   │││╰─╮ ││ ││ ╭╯│╭╮╭╯│ ╭─╮││ ╭╮  │╰╮\n",
      "       3 ┼╯ │  ││╭╯ │╭╮╭╮╭─╯│╭╮ │   │ │││╰╯ │││││││   │╰╯  │ │╰╮│╰─╯ ││││ │ │ ╰╯╰─╯│  │ │\n",
      "       2 ┤  │╭╮│╰╯  ╰╯╰╯││  ╰╯╰╮│   ╰─╯││   ╰╯││││╰╮╭─╯    ╰─╯ ││    ╰╯╰╯ ╰─╯      │ ╭╯ ╰\n",
      "       1 ┤  ╰╯╰╯        ╰╯     ╰╯      ╰╯     ││╰╯ ╰╯          ││                  ╰╮│\n",
      "       0 ┤                                    ╰╯               ╰╯                   ╰╯\n",
      "     0.0028  0.0900  0.1896  0.2768  0.3764  0.4636  0.5633  0.6505  0.7501  0.8373  0.9369\n"
     ]
    }
   ],
   "source": [
    "model = build_model()\n",
    "model.graph.initializers[\"q_weight\"].const_value.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "5c433bec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor<FLOAT,[16,16]>(array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=float32), name='q_weight')\n",
      "\n",
      "Min: 0.0, Max: 0.0, NaN count: 0, Inf count: 0\n",
      "Sparsity (abs<1e-06): 1.00\n",
      "Histogram:\n",
      "     256 ┼                                       ╭╮\n",
      "     224 ┤                                       ││\n",
      "     192 ┤                                       ││\n",
      "     160 ┤                                       ││\n",
      "     128 ┤                                       ││\n",
      "      96 ┤                                       ││\n",
      "      64 ┤                                       ││\n",
      "      32 ┤                                       ││\n",
      "       0 ┼───────────────────────────────────────╯╰──────────────────────────────────────\n",
      "    -0.5000  -0.4000  -0.3000  -0.1875  -0.0875  0.0250  0.1125  0.2125  0.3000  0.4000  0.5000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model.graph.initializers[\"q_weight\"].const_value = (\n",
    "    ir.tensor(np.zeros((hidden_size, hidden_size)).astype(np.float32), name=\"q_weight\")\n",
    ")\n",
    "model.graph.initializers[\"q_weight\"].const_value.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98851a49",
   "metadata": {},
   "source": [
    "### 3. Build a pass to modify the model (merge QKV weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "36f09674",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q weight value:\n",
      "Tensor<FLOAT,[16,16]>(array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=float32), name='q_weight')\n",
      "\n",
      "Min: 0.0, Max: 0.0, NaN count: 0, Inf count: 0\n",
      "Sparsity (abs<1e-06): 1.00\n",
      "Histogram:\n",
      "     256 ┼                                       ╭╮\n",
      "     224 ┤                                       ││\n",
      "     192 ┤                                       ││\n",
      "     160 ┤                                       ││\n",
      "     128 ┤                                       ││\n",
      "      96 ┤                                       ││\n",
      "      64 ┤                                       ││\n",
      "      32 ┤                                       ││\n",
      "       0 ┼───────────────────────────────────────╯╰──────────────────────────────────────\n",
      "    -0.5000  -0.4000  -0.3000  -0.1875  -0.0875  0.0250  0.1125  0.2125  0.3000  0.4000  0.5000\n"
     ]
    }
   ],
   "source": [
    "# Now we want to combine the weights into a single QKV weight matrix\n",
    "\n",
    "for node in model.graph:\n",
    "    if node.op_type != \"Attention\":\n",
    "        continue\n",
    "\n",
    "    # Find the weights for Q, K, V\n",
    "    input_val = node.inputs[0].producer().inputs[0]\n",
    "    q_weight_val = node.inputs[0].producer().inputs[1]\n",
    "    k_weight_val = node.inputs[1].producer().inputs[1]\n",
    "    v_weight_val = node.inputs[2].producer().inputs[1]\n",
    "    assert q_weight_val.const_value is not None\n",
    "    assert k_weight_val.const_value is not None\n",
    "    assert v_weight_val.const_value is not None\n",
    "    # Show the values of the weights\n",
    "    print(\"Q weight value:\")\n",
    "    q_weight_val.const_value.display()\n",
    "\n",
    "    qkv_weight = ir.Value(\n",
    "        name=\"qkv_weight\",\n",
    "        type=ir.TensorType(ir.DataType.FLOAT),\n",
    "        shape=ir.Shape([hidden_size, 3 * hidden_size]),\n",
    "        const_value=ir.tensor(\n",
    "            np.concatenate(\n",
    "                [\n",
    "                    q_weight_val.const_value,\n",
    "                    k_weight_val.const_value,\n",
    "                    v_weight_val.const_value,\n",
    "                ],\n",
    "                axis=1,\n",
    "            )\n",
    "        ),\n",
    "    )\n",
    "    # Create a new MatMul node uses the combined Q, K, V weights\n",
    "    combined_matmul_node = ir.node(\"MatMul\", inputs=[input_val, qkv_weight])\n",
    "    new_qkv = ir.node(\n",
    "        \"Split\",\n",
    "        inputs=combined_matmul_node.outputs,\n",
    "        attributes={\n",
    "            \"axis\": 2,\n",
    "            \"num_outputs\": 3,\n",
    "        },\n",
    "        num_outputs=3,\n",
    "    )\n",
    "    # Add the new node to the graph and register the new initializer\n",
    "    node.prepend((combined_matmul_node, new_qkv))\n",
    "    # Reconnect the Attention node to use the new QKV outputs\n",
    "    ir.convenience.replace_all_uses_with(\n",
    "        node.inputs,\n",
    "        new_qkv.outputs,\n",
    "    )\n",
    "    # Add the new initializer to the graph\n",
    "    model.graph.register_initializer(qkv_weight)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "62c92959",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined QKV model:\n",
      "<\n",
      "    ir_version=10,\n",
      "    opset_imports={'': 23},\n",
      "    producer_name=None,\n",
      "    producer_version=None,\n",
      "    domain=None,\n",
      "    model_version=None,\n",
      ">\n",
      "graph(\n",
      "    name=main_graph,\n",
      "    inputs=(\n",
      "        %\"input\"<FLOAT,[2,3,16]>\n",
      "    ),\n",
      "    outputs=(\n",
      "        %\"val_3\"<FLOAT,[2,3,16]>\n",
      "    ),\n",
      "    initializers=(\n",
      "        %\"q_weight\"<FLOAT,[16,16]>{Tensor(...)},\n",
      "        %\"k_weight\"<FLOAT,[16,16]>{Tensor(...)},\n",
      "        %\"v_weight\"<FLOAT,[16,16]>{Tensor(...)},\n",
      "        %\"qkv_weight\"<FLOAT,[16,48]>{Tensor(...)}\n",
      "    ),\n",
      ") {\n",
      "    0 |  # node_MatMul_0\n",
      "         %\"val_0\"<?,?> ⬅️ ::MatMul(%\"input\", %\"q_weight\"{...})\n",
      "    1 |  # node_MatMul_1\n",
      "         %\"val_1\"<?,?> ⬅️ ::MatMul(%\"input\", %\"k_weight\"{...})\n",
      "    2 |  # node_MatMul_2\n",
      "         %\"val_2\"<?,?> ⬅️ ::MatMul(%\"input\", %\"v_weight\"{...})\n",
      "    3 |  # node_MatMul_4\n",
      "         %\"val_4\"<?,?> ⬅️ ::MatMul(%\"input\", %\"qkv_weight\"{...})\n",
      "    4 |  # node_Split_5\n",
      "         %\"val_5\"<?,?>, %\"val_6\"<?,?>, %\"val_7\"<?,?> ⬅️ ::Split(%\"val_4\") {axis=2, num_outputs=3}\n",
      "    5 |  # node_Attention_3\n",
      "         %\"val_3\"<FLOAT,[2,3,16]> ⬅️ ::Attention(%\"val_5\", %\"val_6\", %\"val_7\") {q_num_heads=1, kv_num_heads=1}\n",
      "    return %\"val_3\"<FLOAT,[2,3,16]>\n",
      "}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Combined QKV model:\")\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbe6ebc8",
   "metadata": {},
   "source": [
    "### 3.5. Run passes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "69416d61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model after removing unused nodes:\n",
      "<\n",
      "    ir_version=10,\n",
      "    opset_imports={'': 23},\n",
      "    producer_name=None,\n",
      "    producer_version=None,\n",
      "    domain=None,\n",
      "    model_version=None,\n",
      ">\n",
      "graph(\n",
      "    name=main_graph,\n",
      "    inputs=(\n",
      "        %\"input\"<FLOAT,[2,3,16]>\n",
      "    ),\n",
      "    outputs=(\n",
      "        %\"val_3\"<FLOAT,[2,3,16]>\n",
      "    ),\n",
      "    initializers=(\n",
      "        %\"qkv_weight\"<FLOAT,[16,48]>{Tensor(...)}\n",
      "    ),\n",
      ") {\n",
      "    0 |  # node_MatMul_4\n",
      "         %\"val_4\"<?,?> ⬅️ ::MatMul(%\"input\", %\"qkv_weight\"{...})\n",
      "    1 |  # node_Split_5\n",
      "         %\"val_5\"<?,?>, %\"val_6\"<?,?>, %\"val_7\"<?,?> ⬅️ ::Split(%\"val_4\") {axis=2, num_outputs=3}\n",
      "    2 |  # node_Attention_3\n",
      "         %\"val_3\"<FLOAT,[2,3,16]> ⬅️ ::Attention(%\"val_5\", %\"val_6\", %\"val_7\") {q_num_heads=1, kv_num_heads=1}\n",
      "    return %\"val_3\"<FLOAT,[2,3,16]>\n",
      "}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import onnx_ir.passes.common as common_passes\n",
    "\n",
    "common_passes.RemoveUnusedNodesPass()(model)\n",
    "\n",
    "print(\"Model after removing unused nodes:\")\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "0e295db9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model after shape inference:\n",
      "<\n",
      "    ir_version=10,\n",
      "    opset_imports={'': 23},\n",
      "    producer_name=None,\n",
      "    producer_version=None,\n",
      "    domain=None,\n",
      "    model_version=None,\n",
      ">\n",
      "graph(\n",
      "    name=main_graph,\n",
      "    inputs=(\n",
      "        %\"input\"<FLOAT,[2,3,16]>\n",
      "    ),\n",
      "    outputs=(\n",
      "        %\"val_3\"<FLOAT,[2,3,16]>\n",
      "    ),\n",
      "    initializers=(\n",
      "        %\"qkv_weight\"<FLOAT,[16,48]>{Tensor(...)}\n",
      "    ),\n",
      ") {\n",
      "    0 |  # node_MatMul_4\n",
      "         %\"val_4\"<FLOAT,[2,3,48]> ⬅️ ::MatMul(%\"input\", %\"qkv_weight\"{...})\n",
      "    1 |  # node_Split_5\n",
      "         %\"val_5\"<FLOAT,[2,3,16]>, %\"val_6\"<FLOAT,[2,3,16]>, %\"val_7\"<FLOAT,[2,3,16]> ⬅️ ::Split(%\"val_4\") {axis=2, num_outputs=3}\n",
      "    2 |  # node_Attention_3\n",
      "         %\"val_3\"<FLOAT,[2,3,16]> ⬅️ ::Attention(%\"val_5\", %\"val_6\", %\"val_7\") {q_num_heads=1, kv_num_heads=1}\n",
      "    return %\"val_3\"<FLOAT,[2,3,16]>\n",
      "}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "common_passes.ShapeInferencePass()(model)\n",
    "\n",
    "print(\"Model after shape inference:\")\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1ffbe3c",
   "metadata": {},
   "source": [
    "### 4. Use rewriter to do the same thing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "a2200331",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<\n",
      "    ir_version=10,\n",
      "    opset_imports={'': 23},\n",
      "    producer_name=None,\n",
      "    producer_version=None,\n",
      "    domain=None,\n",
      "    model_version=None,\n",
      ">\n",
      "graph(\n",
      "    name=main_graph,\n",
      "    inputs=(\n",
      "        %\"input\"<FLOAT,[2,3,16]>\n",
      "    ),\n",
      "    outputs=(\n",
      "        %\"val_3\"<FLOAT,[2,3,16]>\n",
      "    ),\n",
      "    initializers=(\n",
      "        %\"qkv_weight\"<FLOAT,[16,48]>{Tensor(...)}\n",
      "    ),\n",
      ") {\n",
      "    0 |  # node_MatMul_4\n",
      "         %\"val_4\"<FLOAT,[2,3,48]> ⬅️ ::MatMul(%\"input\", %\"qkv_weight\"{...})\n",
      "    1 |  # node_Split_5\n",
      "         %\"val_5\"<FLOAT,[2,3,16]>, %\"val_6\"<FLOAT,[2,3,16]>, %\"val_7\"<FLOAT,[2,3,16]> ⬅️ ::Split(%\"val_4\") {axis=2, num_outputs=3}\n",
      "    2 |  # node_Attention_6\n",
      "         %\"val_3\"<FLOAT,[2,3,16]> ⬅️ ::Attention(%\"val_5\", %\"val_6\", %\"val_7\") {q_num_heads=1, kv_num_heads=1}\n",
      "    return %\"val_3\"<FLOAT,[2,3,16]>\n",
      "}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Now use the rewriter\n",
    "\n",
    "import onnxscript.rewriter as rewriter\n",
    "\n",
    "class CombineQKVWeights(rewriter.pattern.RewriteRuleClassBase):\n",
    "    def pattern(cls, op, input, q_weight, k_weight, v_weight):\n",
    "        q = op.MatMul(input, q_weight)\n",
    "        k = op.MatMul(input, k_weight)\n",
    "        v = op.MatMul(input, v_weight)\n",
    "        return op.Attention(q, k, v, q_num_heads=1, kv_num_heads=1)\n",
    "\n",
    "    def rewrite(cls, op, input, q_weight, k_weight, v_weight):\n",
    "        qkv_weight = op.initializer(\n",
    "            ir.tensor(\n",
    "                np.concatenate(\n",
    "                    [\n",
    "                        q_weight.const_value.numpy(),\n",
    "                        k_weight.const_value.numpy(),\n",
    "                        v_weight.const_value.numpy(),\n",
    "                    ],\n",
    "                    axis=1,\n",
    "                )\n",
    "            ),\n",
    "            name=\"qkv_weight\",\n",
    "        )\n",
    "        combined_matmul = op.MatMul(input, qkv_weight)\n",
    "        new_q, new_k, new_v = op.Split(combined_matmul, axis=2, num_outputs=3, _outputs=3)\n",
    "        return op.Attention(new_q, new_k, new_v, q_num_heads=1, kv_num_heads=1)\n",
    "\n",
    "model = build_model()\n",
    "# Create the rewrite rule\n",
    "rule = CombineQKVWeights.rule()\n",
    "# Apply the rewrite rule to the model\n",
    "rule.apply_to_model(model)\n",
    "# Clean up and run shape inference. Note that you can use the Sequential pass to chain multiple passes together.\n",
    "ir.passes.Sequential(\n",
    "    common_passes.RemoveUnusedNodesPass(),\n",
    "    common_passes.ShapeInferencePass(),\n",
    ")(model)\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "533cab58",
   "metadata": {},
   "source": [
    "### 5. Show it on model explorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "d9521cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ir.save(model, \"merged_qkv.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "8fca9b7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading extensions...\n",
      "2025-06-07 18:56:49.125906: I external/org_tensorflow/tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "Loaded 9 extensions:\n",
      " - TFLite adapter (Flatbuffer)\n",
      " - TFLite adapter (MLIR)\n",
      " - TF adapter (MLIR)\n",
      " - TF adapter (direct)\n",
      " - GraphDef adapter\n",
      " - Pytorch adapter (exported program)\n",
      " - MLIR adapter\n",
      " - ONNX adapter\n",
      " - JSON adapter\n",
      "\n",
      "Starting Model Explorer server at:\n",
      "http://localhost:8083/?data=%7B%22models%22%3A%20%5B%7B%22url%22%3A%20%22/home/justinchu/dev/onnx-meetup-2025/merged_qkv.onnx%22%7D%5D%7D\n",
      "\n",
      "Press Ctrl+C to stop.\n",
      "gio: http://localhost:8083/?data=%7B%22models%22%3A%20%5B%7B%22url%22%3A%20%22/home/justinchu/dev/onnx-meetup-2025/merged_qkv.onnx%22%7D%5D%7D: Operation not supported\n",
      "Stopping server...\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "!onnxvis merged_qkv.onnx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7b27674",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
