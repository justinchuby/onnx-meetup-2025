{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f786336",
   "metadata": {},
   "source": [
    "# Demos for Talk Working with Large Models in ONNX IR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1985be7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: onnxscript in ./.venv/lib/python3.12/site-packages (0.3.0)\n",
      "Requirement already satisfied: onnx-ir in ./.venv/lib/python3.12/site-packages (0.1.1)\n",
      "Requirement already satisfied: onnx-safetensors in ./.venv/lib/python3.12/site-packages (1.1.1)\n",
      "Requirement already satisfied: model-explorer-onnx in ./.venv/lib/python3.12/site-packages (0.3.4)\n",
      "Collecting onnxruntime\n",
      "  Downloading onnxruntime-1.22.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.8 kB)\n",
      "Requirement already satisfied: ml_dtypes in ./.venv/lib/python3.12/site-packages (from onnxscript) (0.5.1)\n",
      "Requirement already satisfied: numpy in ./.venv/lib/python3.12/site-packages (from onnxscript) (2.3.0)\n",
      "Requirement already satisfied: onnx>=1.16 in ./.venv/lib/python3.12/site-packages (from onnxscript) (1.18.0)\n",
      "Requirement already satisfied: packaging in ./.venv/lib/python3.12/site-packages (from onnxscript) (25.0)\n",
      "Requirement already satisfied: typing_extensions>=4.10 in ./.venv/lib/python3.12/site-packages (from onnxscript) (4.14.0)\n",
      "Requirement already satisfied: safetensors in ./.venv/lib/python3.12/site-packages (from onnx-safetensors) (0.5.3)\n",
      "Requirement already satisfied: ai-edge-model-explorer>=0.1.10 in ./.venv/lib/python3.12/site-packages (from model-explorer-onnx) (0.1.19)\n",
      "Collecting coloredlogs (from onnxruntime)\n",
      "  Using cached coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
      "Collecting flatbuffers (from onnxruntime)\n",
      "  Using cached flatbuffers-25.2.10-py2.py3-none-any.whl.metadata (875 bytes)\n",
      "Requirement already satisfied: protobuf in ./.venv/lib/python3.12/site-packages (from onnxruntime) (6.31.1)\n",
      "Collecting sympy (from onnxruntime)\n",
      "  Using cached sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: flask in ./.venv/lib/python3.12/site-packages (from ai-edge-model-explorer>=0.1.10->model-explorer-onnx) (3.1.1)\n",
      "Requirement already satisfied: ipython in ./.venv/lib/python3.12/site-packages (from ai-edge-model-explorer>=0.1.10->model-explorer-onnx) (9.3.0)\n",
      "Requirement already satisfied: ai-edge-model-explorer-adapter==0.1.5 in ./.venv/lib/python3.12/site-packages (from ai-edge-model-explorer>=0.1.10->model-explorer-onnx) (0.1.5)\n",
      "Requirement already satisfied: portpicker in ./.venv/lib/python3.12/site-packages (from ai-edge-model-explorer>=0.1.10->model-explorer-onnx) (1.6.0)\n",
      "Requirement already satisfied: requests in ./.venv/lib/python3.12/site-packages (from ai-edge-model-explorer>=0.1.10->model-explorer-onnx) (2.32.3)\n",
      "Requirement already satisfied: termcolor in ./.venv/lib/python3.12/site-packages (from ai-edge-model-explorer>=0.1.10->model-explorer-onnx) (3.1.0)\n",
      "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime)\n",
      "  Using cached humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
      "Requirement already satisfied: blinker>=1.9.0 in ./.venv/lib/python3.12/site-packages (from flask->ai-edge-model-explorer>=0.1.10->model-explorer-onnx) (1.9.0)\n",
      "Requirement already satisfied: click>=8.1.3 in ./.venv/lib/python3.12/site-packages (from flask->ai-edge-model-explorer>=0.1.10->model-explorer-onnx) (8.2.1)\n",
      "Requirement already satisfied: itsdangerous>=2.2.0 in ./.venv/lib/python3.12/site-packages (from flask->ai-edge-model-explorer>=0.1.10->model-explorer-onnx) (2.2.0)\n",
      "Requirement already satisfied: jinja2>=3.1.2 in ./.venv/lib/python3.12/site-packages (from flask->ai-edge-model-explorer>=0.1.10->model-explorer-onnx) (3.1.6)\n",
      "Requirement already satisfied: markupsafe>=2.1.1 in ./.venv/lib/python3.12/site-packages (from flask->ai-edge-model-explorer>=0.1.10->model-explorer-onnx) (3.0.2)\n",
      "Requirement already satisfied: werkzeug>=3.1.0 in ./.venv/lib/python3.12/site-packages (from flask->ai-edge-model-explorer>=0.1.10->model-explorer-onnx) (3.1.3)\n",
      "Requirement already satisfied: decorator in ./.venv/lib/python3.12/site-packages (from ipython->ai-edge-model-explorer>=0.1.10->model-explorer-onnx) (5.2.1)\n",
      "Requirement already satisfied: ipython-pygments-lexers in ./.venv/lib/python3.12/site-packages (from ipython->ai-edge-model-explorer>=0.1.10->model-explorer-onnx) (1.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in ./.venv/lib/python3.12/site-packages (from ipython->ai-edge-model-explorer>=0.1.10->model-explorer-onnx) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline in ./.venv/lib/python3.12/site-packages (from ipython->ai-edge-model-explorer>=0.1.10->model-explorer-onnx) (0.1.7)\n",
      "Requirement already satisfied: pexpect>4.3 in ./.venv/lib/python3.12/site-packages (from ipython->ai-edge-model-explorer>=0.1.10->model-explorer-onnx) (4.9.0)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in ./.venv/lib/python3.12/site-packages (from ipython->ai-edge-model-explorer>=0.1.10->model-explorer-onnx) (3.0.51)\n",
      "Requirement already satisfied: pygments>=2.4.0 in ./.venv/lib/python3.12/site-packages (from ipython->ai-edge-model-explorer>=0.1.10->model-explorer-onnx) (2.19.1)\n",
      "Requirement already satisfied: stack_data in ./.venv/lib/python3.12/site-packages (from ipython->ai-edge-model-explorer>=0.1.10->model-explorer-onnx) (0.6.3)\n",
      "Requirement already satisfied: traitlets>=5.13.0 in ./.venv/lib/python3.12/site-packages (from ipython->ai-edge-model-explorer>=0.1.10->model-explorer-onnx) (5.14.3)\n",
      "Requirement already satisfied: wcwidth in ./.venv/lib/python3.12/site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython->ai-edge-model-explorer>=0.1.10->model-explorer-onnx) (0.2.13)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in ./.venv/lib/python3.12/site-packages (from jedi>=0.16->ipython->ai-edge-model-explorer>=0.1.10->model-explorer-onnx) (0.8.4)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in ./.venv/lib/python3.12/site-packages (from pexpect>4.3->ipython->ai-edge-model-explorer>=0.1.10->model-explorer-onnx) (0.7.0)\n",
      "Requirement already satisfied: psutil in ./.venv/lib/python3.12/site-packages (from portpicker->ai-edge-model-explorer>=0.1.10->model-explorer-onnx) (7.0.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.12/site-packages (from requests->ai-edge-model-explorer>=0.1.10->model-explorer-onnx) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.12/site-packages (from requests->ai-edge-model-explorer>=0.1.10->model-explorer-onnx) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.12/site-packages (from requests->ai-edge-model-explorer>=0.1.10->model-explorer-onnx) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.12/site-packages (from requests->ai-edge-model-explorer>=0.1.10->model-explorer-onnx) (2025.4.26)\n",
      "Requirement already satisfied: executing>=1.2.0 in ./.venv/lib/python3.12/site-packages (from stack_data->ipython->ai-edge-model-explorer>=0.1.10->model-explorer-onnx) (2.2.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in ./.venv/lib/python3.12/site-packages (from stack_data->ipython->ai-edge-model-explorer>=0.1.10->model-explorer-onnx) (3.0.0)\n",
      "Requirement already satisfied: pure-eval in ./.venv/lib/python3.12/site-packages (from stack_data->ipython->ai-edge-model-explorer>=0.1.10->model-explorer-onnx) (0.2.3)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy->onnxruntime)\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Downloading onnxruntime-1.22.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.4/16.4 MB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hUsing cached coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
      "Using cached humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
      "Using cached flatbuffers-25.2.10-py2.py3-none-any.whl (30 kB)\n",
      "Using cached sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Installing collected packages: mpmath, flatbuffers, sympy, humanfriendly, coloredlogs, onnxruntime\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6/6\u001b[0m [onnxruntime]\u001b[0m [onnxruntime]\n",
      "\u001b[1A\u001b[2KSuccessfully installed coloredlogs-15.0.1 flatbuffers-25.2.10 humanfriendly-10.0 mpmath-1.3.0 onnxruntime-1.22.0 sympy-1.14.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Prepare environment\n",
    "\n",
    "%pip install --upgrade onnxscript onnx-ir onnx-safetensors model-explorer-onnx onnxruntime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bedf1490",
   "metadata": {},
   "source": [
    "## Demo 1: Safetensors in ONNX\n",
    "\n",
    "Q1: Is there a way to use the safetensors format as an external data format for ONNX?\n",
    "A1: Yes. The data is contiguous, row-major, and little-endian (same as ONNX). Data offset can be found by parsing the json header.\n",
    "\n",
    "<img src=\"resources/safetensors-format.svg\" width=\"500\"/>\n",
    "\n",
    "Image source: https://huggingface.co/docs/safetensors/en/index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a54e0bdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<\n",
      "   ir_version: 10,\n",
      "   opset_import: [\"\" : 21],\n",
      "   producer_name: \"onnx-safetensors-example\"\n",
      ">\n",
      "SimpleGraph (float[1,3] input) => (float[1,3] output) \n",
      "   <float[3] weights =  {1,2,3}>\n",
      "{\n",
      "   output = Add (input, weights)\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import onnx\n",
    "\n",
    "model = onnx.load(\"resources/model.textproto\")\n",
    "print(onnx.printer.to_text(model))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04626ef6",
   "metadata": {},
   "source": [
    "### Loading tensors from a safetensors file into an ONNX model\n",
    "\n",
    "We first create a safetensors file with compatible weights, then load these weights into the ONNX model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b77ddb75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<\n",
      "   ir_version: 10,\n",
      "   opset_import: [\"\" : 21],\n",
      "   producer_name: \"onnx-safetensors-example\"\n",
      ">\n",
      "SimpleGraph (float[1,3] input) => (float[1,3] output) \n",
      "   <float[3] weights =  {4,5,6}, float[3] weights>\n",
      "{\n",
      "   output = Add (input, weights)\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import safetensors.numpy\n",
    "\n",
    "import onnx_safetensors\n",
    "\n",
    "# Create a safetensors file with compatible weights\n",
    "# Note that the tensor key \"weights\" matches the name of the tensor in the model\n",
    "weights_dict = {\"weights\": np.array([4.0, 5.0, 6.0], dtype=np.float32)}\n",
    "safetensors.numpy.save_file(weights_dict, \"resources/weights.safetensors\")\n",
    "\n",
    "# Now you can replace the weights in the model\n",
    "replaced_model = onnx_safetensors.load_file(model, \"resources/weights.safetensors\")\n",
    "\n",
    "# Notice how the weights have been replaced to [4, 5, 6]\n",
    "print(onnx.printer.to_text(replaced_model))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cecd56d8",
   "metadata": {},
   "source": [
    "Use `load_file_as_external_data` to load safetensors as external data and replace weights in the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "72d642a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<\n",
      "   ir_version: 10,\n",
      "   opset_import: [\"\" : 21],\n",
      "   producer_name: \"onnx-safetensors-example\"\n",
      ">\n",
      "SimpleGraph (float[1,3] input) => (float[1,3] output) \n",
      "   <float[3] weights = [\"location\": \"resources/weights.safetensors\", \"offset\": \"72\", \"length\": \"12\"], float[3] weights>\n",
      "{\n",
      "   output = Add (input, weights)\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "model_with_external_data = onnx_safetensors.load_file_as_external_data(\n",
    "    model, \"resources/weights.safetensors\"\n",
    ")\n",
    "\n",
    "print(onnx.printer.to_text(model_with_external_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7ff107f",
   "metadata": {},
   "source": [
    "### Using safetensors as external data for ONNX\n",
    "\n",
    "We can similarly save external data file from an ONNX model to safetensors. By storing the tensor dtype in ONNX file, we can even use types safetensors doesn't yet support, like INT4.\n",
    "\n",
    "You can read more at https://github.com/justinchuby/onnx-safetensors/blob/main/examples/tutorial.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eb20a2e",
   "metadata": {},
   "source": [
    "### Inference with ONNX Runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "39c668a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.0, 2.0, 3.0]] + [4, 5, 6] = [array([[5., 7., 9.]], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "import onnxruntime as ort\n",
    "\n",
    "onnx.save(model_with_external_data, \"model_with_external_data.onnx\")\n",
    "session = ort.InferenceSession(\"model_with_external_data.onnx\")\n",
    "output = session.run(None, {\"input\": np.array([[1.0, 2.0, 3.0]], dtype=np.float32)})\n",
    "print(\"[[1.0, 2.0, 3.0]] + [4, 5, 6] =\", output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ab484c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
