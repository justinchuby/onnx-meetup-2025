{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f786336",
   "metadata": {},
   "source": [
    "# Demos for Talk Working with Large Models in ONNX IR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1985be7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare environment\n",
    "\n",
    "%pip install --upgrade onnxscript onnx-ir onnx-safetensors model-explorer-onnx onnxruntime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bedf1490",
   "metadata": {},
   "source": [
    "## Demo 1: Safetensors in ONNX\n",
    "\n",
    "**Q1:** Is there a way to use the safetensors format as an external data format for ONNX?\n",
    "\n",
    "**A1:** Yes. The data is contiguous, row-major, and little-endian (same as ONNX). Data offset can be found by parsing the json header.\n",
    "\n",
    "<img src=\"resources/safetensors-format.svg\" width=\"500\"/>\n",
    "\n",
    "Image source: https://huggingface.co/docs/safetensors/en/index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9337aa3c",
   "metadata": {},
   "source": [
    "**Q2:** How do we do it efficiently?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a54e0bdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<\n",
      "    ir_version=10,\n",
      "    opset_imports={'': 21},\n",
      "    producer_name='onnx-safetensors-example',\n",
      "    producer_version=None,\n",
      "    domain=None,\n",
      "    model_version=None,\n",
      ">\n",
      "graph(\n",
      "    name=SimpleGraph,\n",
      "    inputs=(\n",
      "        %\"input\"<FLOAT,[1,3]>\n",
      "    ),\n",
      "    outputs=(\n",
      "        %\"output\"<FLOAT,[1,3]>\n",
      "    ),\n",
      "    initializers=(\n",
      "        %\"weights\"<FLOAT,[3]>{TensorProtoTensor<FLOAT,[3]>(array([1., 2., 3.], dtype=float32), name='weights')}\n",
      "    ),\n",
      ") {\n",
      "    0 |  # :anonymous_node:130470423510864\n",
      "         %\"output\"<FLOAT,[1,3]> ⬅️ ::Add(%\"input\", %\"weights\"{[1.0, 2.0, 3.0]})\n",
      "    return %\"output\"<FLOAT,[1,3]>\n",
      "}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import onnx_ir as ir\n",
    "\n",
    "model = ir.load(\"resources/model.textproto\")\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04626ef6",
   "metadata": {},
   "source": [
    "### Loading tensors from a safetensors file into an ONNX model\n",
    "\n",
    "We first create a safetensors file with compatible weights, then load these weights into the ONNX model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b77ddb75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<\n",
      "    ir_version=10,\n",
      "    opset_imports={'': 21},\n",
      "    producer_name='onnx-safetensors-example',\n",
      "    producer_version=None,\n",
      "    domain=None,\n",
      "    model_version=None,\n",
      ">\n",
      "graph(\n",
      "    name=SimpleGraph,\n",
      "    inputs=(\n",
      "        %\"input\"<FLOAT,[1,3]>\n",
      "    ),\n",
      "    outputs=(\n",
      "        %\"output\"<FLOAT,[1,3]>\n",
      "    ),\n",
      "    initializers=(\n",
      "        %\"weights\"<FLOAT,[3]>{Tensor<FLOAT,[3]>(array([4., 5., 6.], dtype=float32), name='weights')}\n",
      "    ),\n",
      ") {\n",
      "    0 |  # :anonymous_node:130470423510864\n",
      "         %\"output\"<FLOAT,[1,3]> ⬅️ ::Add(%\"input\", %\"weights\"{[4.0, 5.0, 6.0]})\n",
      "    return %\"output\"<FLOAT,[1,3]>\n",
      "}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import safetensors.numpy\n",
    "\n",
    "import onnx_safetensors\n",
    "\n",
    "# Create a safetensors file with compatible weights\n",
    "# Note that the tensor key \"weights\" matches the name of the tensor in the model\n",
    "weights_dict = {\"weights\": np.array([4.0, 5.0, 6.0], dtype=np.float32)}\n",
    "safetensors.numpy.save_file(weights_dict, \"resources/weights.safetensors\")\n",
    "\n",
    "# Now you can replace the weights in the model\n",
    "replaced_model = onnx_safetensors.load_file(model, \"resources/weights.safetensors\")\n",
    "\n",
    "# Notice how the weights have been replaced to [4, 5, 6]\n",
    "print(replaced_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cecd56d8",
   "metadata": {},
   "source": [
    "Use `load_file_as_external_data` to load safetensors as external data and replace weights in the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "72d642a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<\n",
      "   ir_version: 10,\n",
      "   opset_import: [\"\" : 21],\n",
      "   producer_name: \"onnx-safetensors-example\"\n",
      ">\n",
      "SimpleGraph (float[1,3] input) => (float[1,3] output) \n",
      "   <float[3] weights = [\"location\": \"resources/weights.safetensors\", \"offset\": \"72\", \"length\": \"12\"], float[3] weights>\n",
      "{\n",
      "   output = Add (input, weights)\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "model_with_external_data = onnx_safetensors.load_file_as_external_data(\n",
    "    model, \"resources/weights.safetensors\"\n",
    ")\n",
    "\n",
    "print(onnx.printer.to_text(ir.to_proto(model_with_external_data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7ff107f",
   "metadata": {},
   "source": [
    "### Using safetensors as external data for ONNX\n",
    "\n",
    "We can similarly save external data file from an ONNX model to safetensors. By storing the tensor dtype in ONNX file, we can even use types safetensors doesn't yet support, like INT4.\n",
    "\n",
    "You can read more at https://github.com/justinchuby/onnx-safetensors/blob/main/examples/tutorial.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eb20a2e",
   "metadata": {},
   "source": [
    "### Inference with ONNX Runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "39c668a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.0, 2.0, 3.0]] + [4, 5, 6] = [array([[5., 7., 9.]], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "import onnxruntime as ort\n",
    "\n",
    "ir.save(model_with_external_data, \"model_with_external_data.onnx\")\n",
    "session = ort.InferenceSession(\"model_with_external_data.onnx\")\n",
    "output = session.run(None, {\"input\": np.array([[1.0, 2.0, 3.0]], dtype=np.float32)})\n",
    "print(\"[[1.0, 2.0, 3.0]] + [4, 5, 6] =\", output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c03361ce",
   "metadata": {},
   "source": [
    "## Demo 2: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "160e2559",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ab484c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
