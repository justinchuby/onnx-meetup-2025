 {
  "label": "model_SmolLM17b_optimized.onnx",
  "graphs": [
    {
      "id": "main_graph (2)",
      "nodes": [
        {
          "id": "[value] input_ids",
          "label": "Input",
          "namespace": "",
          "subgraphIds": [],
          "attrs": [
            {
              "key": "name",
              "value": "input_ids"
            },
            {
              "key": "index",
              "value": "0"
            }
          ],
          "incomingEdges": [],
          "outputsMetadata": [
            {
              "id": "0",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "input_ids"
                },
                {
                  "key": "tensor_shape",
                  "value": "INT64[s34,s16]"
                },
                {
                  "key": "[metadata] pkg.torch.export.graph_signature.InputSpec.kind",
                  "value": "USER_INPUT"
                },
                {
                  "key": "[metadata] pkg.torch.export.graph_signature.InputSpec.persistent",
                  "value": "None"
                }
              ]
            }
          ],
          "inputsMetadata": [],
          "style": null,
          "config": null
        },
        {
          "id": "[value] attention_mask",
          "label": "Input",
          "namespace": "",
          "subgraphIds": [],
          "attrs": [
            {
              "key": "name",
              "value": "attention_mask"
            },
            {
              "key": "index",
              "value": "1"
            }
          ],
          "incomingEdges": [],
          "outputsMetadata": [
            {
              "id": "0",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "attention_mask"
                },
                {
                  "key": "tensor_shape",
                  "value": "INT64[s34,s16 + s17]"
                },
                {
                  "key": "[metadata] pkg.torch.export.graph_signature.InputSpec.kind",
                  "value": "USER_INPUT"
                },
                {
                  "key": "[metadata] pkg.torch.export.graph_signature.InputSpec.persistent",
                  "value": "None"
                }
              ]
            }
          ],
          "inputsMetadata": [],
          "style": null,
          "config": null
        },
        {
          "id": "[value] past_key_values_key_cache_0",
          "label": "Input",
          "namespace": "",
          "subgraphIds": [],
          "attrs": [
            {
              "key": "name",
              "value": "past_key_values_key_cache_0"
            },
            {
              "key": "index",
              "value": "2"
            }
          ],
          "incomingEdges": [],
          "outputsMetadata": [
            {
              "id": "0",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "past_key_values_key_cache_0"
                },
                {
                  "key": "tensor_shape",
                  "value": "FLOAT[s34,32,s17,64]"
                },
                {
                  "key": "[metadata] pkg.torch.export.graph_signature.InputSpec.kind",
                  "value": "USER_INPUT"
                },
                {
                  "key": "[metadata] pkg.torch.export.graph_signature.InputSpec.persistent",
                  "value": "None"
                }
              ]
            }
          ],
          "inputsMetadata": [],
          "style": null,
          "config": null
        },
        {
          "id": "[value] past_key_values_key_cache_1",
          "label": "Input",
          "namespace": "",
          "subgraphIds": [],
          "attrs": [
            {
              "key": "name",
              "value": "past_key_values_key_cache_1"
            },
            {
              "key": "index",
              "value": "3"
            }
          ],
          "incomingEdges": [],
          "outputsMetadata": [
            {
              "id": "0",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "past_key_values_key_cache_1"
                },
                {
                  "key": "tensor_shape",
                  "value": "FLOAT[s34,32,s17,64]"
                },
                {
                  "key": "[metadata] pkg.torch.export.graph_signature.InputSpec.kind",
                  "value": "USER_INPUT"
                },
                {
                  "key": "[metadata] pkg.torch.export.graph_signature.InputSpec.persistent",
                  "value": "None"
                }
              ]
            }
          ],
          "inputsMetadata": [],
          "style": null,
          "config": null
        },
        {
          "id": "[value] past_key_values_value_cache_0",
          "label": "Input",
          "namespace": "",
          "subgraphIds": [],
          "attrs": [
            {
              "key": "name",
              "value": "past_key_values_value_cache_0"
            },
            {
              "key": "index",
              "value": "4"
            }
          ],
          "incomingEdges": [],
          "outputsMetadata": [
            {
              "id": "0",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "past_key_values_value_cache_0"
                },
                {
                  "key": "tensor_shape",
                  "value": "FLOAT[s34,32,s17,64]"
                },
                {
                  "key": "[metadata] pkg.torch.export.graph_signature.InputSpec.kind",
                  "value": "USER_INPUT"
                },
                {
                  "key": "[metadata] pkg.torch.export.graph_signature.InputSpec.persistent",
                  "value": "None"
                }
              ]
            }
          ],
          "inputsMetadata": [],
          "style": null,
          "config": null
        },
        {
          "id": "[value] past_key_values_value_cache_1",
          "label": "Input",
          "namespace": "",
          "subgraphIds": [],
          "attrs": [
            {
              "key": "name",
              "value": "past_key_values_value_cache_1"
            },
            {
              "key": "index",
              "value": "5"
            }
          ],
          "incomingEdges": [],
          "outputsMetadata": [
            {
              "id": "0",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "past_key_values_value_cache_1"
                },
                {
                  "key": "tensor_shape",
                  "value": "FLOAT[s34,32,s17,64]"
                },
                {
                  "key": "[metadata] pkg.torch.export.graph_signature.InputSpec.kind",
                  "value": "USER_INPUT"
                },
                {
                  "key": "[metadata] pkg.torch.export.graph_signature.InputSpec.persistent",
                  "value": "None"
                }
              ]
            }
          ],
          "inputsMetadata": [],
          "style": null,
          "config": null
        },
        {
          "id": "node_Shape_2",
          "label": "Shape",
          "namespace": "main_graph/_empty_nn_module_stack_from_metadata_hook: _empty_nn_module_stack_from_metadata_hook/sym_size_int_61: aten.sym_size.int",
          "subgraphIds": [],
          "attrs": [
            {
              "key": "end",
              "value": "2"
            },
            {
              "key": "start",
              "value": "1"
            },
            {
              "key": "[metadata] namespace",
              "value": "_empty_nn_module_stack_from_metadata_hook: _empty_nn_module_stack_from_metadata_hook/sym_size_int_61: aten.sym_size.int"
            },
            {
              "key": "[metadata] pkg.torch.onnx.class_hierarchy",
              "value": "['_empty_nn_module_stack_from_metadata_hook', 'aten.sym_size.int']"
            },
            {
              "key": "[metadata] pkg.torch.onnx.fx_node",
              "value": "%sym_size_int_61 : [num_users=10] = call_function[target=torch.ops.aten.sym_size.int](args = (%input_ids, 1), kwargs = {})"
            },
            {
              "key": "[metadata] pkg.torch.onnx.name_scopes",
              "value": "['_empty_nn_module_stack_from_metadata_hook', 'sym_size_int_61']"
            },
            {
              "key": "[metadata] pkg.torch.onnx.stack_trace",
              "value": "File \"torch/fx/passes/runtime_assert.py\", line 24, in insert_deferred_runtime_asserts"
            }
          ],
          "incomingEdges": [
            {
              "sourceNodeId": "[value] input_ids",
              "sourceNodeOutputId": "0",
              "targetNodeInputId": "0"
            }
          ],
          "outputsMetadata": [
            {
              "id": "0",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "val_1"
                },
                {
                  "key": "tensor_shape",
                  "value": "INT64[1]"
                },
                {
                  "key": "param_name",
                  "value": "shape"
                }
              ]
            }
          ],
          "inputsMetadata": [
            {
              "id": "0",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "input_ids"
                },
                {
                  "key": "tensor_shape",
                  "value": "INT64[s34,s16]"
                },
                {
                  "key": "[metadata] pkg.torch.export.graph_signature.InputSpec.kind",
                  "value": "USER_INPUT"
                },
                {
                  "key": "[metadata] pkg.torch.export.graph_signature.InputSpec.persistent",
                  "value": "None"
                },
                {
                  "key": "param_name",
                  "value": "data"
                }
              ]
            }
          ],
          "style": null,
          "config": null
        },
        {
          "id": "node_Squeeze_3",
          "label": "Squeeze",
          "namespace": "main_graph/_empty_nn_module_stack_from_metadata_hook: _empty_nn_module_stack_from_metadata_hook/sym_size_int_61: aten.sym_size.int",
          "subgraphIds": [],
          "attrs": [
            {
              "key": "[metadata] namespace",
              "value": "_empty_nn_module_stack_from_metadata_hook: _empty_nn_module_stack_from_metadata_hook/sym_size_int_61: aten.sym_size.int"
            },
            {
              "key": "[metadata] pkg.torch.onnx.class_hierarchy",
              "value": "['_empty_nn_module_stack_from_metadata_hook', 'aten.sym_size.int']"
            },
            {
              "key": "[metadata] pkg.torch.onnx.fx_node",
              "value": "%sym_size_int_61 : [num_users=10] = call_function[target=torch.ops.aten.sym_size.int](args = (%input_ids, 1), kwargs = {})"
            },
            {
              "key": "[metadata] pkg.torch.onnx.name_scopes",
              "value": "['_empty_nn_module_stack_from_metadata_hook', 'sym_size_int_61']"
            },
            {
              "key": "[metadata] pkg.torch.onnx.stack_trace",
              "value": "File \"torch/fx/passes/runtime_assert.py\", line 24, in insert_deferred_runtime_asserts"
            }
          ],
          "incomingEdges": [
            {
              "sourceNodeId": "node_Shape_2",
              "sourceNodeOutputId": "0",
              "targetNodeInputId": "0"
            }
          ],
          "outputsMetadata": [
            {
              "id": "0",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "sym_size_int_61"
                },
                {
                  "key": "tensor_shape",
                  "value": "INT64[]"
                },
                {
                  "key": "param_name",
                  "value": "squeezed"
                }
              ]
            }
          ],
          "inputsMetadata": [
            {
              "id": "0",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "val_1"
                },
                {
                  "key": "tensor_shape",
                  "value": "INT64[1]"
                },
                {
                  "key": "param_name",
                  "value": "data"
                }
              ]
            }
          ],
          "style": null,
          "config": null
        },
        {
          "id": "node_Shape_10",
          "label": "Shape",
          "namespace": "main_graph/_empty_nn_module_stack_from_metadata_hook: _empty_nn_module_stack_from_metadata_hook/sym_size_int_67: aten.sym_size.int",
          "subgraphIds": [],
          "attrs": [
            {
              "key": "end",
              "value": "3"
            },
            {
              "key": "start",
              "value": "2"
            },
            {
              "key": "[metadata] namespace",
              "value": "_empty_nn_module_stack_from_metadata_hook: _empty_nn_module_stack_from_metadata_hook/sym_size_int_67: aten.sym_size.int"
            },
            {
              "key": "[metadata] pkg.torch.onnx.class_hierarchy",
              "value": "['_empty_nn_module_stack_from_metadata_hook', 'aten.sym_size.int']"
            },
            {
              "key": "[metadata] pkg.torch.onnx.fx_node",
              "value": "%sym_size_int_67 : [num_users=5] = call_function[target=torch.ops.aten.sym_size.int](args = (%past_key_values_key_cache_1, 2), kwargs = {})"
            },
            {
              "key": "[metadata] pkg.torch.onnx.name_scopes",
              "value": "['_empty_nn_module_stack_from_metadata_hook', 'sym_size_int_67']"
            },
            {
              "key": "[metadata] pkg.torch.onnx.stack_trace",
              "value": "File \"torch/fx/passes/runtime_assert.py\", line 24, in insert_deferred_runtime_asserts"
            }
          ],
          "incomingEdges": [
            {
              "sourceNodeId": "[value] past_key_values_key_cache_1",
              "sourceNodeOutputId": "0",
              "targetNodeInputId": "0"
            }
          ],
          "outputsMetadata": [
            {
              "id": "0",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "val_5"
                },
                {
                  "key": "tensor_shape",
                  "value": "INT64[1]"
                },
                {
                  "key": "param_name",
                  "value": "shape"
                }
              ]
            }
          ],
          "inputsMetadata": [
            {
              "id": "0",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "past_key_values_key_cache_1"
                },
                {
                  "key": "tensor_shape",
                  "value": "FLOAT[s34,32,s17,64]"
                },
                {
                  "key": "[metadata] pkg.torch.export.graph_signature.InputSpec.kind",
                  "value": "USER_INPUT"
                },
                {
                  "key": "[metadata] pkg.torch.export.graph_signature.InputSpec.persistent",
                  "value": "None"
                },
                {
                  "key": "param_name",
                  "value": "data"
                }
              ]
            }
          ],
          "style": null,
          "config": null
        },
        {
          "id": "node_Squeeze_11",
          "label": "Squeeze",
          "namespace": "main_graph/_empty_nn_module_stack_from_metadata_hook: _empty_nn_module_stack_from_metadata_hook/sym_size_int_67: aten.sym_size.int",
          "subgraphIds": [],
          "attrs": [
            {
              "key": "[metadata] namespace",
              "value": "_empty_nn_module_stack_from_metadata_hook: _empty_nn_module_stack_from_metadata_hook/sym_size_int_67: aten.sym_size.int"
            },
            {
              "key": "[metadata] pkg.torch.onnx.class_hierarchy",
              "value": "['_empty_nn_module_stack_from_metadata_hook', 'aten.sym_size.int']"
            },
            {
              "key": "[metadata] pkg.torch.onnx.fx_node",
              "value": "%sym_size_int_67 : [num_users=5] = call_function[target=torch.ops.aten.sym_size.int](args = (%past_key_values_key_cache_1, 2), kwargs = {})"
            },
            {
              "key": "[metadata] pkg.torch.onnx.name_scopes",
              "value": "['_empty_nn_module_stack_from_metadata_hook', 'sym_size_int_67']"
            },
            {
              "key": "[metadata] pkg.torch.onnx.stack_trace",
              "value": "File \"torch/fx/passes/runtime_assert.py\", line 24, in insert_deferred_runtime_asserts"
            }
          ],
          "incomingEdges": [
            {
              "sourceNodeId": "node_Shape_10",
              "sourceNodeOutputId": "0",
              "targetNodeInputId": "0"
            }
          ],
          "outputsMetadata": [
            {
              "id": "0",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "sym_size_int_67"
                },
                {
                  "key": "tensor_shape",
                  "value": "INT64[]"
                },
                {
                  "key": "param_name",
                  "value": "squeezed"
                }
              ]
            }
          ],
          "inputsMetadata": [
            {
              "id": "0",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "val_5"
                },
                {
                  "key": "tensor_shape",
                  "value": "INT64[1]"
                },
                {
                  "key": "param_name",
                  "value": "data"
                }
              ]
            }
          ],
          "style": null,
          "config": null
        },
        {
          "id": "node_Shape_12",
          "label": "Shape",
          "namespace": "main_graph/_empty_nn_module_stack_from_metadata_hook: _empty_nn_module_stack_from_metadata_hook/sym_size_int_68: aten.sym_size.int",
          "subgraphIds": [],
          "attrs": [
            {
              "key": "end",
              "value": "1"
            },
            {
              "key": "start",
              "value": "0"
            },
            {
              "key": "[metadata] namespace",
              "value": "_empty_nn_module_stack_from_metadata_hook: _empty_nn_module_stack_from_metadata_hook/sym_size_int_68: aten.sym_size.int"
            },
            {
              "key": "[metadata] pkg.torch.onnx.class_hierarchy",
              "value": "['_empty_nn_module_stack_from_metadata_hook', 'aten.sym_size.int']"
            },
            {
              "key": "[metadata] pkg.torch.onnx.fx_node",
              "value": "%sym_size_int_68 : [num_users=16] = call_function[target=torch.ops.aten.sym_size.int](args = (%past_key_values_value_cache_0, 0), kwargs = {})"
            },
            {
              "key": "[metadata] pkg.torch.onnx.name_scopes",
              "value": "['_empty_nn_module_stack_from_metadata_hook', 'sym_size_int_68']"
            },
            {
              "key": "[metadata] pkg.torch.onnx.stack_trace",
              "value": "File \"torch/fx/passes/runtime_assert.py\", line 24, in insert_deferred_runtime_asserts"
            }
          ],
          "incomingEdges": [
            {
              "sourceNodeId": "[value] past_key_values_value_cache_0",
              "sourceNodeOutputId": "0",
              "targetNodeInputId": "0"
            }
          ],
          "outputsMetadata": [
            {
              "id": "0",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "val_6"
                },
                {
                  "key": "tensor_shape",
                  "value": "INT64[1]"
                },
                {
                  "key": "param_name",
                  "value": "shape"
                }
              ]
            }
          ],
          "inputsMetadata": [
            {
              "id": "0",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "past_key_values_value_cache_0"
                },
                {
                  "key": "tensor_shape",
                  "value": "FLOAT[s34,32,s17,64]"
                },
                {
                  "key": "[metadata] pkg.torch.export.graph_signature.InputSpec.kind",
                  "value": "USER_INPUT"
                },
                {
                  "key": "[metadata] pkg.torch.export.graph_signature.InputSpec.persistent",
                  "value": "None"
                },
                {
                  "key": "param_name",
                  "value": "data"
                }
              ]
            }
          ],
          "style": null,
          "config": null
        },
        {
          "id": "node_Gather_20",
          "label": "Gather",
          "namespace": "main_graph/: transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/model.embed_tokens: torch.nn.modules.sparse.Embedding/embedding: aten.embedding.default",
          "subgraphIds": [],
          "attrs": [
            {
              "key": "axis",
              "value": "0"
            },
            {
              "key": "[metadata] namespace",
              "value": ": transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/model.embed_tokens: torch.nn.modules.sparse.Embedding/embedding: aten.embedding.default"
            },
            {
              "key": "[metadata] pkg.torch.onnx.class_hierarchy",
              "value": "['transformers.models.llama.modeling_llama.LlamaForCausalLM', 'transformers.models.llama.modeling_llama.LlamaModel', 'torch.nn.modules.sparse.Embedding', 'aten.embedding.default']"
            },
            {
              "key": "[metadata] pkg.torch.onnx.fx_node",
              "value": "%embedding : [num_users=3] = call_function[target=torch.ops.aten.embedding.default](args = (%p_lm_head_weight, %input_ids), kwargs = {})"
            },
            {
              "key": "[metadata] pkg.torch.onnx.name_scopes",
              "value": "['', 'model', 'model.embed_tokens', 'embedding']"
            },
            {
              "key": "[metadata] pkg.torch.onnx.stack_trace",
              "value": "File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 688, in forward\n    outputs: BaseModelOutputWithPast = self.model(\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 422, in forward\n    inputs_embeds = self.embed_tokens(input_ids)\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/torch/nn/modules/sparse.py\", line 190, in forward\n    return F.embedding("
            }
          ],
          "incomingEdges": [
            {
              "sourceNodeId": "[value] lm_head.weight",
              "sourceNodeOutputId": "0",
              "targetNodeInputId": "0"
            },
            {
              "sourceNodeId": "[value] input_ids",
              "sourceNodeOutputId": "0",
              "targetNodeInputId": "1"
            }
          ],
          "outputsMetadata": [
            {
              "id": "0",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "embedding"
                },
                {
                  "key": "tensor_shape",
                  "value": "FLOAT[s34,s16,2048]"
                },
                {
                  "key": "param_name",
                  "value": "output"
                }
              ]
            }
          ],
          "inputsMetadata": [
            {
              "id": "0",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "lm_head.weight"
                },
                {
                  "key": "tensor_shape",
                  "value": "FLOAT[49152,2048]"
                },
                {
                  "key": "param_name",
                  "value": "data"
                }
              ]
            },
            {
              "id": "1",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "input_ids"
                },
                {
                  "key": "tensor_shape",
                  "value": "INT64[s34,s16]"
                },
                {
                  "key": "[metadata] pkg.torch.export.graph_signature.InputSpec.kind",
                  "value": "USER_INPUT"
                },
                {
                  "key": "[metadata] pkg.torch.export.graph_signature.InputSpec.persistent",
                  "value": "None"
                },
                {
                  "key": "param_name",
                  "value": "indices"
                }
              ]
            }
          ],
          "style": null,
          "config": null
        },
        {
          "id": "node_Add_33",
          "label": "Add",
          "namespace": "main_graph/: transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/add_4: <built-in function add>",
          "subgraphIds": [],
          "attrs": [
            {
              "key": "[metadata] namespace",
              "value": ": transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/add_4: <built-in function add>"
            },
            {
              "key": "[metadata] pkg.torch.onnx.class_hierarchy",
              "value": "['transformers.models.llama.modeling_llama.LlamaForCausalLM', 'transformers.models.llama.modeling_llama.LlamaModel', '<built-in function add>']"
            },
            {
              "key": "[metadata] pkg.torch.onnx.fx_node",
              "value": "%add_4 : [num_users=7] = call_function[target=operator.add](args = (%sym_size_int_67, %sym_size_int_61), kwargs = {})"
            },
            {
              "key": "[metadata] pkg.torch.onnx.name_scopes",
              "value": "['', 'model', 'add_4']"
            },
            {
              "key": "[metadata] pkg.torch.onnx.stack_trace",
              "value": "File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 688, in forward\n    outputs: BaseModelOutputWithPast = self.model(\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 430, in forward\n    past_seen_tokens, past_seen_tokens + inputs_embeds.shape[1], device=inputs_embeds.device"
            }
          ],
          "incomingEdges": [
            {
              "sourceNodeId": "node_Squeeze_11",
              "sourceNodeOutputId": "0",
              "targetNodeInputId": "0"
            },
            {
              "sourceNodeId": "node_Squeeze_3",
              "sourceNodeOutputId": "0",
              "targetNodeInputId": "1"
            }
          ],
          "outputsMetadata": [
            {
              "id": "0",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "add_4"
                },
                {
                  "key": "tensor_shape",
                  "value": "INT64[]"
                },
                {
                  "key": "param_name",
                  "value": "C"
                }
              ]
            }
          ],
          "inputsMetadata": [
            {
              "id": "0",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "sym_size_int_67"
                },
                {
                  "key": "tensor_shape",
                  "value": "INT64[]"
                },
                {
                  "key": "param_name",
                  "value": "A"
                }
              ]
            },
            {
              "id": "1",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "sym_size_int_61"
                },
                {
                  "key": "tensor_shape",
                  "value": "INT64[]"
                },
                {
                  "key": "param_name",
                  "value": "B"
                }
              ]
            }
          ],
          "style": null,
          "config": null
        },
        {
          "id": "node_Constant_704",
          "label": "Constant",
          "namespace": "main_graph/: transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/arange: aten.arange.start",
          "subgraphIds": [],
          "attrs": [
            {
              "key": "__value",
              "value": "1"
            },
            {
              "key": "value",
              "value": "TensorProtoTensor<INT64,[]>(array(1), name='val_11')"
            }
          ],
          "incomingEdges": [],
          "outputsMetadata": [
            {
              "id": "0",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "val_11"
                },
                {
                  "key": "tensor_shape",
                  "value": "INT64[]"
                },
                {
                  "key": "param_name",
                  "value": "output"
                }
              ]
            }
          ],
          "inputsMetadata": [],
          "style": null,
          "config": null
        },
        {
          "id": "node_Range_36",
          "label": "Range",
          "namespace": "main_graph/: transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/arange: aten.arange.start",
          "subgraphIds": [],
          "attrs": [
            {
              "key": "[metadata] namespace",
              "value": ": transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/arange: aten.arange.start"
            },
            {
              "key": "[metadata] pkg.torch.onnx.class_hierarchy",
              "value": "['transformers.models.llama.modeling_llama.LlamaForCausalLM', 'transformers.models.llama.modeling_llama.LlamaModel', 'aten.arange.start']"
            },
            {
              "key": "[metadata] pkg.torch.onnx.fx_node",
              "value": "%arange : [num_users=2] = call_function[target=torch.ops.aten.arange.start](args = (%sym_size_int_67, %add_4), kwargs = {device: cuda:0, pin_memory: False})"
            },
            {
              "key": "[metadata] pkg.torch.onnx.name_scopes",
              "value": "['', 'model', 'arange']"
            },
            {
              "key": "[metadata] pkg.torch.onnx.stack_trace",
              "value": "File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 688, in forward\n    outputs: BaseModelOutputWithPast = self.model(\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 429, in forward\n    cache_position = torch.arange("
            }
          ],
          "incomingEdges": [
            {
              "sourceNodeId": "node_Squeeze_11",
              "sourceNodeOutputId": "0",
              "targetNodeInputId": "0"
            },
            {
              "sourceNodeId": "node_Add_33",
              "sourceNodeOutputId": "0",
              "targetNodeInputId": "1"
            },
            {
              "sourceNodeId": "node_Constant_704",
              "sourceNodeOutputId": "0",
              "targetNodeInputId": "2"
            }
          ],
          "outputsMetadata": [
            {
              "id": "0",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "arange"
                },
                {
                  "key": "tensor_shape",
                  "value": "INT64[s16]"
                },
                {
                  "key": "param_name",
                  "value": "output"
                }
              ]
            }
          ],
          "inputsMetadata": [
            {
              "id": "0",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "sym_size_int_67"
                },
                {
                  "key": "tensor_shape",
                  "value": "INT64[]"
                },
                {
                  "key": "param_name",
                  "value": "start"
                }
              ]
            },
            {
              "id": "1",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "add_4"
                },
                {
                  "key": "tensor_shape",
                  "value": "INT64[]"
                },
                {
                  "key": "param_name",
                  "value": "limit"
                }
              ]
            },
            {
              "id": "2",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "val_11"
                },
                {
                  "key": "tensor_shape",
                  "value": "INT64[]"
                },
                {
                  "key": "param_name",
                  "value": "delta"
                }
              ]
            }
          ],
          "style": null,
          "config": null
        },
        {
          "id": "node_Constant_706",
          "label": "Constant",
          "namespace": "main_graph/: transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/full: aten.full.default",
          "subgraphIds": [],
          "attrs": [
            {
              "key": "__value",
              "value": "-3.4028234663852886e+38"
            },
            {
              "key": "value",
              "value": "TensorProtoTensor<FLOAT,[]>(array(-3.4028235e+38, dtype=float32), name='val_14')"
            }
          ],
          "incomingEdges": [],
          "outputsMetadata": [
            {
              "id": "0",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "val_14"
                },
                {
                  "key": "tensor_shape",
                  "value": "FLOAT[]"
                },
                {
                  "key": "param_name",
                  "value": "output"
                }
              ]
            }
          ],
          "inputsMetadata": [],
          "style": null,
          "config": null
        },
        {
          "id": "node_Constant_43",
          "label": "Constant",
          "namespace": "main_graph/: transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/full: aten.full.default",
          "subgraphIds": [],
          "attrs": [
            {
              "key": "__value",
              "value": "[-1]"
            },
            {
              "key": "value",
              "value": "TensorProtoTensor<INT64,[1]>(array([-1]), name='')"
            },
            {
              "key": "[metadata] namespace",
              "value": ": transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/full: aten.full.default"
            },
            {
              "key": "[metadata] pkg.torch.onnx.class_hierarchy",
              "value": "['transformers.models.llama.modeling_llama.LlamaForCausalLM', 'transformers.models.llama.modeling_llama.LlamaModel', 'aten.full.default']"
            },
            {
              "key": "[metadata] pkg.torch.onnx.fx_node",
              "value": "%full : [num_users=1] = call_function[target=torch.ops.aten.full.default](args = ([%sym_size_int_61, %add_4], -3.4028234663852886e+38), kwargs = {dtype: torch.float32, device: cuda:0, pin_memory: False})"
            },
            {
              "key": "[metadata] pkg.torch.onnx.name_scopes",
              "value": "['', 'model', 'full']"
            },
            {
              "key": "[metadata] pkg.torch.onnx.stack_trace",
              "value": "File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 688, in forward\n    outputs: BaseModelOutputWithPast = self.model(\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 436, in forward\n    causal_mask = self._update_causal_mask("
            }
          ],
          "incomingEdges": [],
          "outputsMetadata": [
            {
              "id": "0",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "val_17"
                },
                {
                  "key": "tensor_shape",
                  "value": "INT64[1]"
                },
                {
                  "key": "param_name",
                  "value": "output"
                }
              ]
            }
          ],
          "inputsMetadata": [],
          "style": null,
          "config": null
        },
        {
          "id": "node_Reshape_44",
          "label": "Reshape",
          "namespace": "main_graph/: transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/full: aten.full.default",
          "subgraphIds": [],
          "attrs": [
            {
              "key": "allowzero",
              "value": "0"
            },
            {
              "key": "[metadata] namespace",
              "value": ": transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/full: aten.full.default"
            },
            {
              "key": "[metadata] pkg.torch.onnx.class_hierarchy",
              "value": "['transformers.models.llama.modeling_llama.LlamaForCausalLM', 'transformers.models.llama.modeling_llama.LlamaModel', 'aten.full.default']"
            },
            {
              "key": "[metadata] pkg.torch.onnx.fx_node",
              "value": "%full : [num_users=1] = call_function[target=torch.ops.aten.full.default](args = ([%sym_size_int_61, %add_4], -3.4028234663852886e+38), kwargs = {dtype: torch.float32, device: cuda:0, pin_memory: False})"
            },
            {
              "key": "[metadata] pkg.torch.onnx.name_scopes",
              "value": "['', 'model', 'full']"
            },
            {
              "key": "[metadata] pkg.torch.onnx.stack_trace",
              "value": "File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 688, in forward\n    outputs: BaseModelOutputWithPast = self.model(\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 436, in forward\n    causal_mask = self._update_causal_mask("
            }
          ],
          "incomingEdges": [
            {
              "sourceNodeId": "node_Add_33",
              "sourceNodeOutputId": "0",
              "targetNodeInputId": "0"
            },
            {
              "sourceNodeId": "node_Constant_43",
              "sourceNodeOutputId": "0",
              "targetNodeInputId": "1"
            }
          ],
          "outputsMetadata": [
            {
              "id": "0",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "val_18"
                },
                {
                  "key": "tensor_shape",
                  "value": "INT64[1]"
                },
                {
                  "key": "param_name",
                  "value": "reshaped"
                }
              ]
            }
          ],
          "inputsMetadata": [
            {
              "id": "0",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "add_4"
                },
                {
                  "key": "tensor_shape",
                  "value": "INT64[]"
                },
                {
                  "key": "param_name",
                  "value": "data"
                }
              ]
            },
            {
              "id": "1",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "val_17"
                },
                {
                  "key": "tensor_shape",
                  "value": "INT64[1]"
                },
                {
                  "key": "param_name",
                  "value": "shape"
                }
              ]
            }
          ],
          "style": null,
          "config": null
        },
        {
          "id": "node_Concat_45",
          "label": "Concat",
          "namespace": "main_graph/: transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/full: aten.full.default",
          "subgraphIds": [],
          "attrs": [
            {
              "key": "axis",
              "value": "0"
            },
            {
              "key": "[metadata] namespace",
              "value": ": transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/full: aten.full.default"
            },
            {
              "key": "[metadata] pkg.torch.onnx.class_hierarchy",
              "value": "['transformers.models.llama.modeling_llama.LlamaForCausalLM', 'transformers.models.llama.modeling_llama.LlamaModel', 'aten.full.default']"
            },
            {
              "key": "[metadata] pkg.torch.onnx.fx_node",
              "value": "%full : [num_users=1] = call_function[target=torch.ops.aten.full.default](args = ([%sym_size_int_61, %add_4], -3.4028234663852886e+38), kwargs = {dtype: torch.float32, device: cuda:0, pin_memory: False})"
            },
            {
              "key": "[metadata] pkg.torch.onnx.name_scopes",
              "value": "['', 'model', 'full']"
            },
            {
              "key": "[metadata] pkg.torch.onnx.stack_trace",
              "value": "File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 688, in forward\n    outputs: BaseModelOutputWithPast = self.model(\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 436, in forward\n    causal_mask = self._update_causal_mask("
            }
          ],
          "incomingEdges": [
            {
              "sourceNodeId": "node_Shape_2",
              "sourceNodeOutputId": "0",
              "targetNodeInputId": "0"
            },
            {
              "sourceNodeId": "node_Reshape_44",
              "sourceNodeOutputId": "0",
              "targetNodeInputId": "1"
            }
          ],
          "outputsMetadata": [
            {
              "id": "0",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "val_19"
                },
                {
                  "key": "tensor_shape",
                  "value": "INT64[2]"
                },
                {
                  "key": "param_name",
                  "value": "concat_result"
                }
              ]
            }
          ],
          "inputsMetadata": [
            {
              "id": "0",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "val_1"
                },
                {
                  "key": "tensor_shape",
                  "value": "INT64[1]"
                },
                {
                  "key": "param_name",
                  "value": "inputs"
                }
              ]
            },
            {
              "id": "1",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "val_18"
                },
                {
                  "key": "tensor_shape",
                  "value": "INT64[1]"
                },
                {
                  "key": "param_name",
                  "value": "inputs"
                }
              ]
            }
          ],
          "style": null,
          "config": null
        },
        {
          "id": "node_Expand_47",
          "label": "Expand",
          "namespace": "main_graph/: transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/full: aten.full.default",
          "subgraphIds": [],
          "attrs": [
            {
              "key": "[metadata] namespace",
              "value": ": transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/full: aten.full.default"
            },
            {
              "key": "[metadata] pkg.torch.onnx.class_hierarchy",
              "value": "['transformers.models.llama.modeling_llama.LlamaForCausalLM', 'transformers.models.llama.modeling_llama.LlamaModel', 'aten.full.default']"
            },
            {
              "key": "[metadata] pkg.torch.onnx.fx_node",
              "value": "%full : [num_users=1] = call_function[target=torch.ops.aten.full.default](args = ([%sym_size_int_61, %add_4], -3.4028234663852886e+38), kwargs = {dtype: torch.float32, device: cuda:0, pin_memory: False})"
            },
            {
              "key": "[metadata] pkg.torch.onnx.name_scopes",
              "value": "['', 'model', 'full']"
            },
            {
              "key": "[metadata] pkg.torch.onnx.stack_trace",
              "value": "File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 688, in forward\n    outputs: BaseModelOutputWithPast = self.model(\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 436, in forward\n    causal_mask = self._update_causal_mask("
            }
          ],
          "incomingEdges": [
            {
              "sourceNodeId": "node_Constant_706",
              "sourceNodeOutputId": "0",
              "targetNodeInputId": "0"
            },
            {
              "sourceNodeId": "node_Concat_45",
              "sourceNodeOutputId": "0",
              "targetNodeInputId": "1"
            }
          ],
          "outputsMetadata": [
            {
              "id": "0",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "full"
                },
                {
                  "key": "tensor_shape",
                  "value": "FLOAT[s16,s16 + s17]"
                },
                {
                  "key": "param_name",
                  "value": "output"
                }
              ]
            }
          ],
          "inputsMetadata": [
            {
              "id": "0",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "val_14"
                },
                {
                  "key": "tensor_shape",
                  "value": "FLOAT[]"
                },
                {
                  "key": "param_name",
                  "value": "input"
                }
              ]
            },
            {
              "id": "1",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "val_19"
                },
                {
                  "key": "tensor_shape",
                  "value": "INT64[2]"
                },
                {
                  "key": "param_name",
                  "value": "shape"
                }
              ]
            }
          ],
          "style": null,
          "config": null
        },
        {
          "id": "n0",
          "label": "Constant",
          "namespace": "main_graph",
          "subgraphIds": [],
          "attrs": [
            {
              "key": "__value",
              "value": "1"
            },
            {
              "key": "value_int",
              "value": "1"
            },
            {
              "key": "[metadata] namespace",
              "value": ": transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/triu: aten.triu.default"
            },
            {
              "key": "[metadata] pkg.torch.onnx.class_hierarchy",
              "value": "['transformers.models.llama.modeling_llama.LlamaForCausalLM', 'transformers.models.llama.modeling_llama.LlamaModel', 'aten.triu.default']"
            },
            {
              "key": "[metadata] pkg.torch.onnx.fx_node",
              "value": "%triu : [num_users=1] = call_function[target=torch.ops.aten.triu.default](args = (%full, 1), kwargs = {})"
            },
            {
              "key": "[metadata] pkg.torch.onnx.name_scopes",
              "value": "['', 'model', 'triu']"
            },
            {
              "key": "[metadata] pkg.torch.onnx.stack_trace",
              "value": "File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 688, in forward\n    outputs: BaseModelOutputWithPast = self.model(\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 436, in forward\n    causal_mask = self._update_causal_mask("
            }
          ],
          "incomingEdges": [],
          "outputsMetadata": [
            {
              "id": "0",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "diagonal"
                },
                {
                  "key": "tensor_shape",
                  "value": "INT64[]"
                },
                {
                  "key": "param_name",
                  "value": "output"
                }
              ]
            }
          ],
          "inputsMetadata": [],
          "style": null,
          "config": null
        },
        {
          "id": "n1",
          "label": "Trilu",
          "namespace": "main_graph/: transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/triu: aten.triu.default",
          "subgraphIds": [],
          "attrs": [
            {
              "key": "upper",
              "value": "1"
            },
            {
              "key": "[metadata] namespace",
              "value": ": transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/triu: aten.triu.default"
            },
            {
              "key": "[metadata] pkg.torch.onnx.class_hierarchy",
              "value": "['transformers.models.llama.modeling_llama.LlamaForCausalLM', 'transformers.models.llama.modeling_llama.LlamaModel', 'aten.triu.default']"
            },
            {
              "key": "[metadata] pkg.torch.onnx.fx_node",
              "value": "%triu : [num_users=1] = call_function[target=torch.ops.aten.triu.default](args = (%full, 1), kwargs = {})"
            },
            {
              "key": "[metadata] pkg.torch.onnx.name_scopes",
              "value": "['', 'model', 'triu']"
            },
            {
              "key": "[metadata] pkg.torch.onnx.stack_trace",
              "value": "File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 688, in forward\n    outputs: BaseModelOutputWithPast = self.model(\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 436, in forward\n    causal_mask = self._update_causal_mask("
            }
          ],
          "incomingEdges": [
            {
              "sourceNodeId": "node_Expand_47",
              "sourceNodeOutputId": "0",
              "targetNodeInputId": "0"
            },
            {
              "sourceNodeId": "n0",
              "sourceNodeOutputId": "0",
              "targetNodeInputId": "1"
            }
          ],
          "outputsMetadata": [
            {
              "id": "0",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "triu"
                },
                {
                  "key": "tensor_shape",
                  "value": "FLOAT[s16,s16 + s17]"
                },
                {
                  "key": "param_name",
                  "value": "output"
                }
              ]
            }
          ],
          "inputsMetadata": [
            {
              "id": "0",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "full"
                },
                {
                  "key": "tensor_shape",
                  "value": "FLOAT[s16,s16 + s17]"
                },
                {
                  "key": "param_name",
                  "value": "input"
                }
              ]
            },
            {
              "id": "1",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "diagonal"
                },
                {
                  "key": "tensor_shape",
                  "value": "INT64[]"
                },
                {
                  "key": "param_name",
                  "value": "k"
                }
              ]
            }
          ],
          "style": null,
          "config": null
        },
        {
          "id": "node_Constant_709",
          "label": "Constant",
          "namespace": "main_graph/: transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/arange_1: aten.arange.default",
          "subgraphIds": [],
          "attrs": [
            {
              "key": "__value",
              "value": "0"
            },
            {
              "key": "value",
              "value": "TensorProtoTensor<INT64,[]>(array(0), name='val_22')"
            }
          ],
          "incomingEdges": [],
          "outputsMetadata": [
            {
              "id": "0",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "val_22"
                },
                {
                  "key": "tensor_shape",
                  "value": "INT64[]"
                },
                {
                  "key": "param_name",
                  "value": "output"
                }
              ]
            }
          ],
          "inputsMetadata": [],
          "style": null,
          "config": null
        },
        {
          "id": "node_Constant_711",
          "label": "Constant",
          "namespace": "main_graph/: transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/arange_1: aten.arange.default",
          "subgraphIds": [],
          "attrs": [
            {
              "key": "__value",
              "value": "1"
            },
            {
              "key": "value",
              "value": "TensorProtoTensor<INT64,[]>(array(1), name='val_23')"
            }
          ],
          "incomingEdges": [],
          "outputsMetadata": [
            {
              "id": "0",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "val_23"
                },
                {
                  "key": "tensor_shape",
                  "value": "INT64[]"
                },
                {
                  "key": "param_name",
                  "value": "output"
                }
              ]
            }
          ],
          "inputsMetadata": [],
          "style": null,
          "config": null
        },
        {
          "id": "node_Range_52",
          "label": "Range",
          "namespace": "main_graph/: transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/arange_1: aten.arange.default",
          "subgraphIds": [],
          "attrs": [
            {
              "key": "[metadata] namespace",
              "value": ": transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/arange_1: aten.arange.default"
            },
            {
              "key": "[metadata] pkg.torch.onnx.class_hierarchy",
              "value": "['transformers.models.llama.modeling_llama.LlamaForCausalLM', 'transformers.models.llama.modeling_llama.LlamaModel', 'aten.arange.default']"
            },
            {
              "key": "[metadata] pkg.torch.onnx.fx_node",
              "value": "%arange_1 : [num_users=1] = call_function[target=torch.ops.aten.arange.default](args = (%add_4,), kwargs = {device: cuda:0, pin_memory: False})"
            },
            {
              "key": "[metadata] pkg.torch.onnx.name_scopes",
              "value": "['', 'model', 'arange_1']"
            },
            {
              "key": "[metadata] pkg.torch.onnx.stack_trace",
              "value": "File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 688, in forward\n    outputs: BaseModelOutputWithPast = self.model(\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 436, in forward\n    causal_mask = self._update_causal_mask("
            }
          ],
          "incomingEdges": [
            {
              "sourceNodeId": "node_Constant_709",
              "sourceNodeOutputId": "0",
              "targetNodeInputId": "0"
            },
            {
              "sourceNodeId": "node_Add_33",
              "sourceNodeOutputId": "0",
              "targetNodeInputId": "1"
            },
            {
              "sourceNodeId": "node_Constant_711",
              "sourceNodeOutputId": "0",
              "targetNodeInputId": "2"
            }
          ],
          "outputsMetadata": [
            {
              "id": "0",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "arange_1"
                },
                {
                  "key": "tensor_shape",
                  "value": "INT64[s16 + s17]"
                },
                {
                  "key": "param_name",
                  "value": "output"
                }
              ]
            }
          ],
          "inputsMetadata": [
            {
              "id": "0",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "val_22"
                },
                {
                  "key": "tensor_shape",
                  "value": "INT64[]"
                },
                {
                  "key": "param_name",
                  "value": "start"
                }
              ]
            },
            {
              "id": "1",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "add_4"
                },
                {
                  "key": "tensor_shape",
                  "value": "INT64[]"
                },
                {
                  "key": "param_name",
                  "value": "limit"
                }
              ]
            },
            {
              "id": "2",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "val_23"
                },
                {
                  "key": "tensor_shape",
                  "value": "INT64[]"
                },
                {
                  "key": "param_name",
                  "value": "delta"
                }
              ]
            }
          ],
          "style": null,
          "config": null
        },
        {
          "id": "node_Constant_713",
          "label": "Constant",
          "namespace": "main_graph/: transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/view: aten.view.default",
          "subgraphIds": [],
          "attrs": [
            {
              "key": "__value",
              "value": "[-1,1]"
            },
            {
              "key": "value",
              "value": "TensorProtoTensor<INT64,[2]>(array([-1,  1]), name='val_25')"
            }
          ],
          "incomingEdges": [],
          "outputsMetadata": [
            {
              "id": "0",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "val_25"
                },
                {
                  "key": "tensor_shape",
                  "value": "INT64[2]"
                },
                {
                  "key": "param_name",
                  "value": "output"
                }
              ]
            }
          ],
          "inputsMetadata": [],
          "style": null,
          "config": null
        },
        {
          "id": "node_Reshape_55",
          "label": "Reshape",
          "namespace": "main_graph/: transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/view: aten.view.default",
          "subgraphIds": [],
          "attrs": [
            {
              "key": "allowzero",
              "value": "1"
            },
            {
              "key": "[metadata] namespace",
              "value": ": transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/view: aten.view.default"
            },
            {
              "key": "[metadata] pkg.torch.onnx.class_hierarchy",
              "value": "['transformers.models.llama.modeling_llama.LlamaForCausalLM', 'transformers.models.llama.modeling_llama.LlamaModel', 'aten.view.default']"
            },
            {
              "key": "[metadata] pkg.torch.onnx.fx_node",
              "value": "%view : [num_users=1] = call_function[target=torch.ops.aten.view.default](args = (%arange, [-1, 1]), kwargs = {})"
            },
            {
              "key": "[metadata] pkg.torch.onnx.name_scopes",
              "value": "['', 'model', 'view']"
            },
            {
              "key": "[metadata] pkg.torch.onnx.stack_trace",
              "value": "File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 688, in forward\n    outputs: BaseModelOutputWithPast = self.model(\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 436, in forward\n    causal_mask = self._update_causal_mask("
            }
          ],
          "incomingEdges": [
            {
              "sourceNodeId": "node_Range_36",
              "sourceNodeOutputId": "0",
              "targetNodeInputId": "0"
            },
            {
              "sourceNodeId": "node_Constant_713",
              "sourceNodeOutputId": "0",
              "targetNodeInputId": "1"
            }
          ],
          "outputsMetadata": [
            {
              "id": "0",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "view"
                },
                {
                  "key": "tensor_shape",
                  "value": "INT64[s16,1]"
                },
                {
                  "key": "param_name",
                  "value": "reshaped"
                }
              ]
            }
          ],
          "inputsMetadata": [
            {
              "id": "0",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "arange"
                },
                {
                  "key": "tensor_shape",
                  "value": "INT64[s16]"
                },
                {
                  "key": "param_name",
                  "value": "data"
                }
              ]
            },
            {
              "id": "1",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "val_25"
                },
                {
                  "key": "tensor_shape",
                  "value": "INT64[2]"
                },
                {
                  "key": "param_name",
                  "value": "shape"
                }
              ]
            }
          ],
          "style": null,
          "config": null
        },
        {
          "id": "node_Greater_56",
          "label": "Greater",
          "namespace": "main_graph/: transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/gt: aten.gt.Tensor",
          "subgraphIds": [],
          "attrs": [
            {
              "key": "[metadata] namespace",
              "value": ": transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/gt: aten.gt.Tensor"
            },
            {
              "key": "[metadata] pkg.torch.onnx.class_hierarchy",
              "value": "['transformers.models.llama.modeling_llama.LlamaForCausalLM', 'transformers.models.llama.modeling_llama.LlamaModel', 'aten.gt.Tensor']"
            },
            {
              "key": "[metadata] pkg.torch.onnx.fx_node",
              "value": "%gt : [num_users=1] = call_function[target=torch.ops.aten.gt.Tensor](args = (%arange_1, %view), kwargs = {})"
            },
            {
              "key": "[metadata] pkg.torch.onnx.name_scopes",
              "value": "['', 'model', 'gt']"
            },
            {
              "key": "[metadata] pkg.torch.onnx.stack_trace",
              "value": "File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 688, in forward\n    outputs: BaseModelOutputWithPast = self.model(\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 436, in forward\n    causal_mask = self._update_causal_mask("
            }
          ],
          "incomingEdges": [
            {
              "sourceNodeId": "node_Range_52",
              "sourceNodeOutputId": "0",
              "targetNodeInputId": "0"
            },
            {
              "sourceNodeId": "node_Reshape_55",
              "sourceNodeOutputId": "0",
              "targetNodeInputId": "1"
            }
          ],
          "outputsMetadata": [
            {
              "id": "0",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "gt"
                },
                {
                  "key": "tensor_shape",
                  "value": "BOOL[s16,s16 + s17]"
                },
                {
                  "key": "param_name",
                  "value": "C"
                }
              ]
            }
          ],
          "inputsMetadata": [
            {
              "id": "0",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "arange_1"
                },
                {
                  "key": "tensor_shape",
                  "value": "INT64[s16 + s17]"
                },
                {
                  "key": "param_name",
                  "value": "A"
                }
              ]
            },
            {
              "id": "1",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "view"
                },
                {
                  "key": "tensor_shape",
                  "value": "INT64[s16,1]"
                },
                {
                  "key": "param_name",
                  "value": "B"
                }
              ]
            }
          ],
          "style": null,
          "config": null
        },
        {
          "id": "node_Cast_57",
          "label": "Cast",
          "namespace": "main_graph/: transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/convert_element_type_default: prims.convert_element_type.default",
          "subgraphIds": [],
          "attrs": [
            {
              "key": "to",
              "value": "FLOAT"
            },
            {
              "key": "[metadata] namespace",
              "value": ": transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/convert_element_type_default: prims.convert_element_type.default"
            },
            {
              "key": "[metadata] pkg.torch.onnx.class_hierarchy",
              "value": "['transformers.models.llama.modeling_llama.LlamaForCausalLM', 'transformers.models.llama.modeling_llama.LlamaModel', 'prims.convert_element_type.default']"
            },
            {
              "key": "[metadata] pkg.torch.onnx.fx_node",
              "value": "%convert_element_type_default : [num_users=1] = call_function[target=torch.ops.prims.convert_element_type.default](args = (%gt,), kwargs = {dtype: torch.float32})"
            },
            {
              "key": "[metadata] pkg.torch.onnx.name_scopes",
              "value": "['', 'model', 'convert_element_type_default']"
            },
            {
              "key": "[metadata] pkg.torch.onnx.stack_trace",
              "value": "File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 688, in forward\n    outputs: BaseModelOutputWithPast = self.model(\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 436, in forward\n    causal_mask = self._update_causal_mask("
            }
          ],
          "incomingEdges": [
            {
              "sourceNodeId": "node_Greater_56",
              "sourceNodeOutputId": "0",
              "targetNodeInputId": "0"
            }
          ],
          "outputsMetadata": [
            {
              "id": "0",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "convert_element_type_default"
                },
                {
                  "key": "tensor_shape",
                  "value": "FLOAT[s16,s16 + s17]"
                },
                {
                  "key": "param_name",
                  "value": "output"
                }
              ]
            }
          ],
          "inputsMetadata": [
            {
              "id": "0",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "gt"
                },
                {
                  "key": "tensor_shape",
                  "value": "BOOL[s16,s16 + s17]"
                },
                {
                  "key": "param_name",
                  "value": "input"
                }
              ]
            }
          ],
          "style": null,
          "config": null
        },
        {
          "id": "node_Mul_58",
          "label": "Mul",
          "namespace": "main_graph/: transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/mul_16: aten.mul.Tensor",
          "subgraphIds": [],
          "attrs": [
            {
              "key": "[metadata] namespace",
              "value": ": transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/mul_16: aten.mul.Tensor"
            },
            {
              "key": "[metadata] pkg.torch.onnx.class_hierarchy",
              "value": "['transformers.models.llama.modeling_llama.LlamaForCausalLM', 'transformers.models.llama.modeling_llama.LlamaModel', 'aten.mul.Tensor']"
            },
            {
              "key": "[metadata] pkg.torch.onnx.fx_node",
              "value": "%mul_16 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%triu, %convert_element_type_default), kwargs = {})"
            },
            {
              "key": "[metadata] pkg.torch.onnx.name_scopes",
              "value": "['', 'model', 'mul_16']"
            },
            {
              "key": "[metadata] pkg.torch.onnx.stack_trace",
              "value": "File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 688, in forward\n    outputs: BaseModelOutputWithPast = self.model(\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 436, in forward\n    causal_mask = self._update_causal_mask("
            }
          ],
          "incomingEdges": [
            {
              "sourceNodeId": "n1",
              "sourceNodeOutputId": "0",
              "targetNodeInputId": "0"
            },
            {
              "sourceNodeId": "node_Cast_57",
              "sourceNodeOutputId": "0",
              "targetNodeInputId": "1"
            }
          ],
          "outputsMetadata": [
            {
              "id": "0",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "mul_16"
                },
                {
                  "key": "tensor_shape",
                  "value": "FLOAT[s16,s16 + s17]"
                },
                {
                  "key": "param_name",
                  "value": "C"
                }
              ]
            }
          ],
          "inputsMetadata": [
            {
              "id": "0",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "triu"
                },
                {
                  "key": "tensor_shape",
                  "value": "FLOAT[s16,s16 + s17]"
                },
                {
                  "key": "param_name",
                  "value": "A"
                }
              ]
            },
            {
              "id": "1",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "convert_element_type_default"
                },
                {
                  "key": "tensor_shape",
                  "value": "FLOAT[s16,s16 + s17]"
                },
                {
                  "key": "param_name",
                  "value": "B"
                }
              ]
            }
          ],
          "style": null,
          "config": null
        },
        {
          "id": "node_Constant_60",
          "label": "Constant",
          "namespace": "main_graph/: transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/expand_1: aten.expand.default",
          "subgraphIds": [],
          "attrs": [
            {
              "key": "__value",
              "value": "[1]"
            },
            {
              "key": "value",
              "value": "TensorProtoTensor<INT64,[1]>(array([1]), name='')"
            },
            {
              "key": "[metadata] namespace",
              "value": ": transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/unsqueeze_4: aten.unsqueeze.default"
            },
            {
              "key": "[metadata] pkg.torch.onnx.class_hierarchy",
              "value": "['transformers.models.llama.modeling_llama.LlamaForCausalLM', 'transformers.models.llama.modeling_llama.LlamaModel', 'aten.unsqueeze.default']"
            },
            {
              "key": "[metadata] pkg.torch.onnx.fx_node",
              "value": "%unsqueeze_4 : [num_users=1] = call_function[target=torch.ops.aten.unsqueeze.default](args = (%unsqueeze_3, 1), kwargs = {})"
            },
            {
              "key": "[metadata] pkg.torch.onnx.name_scopes",
              "value": "['', 'model', 'unsqueeze_4']"
            },
            {
              "key": "[metadata] pkg.torch.onnx.stack_trace",
              "value": "File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 688, in forward\n    outputs: BaseModelOutputWithPast = self.model(\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 436, in forward\n    causal_mask = self._update_causal_mask("
            }
          ],
          "incomingEdges": [],
          "outputsMetadata": [
            {
              "id": "0",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "val_26"
                },
                {
                  "key": "tensor_shape",
                  "value": "INT64[1]"
                },
                {
                  "key": "param_name",
                  "value": "output"
                }
              ]
            }
          ],
          "inputsMetadata": [],
          "style": null,
          "config": null
        },
        {
          "id": "node_Constant_1026",
          "label": "Constant",
          "namespace": "main_graph",
          "subgraphIds": [],
          "attrs": [
            {
              "key": "__value",
              "value": "[0,1]"
            },
            {
              "key": "value",
              "value": "TensorProtoTensor<INT64,[2]>(array([0, 1]), name='val_491')"
            }
          ],
          "incomingEdges": [],
          "outputsMetadata": [
            {
              "id": "0",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "val_491"
                },
                {
                  "key": "tensor_shape",
                  "value": "INT64[2]"
                },
                {
                  "key": "param_name",
                  "value": "output"
                }
              ]
            }
          ],
          "inputsMetadata": [],
          "style": null,
          "config": null
        },
        {
          "id": "node_Unsqueeze_1027",
          "label": "Unsqueeze",
          "namespace": "main_graph",
          "subgraphIds": [],
          "attrs": [],
          "incomingEdges": [
            {
              "sourceNodeId": "node_Mul_58",
              "sourceNodeOutputId": "0",
              "targetNodeInputId": "0"
            },
            {
              "sourceNodeId": "node_Constant_1026",
              "sourceNodeOutputId": "0",
              "targetNodeInputId": "1"
            }
          ],
          "outputsMetadata": [
            {
              "id": "0",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "unsqueeze_4"
                },
                {
                  "key": "tensor_shape",
                  "value": "FLOAT[1,1,s16,s16 + s17]"
                },
                {
                  "key": "param_name",
                  "value": "expanded"
                }
              ]
            }
          ],
          "inputsMetadata": [
            {
              "id": "0",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "mul_16"
                },
                {
                  "key": "tensor_shape",
                  "value": "FLOAT[s16,s16 + s17]"
                },
                {
                  "key": "param_name",
                  "value": "data"
                }
              ]
            },
            {
              "id": "1",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "val_491"
                },
                {
                  "key": "tensor_shape",
                  "value": "INT64[2]"
                },
                {
                  "key": "param_name",
                  "value": "axes"
                }
              ]
            }
          ],
          "style": null,
          "config": null
        },
        {
          "id": "node_Constant_62",
          "label": "Constant",
          "namespace": "main_graph/: transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel",
          "subgraphIds": [],
          "attrs": [
            {
              "key": "__value",
              "value": "0"
            },
            {
              "key": "value",
              "value": "TensorProtoTensor<INT64,[]>(array(0), name='')"
            },
            {
              "key": "[metadata] namespace",
              "value": ": transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/slice_3: aten.slice.Tensor"
            },
            {
              "key": "[metadata] pkg.torch.onnx.class_hierarchy",
              "value": "['transformers.models.llama.modeling_llama.LlamaForCausalLM', 'transformers.models.llama.modeling_llama.LlamaModel', 'aten.slice.Tensor']"
            },
            {
              "key": "[metadata] pkg.torch.onnx.fx_node",
              "value": "%slice_3 : [num_users=1] = call_function[target=torch.ops.aten.slice.Tensor](args = (%unsqueeze_4, 2, 0, 9223372036854775807), kwargs = {})"
            },
            {
              "key": "[metadata] pkg.torch.onnx.name_scopes",
              "value": "['', 'model', 'slice_3']"
            },
            {
              "key": "[metadata] pkg.torch.onnx.stack_trace",
              "value": "File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 688, in forward\n    outputs: BaseModelOutputWithPast = self.model(\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 436, in forward\n    causal_mask = self._update_causal_mask("
            }
          ],
          "incomingEdges": [],
          "outputsMetadata": [
            {
              "id": "0",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "val_27"
                },
                {
                  "key": "tensor_shape",
                  "value": "INT64[]"
                },
                {
                  "key": "param_name",
                  "value": "output"
                }
              ]
            }
          ],
          "inputsMetadata": [],
          "style": null,
          "config": null
        },
        {
          "id": "node_Constant_70",
          "label": "Constant",
          "namespace": "main_graph/: transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/slice_scatter: aten.slice_scatter.default",
          "subgraphIds": [],
          "attrs": [
            {
              "key": "__value",
              "value": "2"
            },
            {
              "key": "value",
              "value": "TensorProtoTensor<INT64,[]>(array(2), name='')"
            },
            {
              "key": "[metadata] namespace",
              "value": ": transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/slice_3: aten.slice.Tensor"
            },
            {
              "key": "[metadata] pkg.torch.onnx.class_hierarchy",
              "value": "['transformers.models.llama.modeling_llama.LlamaForCausalLM', 'transformers.models.llama.modeling_llama.LlamaModel', 'aten.slice.Tensor']"
            },
            {
              "key": "[metadata] pkg.torch.onnx.fx_node",
              "value": "%slice_3 : [num_users=1] = call_function[target=torch.ops.aten.slice.Tensor](args = (%unsqueeze_4, 2, 0, 9223372036854775807), kwargs = {})"
            },
            {
              "key": "[metadata] pkg.torch.onnx.name_scopes",
              "value": "['', 'model', 'slice_3']"
            },
            {
              "key": "[metadata] pkg.torch.onnx.stack_trace",
              "value": "File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 688, in forward\n    outputs: BaseModelOutputWithPast = self.model(\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 436, in forward\n    causal_mask = self._update_causal_mask("
            }
          ],
          "incomingEdges": [],
          "outputsMetadata": [
            {
              "id": "0",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "val_35"
                },
                {
                  "key": "tensor_shape",
                  "value": "INT64[]"
                },
                {
                  "key": "param_name",
                  "value": "output"
                }
              ]
            }
          ],
          "inputsMetadata": [],
          "style": null,
          "config": null
        },
        {
          "id": "node_Constant_90",
          "label": "Constant",
          "namespace": "main_graph/: transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel",
          "subgraphIds": [],
          "attrs": [
            {
              "key": "__value",
              "value": "[-1]"
            },
            {
              "key": "value",
              "value": "TensorProtoTensor<INT64,[1]>(array([-1]), name='')"
            },
            {
              "key": "[metadata] namespace",
              "value": ": transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/expand_1: aten.expand.default"
            },
            {
              "key": "[metadata] pkg.torch.onnx.class_hierarchy",
              "value": "['transformers.models.llama.modeling_llama.LlamaForCausalLM', 'transformers.models.llama.modeling_llama.LlamaModel', 'aten.expand.default']"
            },
            {
              "key": "[metadata] pkg.torch.onnx.fx_node",
              "value": "%expand_1 : [num_users=1] = call_function[target=torch.ops.aten.expand.default](args = (%slice_4, [%sym_size_int_68, 1, -1, -1]), kwargs = {})"
            },
            {
              "key": "[metadata] pkg.torch.onnx.name_scopes",
              "value": "['', 'model', 'expand_1']"
            },
            {
              "key": "[metadata] pkg.torch.onnx.stack_trace",
              "value": "File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 688, in forward\n    outputs: BaseModelOutputWithPast = self.model(\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 436, in forward\n    causal_mask = self._update_causal_mask("
            }
          ],
          "incomingEdges": [],
          "outputsMetadata": [
            {
              "id": "0",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "val_53"
                },
                {
                  "key": "tensor_shape",
                  "value": "INT64[1]"
                },
                {
                  "key": "param_name",
                  "value": "output"
                }
              ]
            }
          ],
          "inputsMetadata": [],
          "style": null,
          "config": null
        },
        {
          "id": "node_Concat_91",
          "label": "Concat",
          "namespace": "main_graph/: transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/expand_1: aten.expand.default",
          "subgraphIds": [],
          "attrs": [
            {
              "key": "axis",
              "value": "0"
            },
            {
              "key": "[metadata] namespace",
              "value": ": transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/expand_1: aten.expand.default"
            },
            {
              "key": "[metadata] pkg.torch.onnx.class_hierarchy",
              "value": "['transformers.models.llama.modeling_llama.LlamaForCausalLM', 'transformers.models.llama.modeling_llama.LlamaModel', 'aten.expand.default']"
            },
            {
              "key": "[metadata] pkg.torch.onnx.fx_node",
              "value": "%expand_1 : [num_users=1] = call_function[target=torch.ops.aten.expand.default](args = (%slice_4, [%sym_size_int_68, 1, -1, -1]), kwargs = {})"
            },
            {
              "key": "[metadata] pkg.torch.onnx.name_scopes",
              "value": "['', 'model', 'expand_1']"
            },
            {
              "key": "[metadata] pkg.torch.onnx.stack_trace",
              "value": "File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 688, in forward\n    outputs: BaseModelOutputWithPast = self.model(\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 436, in forward\n    causal_mask = self._update_causal_mask("
            }
          ],
          "incomingEdges": [
            {
              "sourceNodeId": "node_Shape_12",
              "sourceNodeOutputId": "0",
              "targetNodeInputId": "0"
            },
            {
              "sourceNodeId": "node_Constant_60",
              "sourceNodeOutputId": "0",
              "targetNodeInputId": "1"
            },
            {
              "sourceNodeId": "node_Constant_90",
              "sourceNodeOutputId": "0",
              "targetNodeInputId": "2"
            },
            {
              "sourceNodeId": "node_Constant_90",
              "sourceNodeOutputId": "0",
              "targetNodeInputId": "3"
            }
          ],
          "outputsMetadata": [
            {
              "id": "0",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "val_54"
                },
                {
                  "key": "tensor_shape",
                  "value": "INT64[4]"
                },
                {
                  "key": "param_name",
                  "value": "concat_result"
                }
              ]
            }
          ],
          "inputsMetadata": [
            {
              "id": "0",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "val_6"
                },
                {
                  "key": "tensor_shape",
                  "value": "INT64[1]"
                },
                {
                  "key": "param_name",
                  "value": "inputs"
                }
              ]
            },
            {
              "id": "1",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "val_26"
                },
                {
                  "key": "tensor_shape",
                  "value": "INT64[1]"
                },
                {
                  "key": "param_name",
                  "value": "inputs"
                }
              ]
            },
            {
              "id": "2",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "val_53"
                },
                {
                  "key": "tensor_shape",
                  "value": "INT64[1]"
                },
                {
                  "key": "param_name",
                  "value": "inputs"
                }
              ]
            },
            {
              "id": "3",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "val_53"
                },
                {
                  "key": "tensor_shape",
                  "value": "INT64[1]"
                },
                {
                  "key": "param_name",
                  "value": "inputs"
                }
              ]
            }
          ],
          "style": null,
          "config": null
        },
        {
          "id": "node_Abs_93",
          "label": "Abs",
          "namespace": "main_graph/: transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/expand_1: aten.expand.default",
          "subgraphIds": [],
          "attrs": [
            {
              "key": "[metadata] namespace",
              "value": ": transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/expand_1: aten.expand.default"
            },
            {
              "key": "[metadata] pkg.torch.onnx.class_hierarchy",
              "value": "['transformers.models.llama.modeling_llama.LlamaForCausalLM', 'transformers.models.llama.modeling_llama.LlamaModel', 'aten.expand.default']"
            },
            {
              "key": "[metadata] pkg.torch.onnx.fx_node",
              "value": "%expand_1 : [num_users=1] = call_function[target=torch.ops.aten.expand.default](args = (%slice_4, [%sym_size_int_68, 1, -1, -1]), kwargs = {})"
            },
            {
              "key": "[metadata] pkg.torch.onnx.name_scopes",
              "value": "['', 'model', 'expand_1']"
            },
            {
              "key": "[metadata] pkg.torch.onnx.stack_trace",
              "value": "File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 688, in forward\n    outputs: BaseModelOutputWithPast = self.model(\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 436, in forward\n    causal_mask = self._update_causal_mask("
            }
          ],
          "incomingEdges": [
            {
              "sourceNodeId": "node_Concat_91",
              "sourceNodeOutputId": "0",
              "targetNodeInputId": "0"
            }
          ],
          "outputsMetadata": [
            {
              "id": "0",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "val_56"
                },
                {
                  "key": "tensor_shape",
                  "value": "INT64[4]"
                },
                {
                  "key": "param_name",
                  "value": "Y"
                }
              ]
            }
          ],
          "inputsMetadata": [
            {
              "id": "0",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "val_54"
                },
                {
                  "key": "tensor_shape",
                  "value": "INT64[4]"
                },
                {
                  "key": "param_name",
                  "value": "X"
                }
              ]
            }
          ],
          "style": null,
          "config": null
        },
        {
          "id": "node_Expand_94",
          "label": "Expand",
          "namespace": "main_graph/: transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/expand_1: aten.expand.default",
          "subgraphIds": [],
          "attrs": [
            {
              "key": "[metadata] namespace",
              "value": ": transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/expand_1: aten.expand.default"
            },
            {
              "key": "[metadata] pkg.torch.onnx.class_hierarchy",
              "value": "['transformers.models.llama.modeling_llama.LlamaForCausalLM', 'transformers.models.llama.modeling_llama.LlamaModel', 'aten.expand.default']"
            },
            {
              "key": "[metadata] pkg.torch.onnx.fx_node",
              "value": "%expand_1 : [num_users=1] = call_function[target=torch.ops.aten.expand.default](args = (%slice_4, [%sym_size_int_68, 1, -1, -1]), kwargs = {})"
            },
            {
              "key": "[metadata] pkg.torch.onnx.name_scopes",
              "value": "['', 'model', 'expand_1']"
            },
            {
              "key": "[metadata] pkg.torch.onnx.stack_trace",
              "value": "File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 688, in forward\n    outputs: BaseModelOutputWithPast = self.model(\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 436, in forward\n    causal_mask = self._update_causal_mask("
            }
          ],
          "incomingEdges": [
            {
              "sourceNodeId": "node_Unsqueeze_1027",
              "sourceNodeOutputId": "0",
              "targetNodeInputId": "0"
            },
            {
              "sourceNodeId": "node_Abs_93",
              "sourceNodeOutputId": "0",
              "targetNodeInputId": "1"
            }
          ],
          "outputsMetadata": [
            {
              "id": "0",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "expand_1"
                },
                {
                  "key": "tensor_shape",
                  "value": "FLOAT[s34,1,s16,s16 + s17]"
                },
                {
                  "key": "param_name",
                  "value": "output"
                }
              ]
            }
          ],
          "inputsMetadata": [
            {
              "id": "0",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "unsqueeze_4"
                },
                {
                  "key": "tensor_shape",
                  "value": "FLOAT[1,1,s16,s16 + s17]"
                },
                {
                  "key": "param_name",
                  "value": "input"
                }
              ]
            },
            {
              "id": "1",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "val_56"
                },
                {
                  "key": "tensor_shape",
                  "value": "INT64[4]"
                },
                {
                  "key": "param_name",
                  "value": "shape"
                }
              ]
            }
          ],
          "style": null,
          "config": null
        },
        {
          "id": "node_Constant_105",
          "label": "Constant",
          "namespace": "main_graph/: transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel",
          "subgraphIds": [],
          "attrs": [
            {
              "key": "__value",
              "value": "1"
            },
            {
              "key": "value",
              "value": "TensorProtoTensor<INT64,[]>(array(1), name='')"
            },
            {
              "key": "[metadata] namespace",
              "value": ": transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/slice_6: aten.slice.Tensor"
            },
            {
              "key": "[metadata] pkg.torch.onnx.class_hierarchy",
              "value": "['transformers.models.llama.modeling_llama.LlamaForCausalLM', 'transformers.models.llama.modeling_llama.LlamaModel', 'aten.slice.Tensor']"
            },
            {
              "key": "[metadata] pkg.torch.onnx.fx_node",
              "value": "%slice_6 : [num_users=1] = call_function[target=torch.ops.aten.slice.Tensor](args = (%slice_5, 1), kwargs = {})"
            },
            {
              "key": "[metadata] pkg.torch.onnx.name_scopes",
              "value": "['', 'model', 'slice_6']"
            },
            {
              "key": "[metadata] pkg.torch.onnx.stack_trace",
              "value": "File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 688, in forward\n    outputs: BaseModelOutputWithPast = self.model(\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 436, in forward\n    causal_mask = self._update_causal_mask("
            }
          ],
          "incomingEdges": [],
          "outputsMetadata": [
            {
              "id": "0",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "val_65"
                },
                {
                  "key": "tensor_shape",
                  "value": "INT64[]"
                },
                {
                  "key": "param_name",
                  "value": "output"
                }
              ]
            }
          ],
          "inputsMetadata": [],
          "style": null,
          "config": null
        },
        {
          "id": "node_Constant_118",
          "label": "Constant",
          "namespace": "main_graph",
          "subgraphIds": [],
          "attrs": [
            {
              "key": "__value",
              "value": "[0]"
            },
            {
              "key": "value_ints",
              "value": "[0]"
            },
            {
              "key": "[metadata] namespace",
              "value": ": transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/slice_8: aten.slice.Tensor"
            },
            {
              "key": "[metadata] pkg.torch.onnx.class_hierarchy",
              "value": "['transformers.models.llama.modeling_llama.LlamaForCausalLM', 'transformers.models.llama.modeling_llama.LlamaModel', 'aten.slice.Tensor']"
            },
            {
              "key": "[metadata] pkg.torch.onnx.fx_node",
              "value": "%slice_8 : [num_users=1] = call_function[target=torch.ops.aten.slice.Tensor](args = (%slice_7, 3, None, %add_4), kwargs = {})"
            },
            {
              "key": "[metadata] pkg.torch.onnx.name_scopes",
              "value": "['', 'model', 'slice_8']"
            },
            {
              "key": "[metadata] pkg.torch.onnx.stack_trace",
              "value": "File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 688, in forward\n    outputs: BaseModelOutputWithPast = self.model(\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 436, in forward\n    causal_mask = self._update_causal_mask("
            }
          ],
          "incomingEdges": [],
          "outputsMetadata": [
            {
              "id": "0",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "val_76"
                },
                {
                  "key": "tensor_shape",
                  "value": "INT64[1]"
                },
                {
                  "key": "param_name",
                  "value": "output"
                }
              ]
            }
          ],
          "inputsMetadata": [],
          "style": null,
          "config": null
        },
        {
          "id": "node_Constant_120",
          "label": "Constant",
          "namespace": "main_graph/: transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/slice_8: aten.slice.Tensor",
          "subgraphIds": [],
          "attrs": [
            {
              "key": "__value",
              "value": "[-1]"
            },
            {
              "key": "value_ints",
              "value": "[-1]"
            },
            {
              "key": "[metadata] namespace",
              "value": ": transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/slice_8: aten.slice.Tensor"
            },
            {
              "key": "[metadata] pkg.torch.onnx.class_hierarchy",
              "value": "['transformers.models.llama.modeling_llama.LlamaForCausalLM', 'transformers.models.llama.modeling_llama.LlamaModel', 'aten.slice.Tensor']"
            },
            {
              "key": "[metadata] pkg.torch.onnx.fx_node",
              "value": "%slice_8 : [num_users=1] = call_function[target=torch.ops.aten.slice.Tensor](args = (%slice_7, 3, None, %add_4), kwargs = {})"
            },
            {
              "key": "[metadata] pkg.torch.onnx.name_scopes",
              "value": "['', 'model', 'slice_8']"
            },
            {
              "key": "[metadata] pkg.torch.onnx.stack_trace",
              "value": "File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 688, in forward\n    outputs: BaseModelOutputWithPast = self.model(\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 436, in forward\n    causal_mask = self._update_causal_mask("
            }
          ],
          "incomingEdges": [],
          "outputsMetadata": [
            {
              "id": "0",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "val_78"
                },
                {
                  "key": "tensor_shape",
                  "value": "INT64[1]"
                },
                {
                  "key": "param_name",
                  "value": "output"
                }
              ]
            }
          ],
          "inputsMetadata": [],
          "style": null,
          "config": null
        },
        {
          "id": "node_Reshape_121",
          "label": "Reshape",
          "namespace": "main_graph/: transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/slice_8: aten.slice.Tensor",
          "subgraphIds": [],
          "attrs": [
            {
              "key": "allowzero",
              "value": "0"
            },
            {
              "key": "[metadata] namespace",
              "value": ": transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/slice_8: aten.slice.Tensor"
            },
            {
              "key": "[metadata] pkg.torch.onnx.class_hierarchy",
              "value": "['transformers.models.llama.modeling_llama.LlamaForCausalLM', 'transformers.models.llama.modeling_llama.LlamaModel', 'aten.slice.Tensor']"
            },
            {
              "key": "[metadata] pkg.torch.onnx.fx_node",
              "value": "%slice_8 : [num_users=1] = call_function[target=torch.ops.aten.slice.Tensor](args = (%slice_7, 3, None, %add_4), kwargs = {})"
            },
            {
              "key": "[metadata] pkg.torch.onnx.name_scopes",
              "value": "['', 'model', 'slice_8']"
            },
            {
              "key": "[metadata] pkg.torch.onnx.stack_trace",
              "value": "File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 688, in forward\n    outputs: BaseModelOutputWithPast = self.model(\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 436, in forward\n    causal_mask = self._update_causal_mask("
            }
          ],
          "incomingEdges": [
            {
              "sourceNodeId": "node_Add_33",
              "sourceNodeOutputId": "0",
              "targetNodeInputId": "0"
            },
            {
              "sourceNodeId": "node_Constant_120",
              "sourceNodeOutputId": "0",
              "targetNodeInputId": "1"
            }
          ],
          "outputsMetadata": [
            {
              "id": "0",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "val_79"
                },
                {
                  "key": "tensor_shape",
                  "value": "INT64[1]"
                },
                {
                  "key": "param_name",
                  "value": "reshaped"
                }
              ]
            }
          ],
          "inputsMetadata": [
            {
              "id": "0",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "add_4"
                },
                {
                  "key": "tensor_shape",
                  "value": "INT64[]"
                },
                {
                  "key": "param_name",
                  "value": "data"
                }
              ]
            },
            {
              "id": "1",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "val_78"
                },
                {
                  "key": "tensor_shape",
                  "value": "INT64[1]"
                },
                {
                  "key": "param_name",
                  "value": "shape"
                }
              ]
            }
          ],
          "style": null,
          "config": null
        },
        {
          "id": "node_Constant_745",
          "label": "Constant",
          "namespace": "main_graph/: transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/slice_8: aten.slice.Tensor",
          "subgraphIds": [],
          "attrs": [
            {
              "key": "__value",
              "value": "[3]"
            },
            {
              "key": "value",
              "value": "TensorProtoTensor<INT64,[1]>(array([3]), name='val_82')"
            }
          ],
          "incomingEdges": [],
          "outputsMetadata": [
            {
              "id": "0",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "val_82"
                },
                {
                  "key": "tensor_shape",
                  "value": "INT64[1]"
                },
                {
                  "key": "param_name",
                  "value": "output"
                }
              ]
            }
          ],
          "inputsMetadata": [],
          "style": null,
          "config": null
        },
        {
          "id": "node_Constant_125",
          "label": "Constant",
          "namespace": "main_graph/: transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel",
          "subgraphIds": [],
          "attrs": [
            {
              "key": "__value",
              "value": "[1]"
            },
            {
              "key": "value_ints",
              "value": "[1]"
            },
            {
              "key": "[metadata] namespace",
              "value": ": transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/slice_8: aten.slice.Tensor"
            },
            {
              "key": "[metadata] pkg.torch.onnx.class_hierarchy",
              "value": "['transformers.models.llama.modeling_llama.LlamaForCausalLM', 'transformers.models.llama.modeling_llama.LlamaModel', 'aten.slice.Tensor']"
            },
            {
              "key": "[metadata] pkg.torch.onnx.fx_node",
              "value": "%slice_8 : [num_users=1] = call_function[target=torch.ops.aten.slice.Tensor](args = (%slice_7, 3, None, %add_4), kwargs = {})"
            },
            {
              "key": "[metadata] pkg.torch.onnx.name_scopes",
              "value": "['', 'model', 'slice_8']"
            },
            {
              "key": "[metadata] pkg.torch.onnx.stack_trace",
              "value": "File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 688, in forward\n    outputs: BaseModelOutputWithPast = self.model(\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 436, in forward\n    causal_mask = self._update_causal_mask("
            }
          ],
          "incomingEdges": [],
          "outputsMetadata": [
            {
              "id": "0",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "val_83"
                },
                {
                  "key": "tensor_shape",
                  "value": "INT64[1]"
                },
                {
                  "key": "param_name",
                  "value": "output"
                }
              ]
            }
          ],
          "inputsMetadata": [],
          "style": null,
          "config": null
        },
        {
          "id": "node_Slice_126",
          "label": "Slice",
          "namespace": "main_graph/: transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/slice_8: aten.slice.Tensor",
          "subgraphIds": [],
          "attrs": [
            {
              "key": "[metadata] namespace",
              "value": ": transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/slice_8: aten.slice.Tensor"
            },
            {
              "key": "[metadata] pkg.torch.onnx.class_hierarchy",
              "value": "['transformers.models.llama.modeling_llama.LlamaForCausalLM', 'transformers.models.llama.modeling_llama.LlamaModel', 'aten.slice.Tensor']"
            },
            {
              "key": "[metadata] pkg.torch.onnx.fx_node",
              "value": "%slice_8 : [num_users=1] = call_function[target=torch.ops.aten.slice.Tensor](args = (%slice_7, 3, None, %add_4), kwargs = {})"
            },
            {
              "key": "[metadata] pkg.torch.onnx.name_scopes",
              "value": "['', 'model', 'slice_8']"
            },
            {
              "key": "[metadata] pkg.torch.onnx.stack_trace",
              "value": "File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 688, in forward\n    outputs: BaseModelOutputWithPast = self.model(\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 436, in forward\n    causal_mask = self._update_causal_mask("
            }
          ],
          "incomingEdges": [
            {
              "sourceNodeId": "node_Expand_94",
              "sourceNodeOutputId": "0",
              "targetNodeInputId": "0"
            },
            {
              "sourceNodeId": "node_Constant_118",
              "sourceNodeOutputId": "0",
              "targetNodeInputId": "1"
            },
            {
              "sourceNodeId": "node_Reshape_121",
              "sourceNodeOutputId": "0",
              "targetNodeInputId": "2"
            },
            {
              "sourceNodeId": "node_Constant_745",
              "sourceNodeOutputId": "0",
              "targetNodeInputId": "3"
            },
            {
              "sourceNodeId": "node_Constant_125",
              "sourceNodeOutputId": "0",
              "targetNodeInputId": "4"
            }
          ],
          "outputsMetadata": [
            {
              "id": "0",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "slice_8"
                },
                {
                  "key": "tensor_shape",
                  "value": "FLOAT[s34,1,s16,s16 + s17]"
                },
                {
                  "key": "param_name",
                  "value": "output"
                }
              ]
            }
          ],
          "inputsMetadata": [
            {
              "id": "0",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "expand_1"
                },
                {
                  "key": "tensor_shape",
                  "value": "FLOAT[s34,1,s16,s16 + s17]"
                },
                {
                  "key": "param_name",
                  "value": "data"
                }
              ]
            },
            {
              "id": "1",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "val_76"
                },
                {
                  "key": "tensor_shape",
                  "value": "INT64[1]"
                },
                {
                  "key": "param_name",
                  "value": "starts"
                }
              ]
            },
            {
              "id": "2",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "val_79"
                },
                {
                  "key": "tensor_shape",
                  "value": "INT64[1]"
                },
                {
                  "key": "param_name",
                  "value": "ends"
                }
              ]
            },
            {
              "id": "3",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "val_82"
                },
                {
                  "key": "tensor_shape",
                  "value": "INT64[1]"
                },
                {
                  "key": "param_name",
                  "value": "axes"
                }
              ]
            },
            {
              "id": "4",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "val_83"
                },
                {
                  "key": "tensor_shape",
                  "value": "INT64[1]"
                },
                {
                  "key": "param_name",
                  "value": "steps"
                }
              ]
            }
          ],
          "style": null,
          "config": null
        },
        {
          "id": "node_Constant_1028",
          "label": "Constant",
          "namespace": "main_graph",
          "subgraphIds": [],
          "attrs": [
            {
              "key": "__value",
              "value": "[1,2]"
            },
            {
              "key": "value",
              "value": "TensorProtoTensor<INT64,[2]>(array([1, 2]), name='val_492')"
            }
          ],
          "incomingEdges": [],
          "outputsMetadata": [
            {
              "id": "0",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "val_492"
                },
                {
                  "key": "tensor_shape",
                  "value": "INT64[2]"
                },
                {
                  "key": "param_name",
                  "value": "output"
                }
              ]
            }
          ],
          "inputsMetadata": [],
          "style": null,
          "config": null
        },
        {
          "id": "node_Unsqueeze_1029",
          "label": "Unsqueeze",
          "namespace": "main_graph",
          "subgraphIds": [],
          "attrs": [],
          "incomingEdges": [
            {
              "sourceNodeId": "[value] attention_mask",
              "sourceNodeOutputId": "0",
              "targetNodeInputId": "0"
            },
            {
              "sourceNodeId": "node_Constant_1028",
              "sourceNodeOutputId": "0",
              "targetNodeInputId": "1"
            }
          ],
          "outputsMetadata": [
            {
              "id": "0",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "unsqueeze_6"
                },
                {
                  "key": "tensor_shape",
                  "value": "INT64[s34,1,1,s16 + s17]"
                },
                {
                  "key": "param_name",
                  "value": "expanded"
                }
              ]
            }
          ],
          "inputsMetadata": [
            {
              "id": "0",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "attention_mask"
                },
                {
                  "key": "tensor_shape",
                  "value": "INT64[s34,s16 + s17]"
                },
                {
                  "key": "[metadata] pkg.torch.export.graph_signature.InputSpec.kind",
                  "value": "USER_INPUT"
                },
                {
                  "key": "[metadata] pkg.torch.export.graph_signature.InputSpec.persistent",
                  "value": "None"
                },
                {
                  "key": "param_name",
                  "value": "data"
                }
              ]
            },
            {
              "id": "1",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "val_492"
                },
                {
                  "key": "tensor_shape",
                  "value": "INT64[2]"
                },
                {
                  "key": "param_name",
                  "value": "axes"
                }
              ]
            }
          ],
          "style": null,
          "config": null
        },
        {
          "id": "node_Cast_152",
          "label": "Cast",
          "namespace": "main_graph/: transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/convert_element_type_default_1: prims.convert_element_type.default",
          "subgraphIds": [],
          "attrs": [
            {
              "key": "to",
              "value": "FLOAT"
            },
            {
              "key": "[metadata] namespace",
              "value": ": transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/convert_element_type_default_1: prims.convert_element_type.default"
            },
            {
              "key": "[metadata] pkg.torch.onnx.class_hierarchy",
              "value": "['transformers.models.llama.modeling_llama.LlamaForCausalLM', 'transformers.models.llama.modeling_llama.LlamaModel', 'prims.convert_element_type.default']"
            },
            {
              "key": "[metadata] pkg.torch.onnx.fx_node",
              "value": "%convert_element_type_default_1 : [num_users=1] = call_function[target=torch.ops.prims.convert_element_type.default](args = (%slice_10,), kwargs = {dtype: torch.float32})"
            },
            {
              "key": "[metadata] pkg.torch.onnx.name_scopes",
              "value": "['', 'model', 'convert_element_type_default_1']"
            },
            {
              "key": "[metadata] pkg.torch.onnx.stack_trace",
              "value": "File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 688, in forward\n    outputs: BaseModelOutputWithPast = self.model(\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 436, in forward\n    causal_mask = self._update_causal_mask("
            }
          ],
          "incomingEdges": [
            {
              "sourceNodeId": "node_Unsqueeze_1029",
              "sourceNodeOutputId": "0",
              "targetNodeInputId": "0"
            }
          ],
          "outputsMetadata": [
            {
              "id": "0",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "convert_element_type_default_1"
                },
                {
                  "key": "tensor_shape",
                  "value": "FLOAT[s34,1,1,s16 + s17]"
                },
                {
                  "key": "param_name",
                  "value": "output"
                }
              ]
            }
          ],
          "inputsMetadata": [
            {
              "id": "0",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "unsqueeze_6"
                },
                {
                  "key": "tensor_shape",
                  "value": "INT64[s34,1,1,s16 + s17]"
                },
                {
                  "key": "param_name",
                  "value": "input"
                }
              ]
            }
          ],
          "style": null,
          "config": null
        },
        {
          "id": "node_Add_153",
          "label": "Add",
          "namespace": "main_graph/: transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/add_89: aten.add.Tensor",
          "subgraphIds": [],
          "attrs": [
            {
              "key": "[metadata] namespace",
              "value": ": transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/add_89: aten.add.Tensor"
            },
            {
              "key": "[metadata] pkg.torch.onnx.class_hierarchy",
              "value": "['transformers.models.llama.modeling_llama.LlamaForCausalLM', 'transformers.models.llama.modeling_llama.LlamaModel', 'aten.add.Tensor']"
            },
            {
              "key": "[metadata] pkg.torch.onnx.fx_node",
              "value": "%add_89 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%slice_8, %convert_element_type_default_1), kwargs = {})"
            },
            {
              "key": "[metadata] pkg.torch.onnx.name_scopes",
              "value": "['', 'model', 'add_89']"
            },
            {
              "key": "[metadata] pkg.torch.onnx.stack_trace",
              "value": "File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 688, in forward\n    outputs: BaseModelOutputWithPast = self.model(\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 436, in forward\n    causal_mask = self._update_causal_mask("
            }
          ],
          "incomingEdges": [
            {
              "sourceNodeId": "node_Slice_126",
              "sourceNodeOutputId": "0",
              "targetNodeInputId": "0"
            },
            {
              "sourceNodeId": "node_Cast_152",
              "sourceNodeOutputId": "0",
              "targetNodeInputId": "1"
            }
          ],
          "outputsMetadata": [
            {
              "id": "0",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "add_89"
                },
                {
                  "key": "tensor_shape",
                  "value": "FLOAT[s34,1,s16,s16 + s17]"
                },
                {
                  "key": "param_name",
                  "value": "C"
                }
              ]
            }
          ],
          "inputsMetadata": [
            {
              "id": "0",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "slice_8"
                },
                {
                  "key": "tensor_shape",
                  "value": "FLOAT[s34,1,s16,s16 + s17]"
                },
                {
                  "key": "param_name",
                  "value": "A"
                }
              ]
            },
            {
              "id": "1",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "convert_element_type_default_1"
                },
                {
                  "key": "tensor_shape",
                  "value": "FLOAT[s34,1,1,s16 + s17]"
                },
                {
                  "key": "param_name",
                  "value": "B"
                }
              ]
            }
          ],
          "style": null,
          "config": null
        },
        {
          "id": "node_Constant_764",
          "label": "Constant",
          "namespace": "main_graph/: transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/eq_67: aten.eq.Tensor",
          "subgraphIds": [],
          "attrs": [
            {
              "key": "__value",
              "value": "0.0"
            },
            {
              "key": "value",
              "value": "TensorProtoTensor<FLOAT,[]>(array(0., dtype=float32), name='scalar_tensor_default')"
            }
          ],
          "incomingEdges": [],
          "outputsMetadata": [
            {
              "id": "0",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "scalar_tensor_default"
                },
                {
                  "key": "tensor_shape",
                  "value": "FLOAT[]"
                },
                {
                  "key": "param_name",
                  "value": "output"
                }
              ]
            }
          ],
          "inputsMetadata": [],
          "style": null,
          "config": null
        },
        {
          "id": "node_Equal_155",
          "label": "Equal",
          "namespace": "main_graph/: transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/eq_67: aten.eq.Tensor",
          "subgraphIds": [],
          "attrs": [
            {
              "key": "[metadata] namespace",
              "value": ": transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/eq_67: aten.eq.Tensor"
            },
            {
              "key": "[metadata] pkg.torch.onnx.class_hierarchy",
              "value": "['transformers.models.llama.modeling_llama.LlamaForCausalLM', 'transformers.models.llama.modeling_llama.LlamaModel', 'aten.eq.Tensor']"
            },
            {
              "key": "[metadata] pkg.torch.onnx.fx_node",
              "value": "%eq_67 : [num_users=1] = call_function[target=torch.ops.aten.eq.Tensor](args = (%add_89, %scalar_tensor_default), kwargs = {})"
            },
            {
              "key": "[metadata] pkg.torch.onnx.name_scopes",
              "value": "['', 'model', 'eq_67']"
            },
            {
              "key": "[metadata] pkg.torch.onnx.stack_trace",
              "value": "File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 688, in forward\n    outputs: BaseModelOutputWithPast = self.model(\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 436, in forward\n    causal_mask = self._update_causal_mask("
            }
          ],
          "incomingEdges": [
            {
              "sourceNodeId": "node_Add_153",
              "sourceNodeOutputId": "0",
              "targetNodeInputId": "0"
            },
            {
              "sourceNodeId": "node_Constant_764",
              "sourceNodeOutputId": "0",
              "targetNodeInputId": "1"
            }
          ],
          "outputsMetadata": [
            {
              "id": "0",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "eq_67"
                },
                {
                  "key": "tensor_shape",
                  "value": "BOOL[s34,1,s16,s16 + s17]"
                },
                {
                  "key": "param_name",
                  "value": "C"
                }
              ]
            }
          ],
          "inputsMetadata": [
            {
              "id": "0",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "add_89"
                },
                {
                  "key": "tensor_shape",
                  "value": "FLOAT[s34,1,s16,s16 + s17]"
                },
                {
                  "key": "param_name",
                  "value": "A"
                }
              ]
            },
            {
              "id": "1",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "scalar_tensor_default"
                },
                {
                  "key": "tensor_shape",
                  "value": "FLOAT[]"
                },
                {
                  "key": "param_name",
                  "value": "B"
                }
              ]
            }
          ],
          "style": null,
          "config": null
        },
        {
          "id": "node_Constant_777",
          "label": "Constant",
          "namespace": "main_graph/: transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/slice_14: aten.slice.Tensor",
          "subgraphIds": [],
          "attrs": [
            {
              "key": "__value",
              "value": "[3]"
            },
            {
              "key": "value",
              "value": "TensorProtoTensor<INT64,[1]>(array([3]), name='val_129')"
            }
          ],
          "incomingEdges": [],
          "outputsMetadata": [
            {
              "id": "0",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "val_129"
                },
                {
                  "key": "tensor_shape",
                  "value": "INT64[1]"
                },
                {
                  "key": "param_name",
                  "value": "output"
                }
              ]
            }
          ],
          "inputsMetadata": [],
          "style": null,
          "config": null
        },
        {
          "id": "node_Slice_185",
          "label": "Slice",
          "namespace": "main_graph/: transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/slice_14: aten.slice.Tensor",
          "subgraphIds": [],
          "attrs": [
            {
              "key": "[metadata] namespace",
              "value": ": transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/slice_14: aten.slice.Tensor"
            },
            {
              "key": "[metadata] pkg.torch.onnx.class_hierarchy",
              "value": "['transformers.models.llama.modeling_llama.LlamaForCausalLM', 'transformers.models.llama.modeling_llama.LlamaModel', 'aten.slice.Tensor']"
            },
            {
              "key": "[metadata] pkg.torch.onnx.fx_node",
              "value": "%slice_14 : [num_users=1] = call_function[target=torch.ops.aten.slice.Tensor](args = (%slice_13, 3, None, %add_4), kwargs = {})"
            },
            {
              "key": "[metadata] pkg.torch.onnx.name_scopes",
              "value": "['', 'model', 'slice_14']"
            },
            {
              "key": "[metadata] pkg.torch.onnx.stack_trace",
              "value": "File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 688, in forward\n    outputs: BaseModelOutputWithPast = self.model(\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 436, in forward\n    causal_mask = self._update_causal_mask("
            }
          ],
          "incomingEdges": [
            {
              "sourceNodeId": "node_Expand_94",
              "sourceNodeOutputId": "0",
              "targetNodeInputId": "0"
            },
            {
              "sourceNodeId": "node_Constant_118",
              "sourceNodeOutputId": "0",
              "targetNodeInputId": "1"
            },
            {
              "sourceNodeId": "node_Reshape_121",
              "sourceNodeOutputId": "0",
              "targetNodeInputId": "2"
            },
            {
              "sourceNodeId": "node_Constant_777",
              "sourceNodeOutputId": "0",
              "targetNodeInputId": "3"
            },
            {
              "sourceNodeId": "node_Constant_125",
              "sourceNodeOutputId": "0",
              "targetNodeInputId": "4"
            }
          ],
          "outputsMetadata": [
            {
              "id": "0",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "slice_14"
                },
                {
                  "key": "tensor_shape",
                  "value": "FLOAT[s34,1,s16,s16 + s17]"
                },
                {
                  "key": "param_name",
                  "value": "output"
                }
              ]
            }
          ],
          "inputsMetadata": [
            {
              "id": "0",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "expand_1"
                },
                {
                  "key": "tensor_shape",
                  "value": "FLOAT[s34,1,s16,s16 + s17]"
                },
                {
                  "key": "param_name",
                  "value": "data"
                }
              ]
            },
            {
              "id": "1",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "val_76"
                },
                {
                  "key": "tensor_shape",
                  "value": "INT64[1]"
                },
                {
                  "key": "param_name",
                  "value": "starts"
                }
              ]
            },
            {
              "id": "2",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "val_79"
                },
                {
                  "key": "tensor_shape",
                  "value": "INT64[1]"
                },
                {
                  "key": "param_name",
                  "value": "ends"
                }
              ]
            },
            {
              "id": "3",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "val_129"
                },
                {
                  "key": "tensor_shape",
                  "value": "INT64[1]"
                },
                {
                  "key": "param_name",
                  "value": "axes"
                }
              ]
            },
            {
              "id": "4",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "val_83"
                },
                {
                  "key": "tensor_shape",
                  "value": "INT64[1]"
                },
                {
                  "key": "param_name",
                  "value": "steps"
                }
              ]
            }
          ],
          "style": null,
          "config": null
        },
        {
          "id": "node_Constant_779",
          "label": "Constant",
          "namespace": "main_graph/: transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/masked_fill: aten.masked_fill.Scalar",
          "subgraphIds": [],
          "attrs": [
            {
              "key": "__value",
              "value": "-3.4028234663852886e+38"
            },
            {
              "key": "value",
              "value": "TensorProtoTensor<FLOAT,[]>(array(-3.4028235e+38, dtype=float32), name='val_131')"
            }
          ],
          "incomingEdges": [],
          "outputsMetadata": [
            {
              "id": "0",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "val_131"
                },
                {
                  "key": "tensor_shape",
                  "value": "FLOAT[]"
                },
                {
                  "key": "param_name",
                  "value": "output"
                }
              ]
            }
          ],
          "inputsMetadata": [],
          "style": null,
          "config": null
        },
        {
          "id": "node_Where_187",
          "label": "Where",
          "namespace": "main_graph/: transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/masked_fill: aten.masked_fill.Scalar",
          "subgraphIds": [],
          "attrs": [
            {
              "key": "[metadata] namespace",
              "value": ": transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/masked_fill: aten.masked_fill.Scalar"
            },
            {
              "key": "[metadata] pkg.torch.onnx.class_hierarchy",
              "value": "['transformers.models.llama.modeling_llama.LlamaForCausalLM', 'transformers.models.llama.modeling_llama.LlamaModel', 'aten.masked_fill.Scalar']"
            },
            {
              "key": "[metadata] pkg.torch.onnx.fx_node",
              "value": "%masked_fill : [num_users=1] = call_function[target=torch.ops.aten.masked_fill.Scalar](args = (%slice_14, %eq_67, -3.4028234663852886e+38), kwargs = {})"
            },
            {
              "key": "[metadata] pkg.torch.onnx.name_scopes",
              "value": "['', 'model', 'masked_fill']"
            },
            {
              "key": "[metadata] pkg.torch.onnx.stack_trace",
              "value": "File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 688, in forward\n    outputs: BaseModelOutputWithPast = self.model(\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 436, in forward\n    causal_mask = self._update_causal_mask("
            }
          ],
          "incomingEdges": [
            {
              "sourceNodeId": "node_Equal_155",
              "sourceNodeOutputId": "0",
              "targetNodeInputId": "0"
            },
            {
              "sourceNodeId": "node_Constant_779",
              "sourceNodeOutputId": "0",
              "targetNodeInputId": "1"
            },
            {
              "sourceNodeId": "node_Slice_185",
              "sourceNodeOutputId": "0",
              "targetNodeInputId": "2"
            }
          ],
          "outputsMetadata": [
            {
              "id": "0",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "masked_fill"
                },
                {
                  "key": "tensor_shape",
                  "value": "FLOAT[s34,1,s16,s16 + s17]"
                },
                {
                  "key": "param_name",
                  "value": "output"
                }
              ]
            }
          ],
          "inputsMetadata": [
            {
              "id": "0",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "eq_67"
                },
                {
                  "key": "tensor_shape",
                  "value": "BOOL[s34,1,s16,s16 + s17]"
                },
                {
                  "key": "param_name",
                  "value": "condition"
                }
              ]
            },
            {
              "id": "1",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "val_131"
                },
                {
                  "key": "tensor_shape",
                  "value": "FLOAT[]"
                },
                {
                  "key": "param_name",
                  "value": "X"
                }
              ]
            },
            {
              "id": "2",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "slice_14"
                },
                {
                  "key": "tensor_shape",
                  "value": "FLOAT[s34,1,s16,s16 + s17]"
                },
                {
                  "key": "param_name",
                  "value": "Y"
                }
              ]
            }
          ],
          "style": null,
          "config": null
        },
        {
          "id": "node_Shape_245",
          "label": "Shape",
          "namespace": "main_graph/: transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/slice_scatter: aten.slice_scatter.default",
          "subgraphIds": [],
          "attrs": [
            {
              "key": "start",
              "value": "0"
            },
            {
              "key": "[metadata] namespace",
              "value": ": transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/slice_scatter: aten.slice_scatter.default"
            },
            {
              "key": "[metadata] pkg.torch.onnx.class_hierarchy",
              "value": "['transformers.models.llama.modeling_llama.LlamaForCausalLM', 'transformers.models.llama.modeling_llama.LlamaModel', 'aten.slice_scatter.default']"
            },
            {
              "key": "[metadata] pkg.torch.onnx.fx_node",
              "value": "%slice_scatter : [num_users=1] = call_function[target=torch.ops.aten.slice_scatter.default](args = (%slice_19, %copy, 2, 0, 9223372036854775807), kwargs = {})"
            },
            {
              "key": "[metadata] pkg.torch.onnx.name_scopes",
              "value": "['', 'model', 'slice_scatter']"
            },
            {
              "key": "[metadata] pkg.torch.onnx.stack_trace",
              "value": "File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 688, in forward\n    outputs: BaseModelOutputWithPast = self.model(\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 436, in forward\n    causal_mask = self._update_causal_mask("
            }
          ],
          "incomingEdges": [
            {
              "sourceNodeId": "node_Expand_94",
              "sourceNodeOutputId": "0",
              "targetNodeInputId": "0"
            }
          ],
          "outputsMetadata": [
            {
              "id": "0",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "val_183"
                },
                {
                  "key": "tensor_shape",
                  "value": "INT64[4]"
                },
                {
                  "key": "param_name",
                  "value": "shape"
                }
              ]
            }
          ],
          "inputsMetadata": [
            {
              "id": "0",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "expand_1"
                },
                {
                  "key": "tensor_shape",
                  "value": "FLOAT[s34,1,s16,s16 + s17]"
                },
                {
                  "key": "param_name",
                  "value": "data"
                }
              ]
            }
          ],
          "style": null,
          "config": null
        },
        {
          "id": "node_Gather_246",
          "label": "Gather",
          "namespace": "main_graph/: transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/slice_scatter: aten.slice_scatter.default",
          "subgraphIds": [],
          "attrs": [
            {
              "key": "axis",
              "value": "0"
            },
            {
              "key": "[metadata] namespace",
              "value": ": transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/slice_scatter: aten.slice_scatter.default"
            },
            {
              "key": "[metadata] pkg.torch.onnx.class_hierarchy",
              "value": "['transformers.models.llama.modeling_llama.LlamaForCausalLM', 'transformers.models.llama.modeling_llama.LlamaModel', 'aten.slice_scatter.default']"
            },
            {
              "key": "[metadata] pkg.torch.onnx.fx_node",
              "value": "%slice_scatter : [num_users=1] = call_function[target=torch.ops.aten.slice_scatter.default](args = (%slice_19, %copy, 2, 0, 9223372036854775807), kwargs = {})"
            },
            {
              "key": "[metadata] pkg.torch.onnx.name_scopes",
              "value": "['', 'model', 'slice_scatter']"
            },
            {
              "key": "[metadata] pkg.torch.onnx.stack_trace",
              "value": "File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 688, in forward\n    outputs: BaseModelOutputWithPast = self.model(\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 436, in forward\n    causal_mask = self._update_causal_mask("
            }
          ],
          "incomingEdges": [
            {
              "sourceNodeId": "node_Shape_245",
              "sourceNodeOutputId": "0",
              "targetNodeInputId": "0"
            },
            {
              "sourceNodeId": "node_Constant_70",
              "sourceNodeOutputId": "0",
              "targetNodeInputId": "1"
            }
          ],
          "outputsMetadata": [
            {
              "id": "0",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "val_184"
                },
                {
                  "key": "tensor_shape",
                  "value": "INT64[]"
                },
                {
                  "key": "param_name",
                  "value": "output"
                }
              ]
            }
          ],
          "inputsMetadata": [
            {
              "id": "0",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "val_183"
                },
                {
                  "key": "tensor_shape",
                  "value": "INT64[4]"
                },
                {
                  "key": "param_name",
                  "value": "data"
                }
              ]
            },
            {
              "id": "1",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "val_35"
                },
                {
                  "key": "tensor_shape",
                  "value": "INT64[]"
                },
                {
                  "key": "param_name",
                  "value": "indices"
                }
              ]
            }
          ],
          "style": null,
          "config": null
        },
        {
          "id": "node_Range_247",
          "label": "Range",
          "namespace": "main_graph/: transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/slice_scatter: aten.slice_scatter.default",
          "subgraphIds": [],
          "attrs": [
            {
              "key": "[metadata] namespace",
              "value": ": transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/slice_scatter: aten.slice_scatter.default"
            },
            {
              "key": "[metadata] pkg.torch.onnx.class_hierarchy",
              "value": "['transformers.models.llama.modeling_llama.LlamaForCausalLM', 'transformers.models.llama.modeling_llama.LlamaModel', 'aten.slice_scatter.default']"
            },
            {
              "key": "[metadata] pkg.torch.onnx.fx_node",
              "value": "%slice_scatter : [num_users=1] = call_function[target=torch.ops.aten.slice_scatter.default](args = (%slice_19, %copy, 2, 0, 9223372036854775807), kwargs = {})"
            },
            {
              "key": "[metadata] pkg.torch.onnx.name_scopes",
              "value": "['', 'model', 'slice_scatter']"
            },
            {
              "key": "[metadata] pkg.torch.onnx.stack_trace",
              "value": "File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 688, in forward\n    outputs: BaseModelOutputWithPast = self.model(\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 436, in forward\n    causal_mask = self._update_causal_mask("
            }
          ],
          "incomingEdges": [
            {
              "sourceNodeId": "node_Constant_62",
              "sourceNodeOutputId": "0",
              "targetNodeInputId": "0"
            },
            {
              "sourceNodeId": "node_Gather_246",
              "sourceNodeOutputId": "0",
              "targetNodeInputId": "1"
            },
            {
              "sourceNodeId": "node_Constant_105",
              "sourceNodeOutputId": "0",
              "targetNodeInputId": "2"
            }
          ],
          "outputsMetadata": [
            {
              "id": "0",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "val_185"
                },
                {
                  "key": "tensor_shape",
                  "value": "INT64[unk__16]"
                },
                {
                  "key": "param_name",
                  "value": "output"
                }
              ]
            }
          ],
          "inputsMetadata": [
            {
              "id": "0",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "val_27"
                },
                {
                  "key": "tensor_shape",
                  "value": "INT64[]"
                },
                {
                  "key": "param_name",
                  "value": "start"
                }
              ]
            },
            {
              "id": "1",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "val_184"
                },
                {
                  "key": "tensor_shape",
                  "value": "INT64[]"
                },
                {
                  "key": "param_name",
                  "value": "limit"
                }
              ]
            },
            {
              "id": "2",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "val_65"
                },
                {
                  "key": "tensor_shape",
                  "value": "INT64[]"
                },
                {
                  "key": "param_name",
                  "value": "delta"
                }
              ]
            }
          ],
          "style": null,
          "config": null
        },
        {
          "id": "node_Unsqueeze_252",
          "label": "Unsqueeze",
          "namespace": "main_graph/: transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/slice_scatter: aten.slice_scatter.default",
          "subgraphIds": [],
          "attrs": [
            {
              "key": "[metadata] namespace",
              "value": ": transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/slice_scatter: aten.slice_scatter.default"
            },
            {
              "key": "[metadata] pkg.torch.onnx.class_hierarchy",
              "value": "['transformers.models.llama.modeling_llama.LlamaForCausalLM', 'transformers.models.llama.modeling_llama.LlamaModel', 'aten.slice_scatter.default']"
            },
            {
              "key": "[metadata] pkg.torch.onnx.fx_node",
              "value": "%slice_scatter : [num_users=1] = call_function[target=torch.ops.aten.slice_scatter.default](args = (%slice_19, %copy, 2, 0, 9223372036854775807), kwargs = {})"
            },
            {
              "key": "[metadata] pkg.torch.onnx.name_scopes",
              "value": "['', 'model', 'slice_scatter']"
            },
            {
              "key": "[metadata] pkg.torch.onnx.stack_trace",
              "value": "File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 688, in forward\n    outputs: BaseModelOutputWithPast = self.model(\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 436, in forward\n    causal_mask = self._update_causal_mask("
            }
          ],
          "incomingEdges": [
            {
              "sourceNodeId": "node_Range_247",
              "sourceNodeOutputId": "0",
              "targetNodeInputId": "0"
            },
            {
              "sourceNodeId": "node_Constant_90",
              "sourceNodeOutputId": "0",
              "targetNodeInputId": "1"
            }
          ],
          "outputsMetadata": [
            {
              "id": "0",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "val_190"
                },
                {
                  "key": "tensor_shape",
                  "value": "INT64[unk__16,1]"
                },
                {
                  "key": "param_name",
                  "value": "expanded"
                }
              ]
            }
          ],
          "inputsMetadata": [
            {
              "id": "0",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "val_185"
                },
                {
                  "key": "tensor_shape",
                  "value": "INT64[unk__16]"
                },
                {
                  "key": "param_name",
                  "value": "data"
                }
              ]
            },
            {
              "id": "1",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "val_53"
                },
                {
                  "key": "tensor_shape",
                  "value": "INT64[1]"
                },
                {
                  "key": "param_name",
                  "value": "axes"
                }
              ]
            }
          ],
          "style": null,
          "config": null
        },
        {
          "id": "node_Transpose_253",
          "label": "Transpose",
          "namespace": "main_graph/: transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/slice_scatter: aten.slice_scatter.default",
          "subgraphIds": [],
          "attrs": [
            {
              "key": "perm",
              "value": "[2, 1, 0, 3]"
            },
            {
              "key": "[metadata] namespace",
              "value": ": transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/slice_scatter: aten.slice_scatter.default"
            },
            {
              "key": "[metadata] pkg.torch.onnx.class_hierarchy",
              "value": "['transformers.models.llama.modeling_llama.LlamaForCausalLM', 'transformers.models.llama.modeling_llama.LlamaModel', 'aten.slice_scatter.default']"
            },
            {
              "key": "[metadata] pkg.torch.onnx.fx_node",
              "value": "%slice_scatter : [num_users=1] = call_function[target=torch.ops.aten.slice_scatter.default](args = (%slice_19, %copy, 2, 0, 9223372036854775807), kwargs = {})"
            },
            {
              "key": "[metadata] pkg.torch.onnx.name_scopes",
              "value": "['', 'model', 'slice_scatter']"
            },
            {
              "key": "[metadata] pkg.torch.onnx.stack_trace",
              "value": "File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 688, in forward\n    outputs: BaseModelOutputWithPast = self.model(\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 436, in forward\n    causal_mask = self._update_causal_mask("
            }
          ],
          "incomingEdges": [
            {
              "sourceNodeId": "node_Where_187",
              "sourceNodeOutputId": "0",
              "targetNodeInputId": "0"
            }
          ],
          "outputsMetadata": [
            {
              "id": "0",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "val_191"
                },
                {
                  "key": "tensor_shape",
                  "value": "FLOAT[s16,1,s34,s16 + s17]"
                },
                {
                  "key": "param_name",
                  "value": "transposed"
                }
              ]
            }
          ],
          "inputsMetadata": [
            {
              "id": "0",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "masked_fill"
                },
                {
                  "key": "tensor_shape",
                  "value": "FLOAT[s34,1,s16,s16 + s17]"
                },
                {
                  "key": "param_name",
                  "value": "data"
                }
              ]
            }
          ],
          "style": null,
          "config": null
        },
        {
          "id": "node_Transpose_254",
          "label": "Transpose",
          "namespace": "main_graph/: transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/slice_scatter: aten.slice_scatter.default",
          "subgraphIds": [],
          "attrs": [
            {
              "key": "perm",
              "value": "[2, 1, 0, 3]"
            },
            {
              "key": "[metadata] namespace",
              "value": ": transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/slice_scatter: aten.slice_scatter.default"
            },
            {
              "key": "[metadata] pkg.torch.onnx.class_hierarchy",
              "value": "['transformers.models.llama.modeling_llama.LlamaForCausalLM', 'transformers.models.llama.modeling_llama.LlamaModel', 'aten.slice_scatter.default']"
            },
            {
              "key": "[metadata] pkg.torch.onnx.fx_node",
              "value": "%slice_scatter : [num_users=1] = call_function[target=torch.ops.aten.slice_scatter.default](args = (%slice_19, %copy, 2, 0, 9223372036854775807), kwargs = {})"
            },
            {
              "key": "[metadata] pkg.torch.onnx.name_scopes",
              "value": "['', 'model', 'slice_scatter']"
            },
            {
              "key": "[metadata] pkg.torch.onnx.stack_trace",
              "value": "File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 688, in forward\n    outputs: BaseModelOutputWithPast = self.model(\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 436, in forward\n    causal_mask = self._update_causal_mask("
            }
          ],
          "incomingEdges": [
            {
              "sourceNodeId": "node_Expand_94",
              "sourceNodeOutputId": "0",
              "targetNodeInputId": "0"
            }
          ],
          "outputsMetadata": [
            {
              "id": "0",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "val_192"
                },
                {
                  "key": "tensor_shape",
                  "value": "FLOAT[s16,1,s34,s16 + s17]"
                },
                {
                  "key": "param_name",
                  "value": "transposed"
                }
              ]
            }
          ],
          "inputsMetadata": [
            {
              "id": "0",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "expand_1"
                },
                {
                  "key": "tensor_shape",
                  "value": "FLOAT[s34,1,s16,s16 + s17]"
                },
                {
                  "key": "param_name",
                  "value": "data"
                }
              ]
            }
          ],
          "style": null,
          "config": null
        },
        {
          "id": "node_ScatterND_255",
          "label": "ScatterND",
          "namespace": "main_graph/: transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/slice_scatter: aten.slice_scatter.default",
          "subgraphIds": [],
          "attrs": [
            {
              "key": "reduction",
              "value": "none"
            },
            {
              "key": "[metadata] namespace",
              "value": ": transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/slice_scatter: aten.slice_scatter.default"
            },
            {
              "key": "[metadata] pkg.torch.onnx.class_hierarchy",
              "value": "['transformers.models.llama.modeling_llama.LlamaForCausalLM', 'transformers.models.llama.modeling_llama.LlamaModel', 'aten.slice_scatter.default']"
            },
            {
              "key": "[metadata] pkg.torch.onnx.fx_node",
              "value": "%slice_scatter : [num_users=1] = call_function[target=torch.ops.aten.slice_scatter.default](args = (%slice_19, %copy, 2, 0, 9223372036854775807), kwargs = {})"
            },
            {
              "key": "[metadata] pkg.torch.onnx.name_scopes",
              "value": "['', 'model', 'slice_scatter']"
            },
            {
              "key": "[metadata] pkg.torch.onnx.stack_trace",
              "value": "File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 688, in forward\n    outputs: BaseModelOutputWithPast = self.model(\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 436, in forward\n    causal_mask = self._update_causal_mask("
            }
          ],
          "incomingEdges": [
            {
              "sourceNodeId": "node_Transpose_254",
              "sourceNodeOutputId": "0",
              "targetNodeInputId": "0"
            },
            {
              "sourceNodeId": "node_Unsqueeze_252",
              "sourceNodeOutputId": "0",
              "targetNodeInputId": "1"
            },
            {
              "sourceNodeId": "node_Transpose_253",
              "sourceNodeOutputId": "0",
              "targetNodeInputId": "2"
            }
          ],
          "outputsMetadata": [
            {
              "id": "0",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "val_193"
                },
                {
                  "key": "tensor_shape",
                  "value": "FLOAT[s16,1,s34,s16 + s17]"
                },
                {
                  "key": "param_name",
                  "value": "output"
                }
              ]
            }
          ],
          "inputsMetadata": [
            {
              "id": "0",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "val_192"
                },
                {
                  "key": "tensor_shape",
                  "value": "FLOAT[s16,1,s34,s16 + s17]"
                },
                {
                  "key": "param_name",
                  "value": "data"
                }
              ]
            },
            {
              "id": "1",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "val_190"
                },
                {
                  "key": "tensor_shape",
                  "value": "INT64[unk__16,1]"
                },
                {
                  "key": "param_name",
                  "value": "indices"
                }
              ]
            },
            {
              "id": "2",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "val_191"
                },
                {
                  "key": "tensor_shape",
                  "value": "FLOAT[s16,1,s34,s16 + s17]"
                },
                {
                  "key": "param_name",
                  "value": "updates"
                }
              ]
            }
          ],
          "style": null,
          "config": null
        },
        {
          "id": "node_Gather_259",
          "label": "Gather",
          "namespace": "main_graph/: transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/slice_scatter_1: aten.slice_scatter.default",
          "subgraphIds": [],
          "attrs": [
            {
              "key": "axis",
              "value": "0"
            },
            {
              "key": "[metadata] namespace",
              "value": ": transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/slice_scatter_1: aten.slice_scatter.default"
            },
            {
              "key": "[metadata] pkg.torch.onnx.class_hierarchy",
              "value": "['transformers.models.llama.modeling_llama.LlamaForCausalLM', 'transformers.models.llama.modeling_llama.LlamaModel', 'aten.slice_scatter.default']"
            },
            {
              "key": "[metadata] pkg.torch.onnx.fx_node",
              "value": "%slice_scatter_1 : [num_users=1] = call_function[target=torch.ops.aten.slice_scatter.default](args = (%slice_18, %slice_scatter, 1, 0, 9223372036854775807), kwargs = {})"
            },
            {
              "key": "[metadata] pkg.torch.onnx.name_scopes",
              "value": "['', 'model', 'slice_scatter_1']"
            },
            {
              "key": "[metadata] pkg.torch.onnx.stack_trace",
              "value": "File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 688, in forward\n    outputs: BaseModelOutputWithPast = self.model(\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 436, in forward\n    causal_mask = self._update_causal_mask("
            }
          ],
          "incomingEdges": [
            {
              "sourceNodeId": "node_Shape_245",
              "sourceNodeOutputId": "0",
              "targetNodeInputId": "0"
            },
            {
              "sourceNodeId": "node_Constant_105",
              "sourceNodeOutputId": "0",
              "targetNodeInputId": "1"
            }
          ],
          "outputsMetadata": [
            {
              "id": "0",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "val_196"
                },
                {
                  "key": "tensor_shape",
                  "value": "INT64[]"
                },
                {
                  "key": "param_name",
                  "value": "output"
                }
              ]
            }
          ],
          "inputsMetadata": [
            {
              "id": "0",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "val_183"
                },
                {
                  "key": "tensor_shape",
                  "value": "INT64[4]"
                },
                {
                  "key": "param_name",
                  "value": "data"
                }
              ]
            },
            {
              "id": "1",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "val_65"
                },
                {
                  "key": "tensor_shape",
                  "value": "INT64[]"
                },
                {
                  "key": "param_name",
                  "value": "indices"
                }
              ]
            }
          ],
          "style": null,
          "config": null
        },
        {
          "id": "node_Range_260",
          "label": "Range",
          "namespace": "main_graph/: transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/slice_scatter_1: aten.slice_scatter.default",
          "subgraphIds": [],
          "attrs": [
            {
              "key": "[metadata] namespace",
              "value": ": transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/slice_scatter_1: aten.slice_scatter.default"
            },
            {
              "key": "[metadata] pkg.torch.onnx.class_hierarchy",
              "value": "['transformers.models.llama.modeling_llama.LlamaForCausalLM', 'transformers.models.llama.modeling_llama.LlamaModel', 'aten.slice_scatter.default']"
            },
            {
              "key": "[metadata] pkg.torch.onnx.fx_node",
              "value": "%slice_scatter_1 : [num_users=1] = call_function[target=torch.ops.aten.slice_scatter.default](args = (%slice_18, %slice_scatter, 1, 0, 9223372036854775807), kwargs = {})"
            },
            {
              "key": "[metadata] pkg.torch.onnx.name_scopes",
              "value": "['', 'model', 'slice_scatter_1']"
            },
            {
              "key": "[metadata] pkg.torch.onnx.stack_trace",
              "value": "File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 688, in forward\n    outputs: BaseModelOutputWithPast = self.model(\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 436, in forward\n    causal_mask = self._update_causal_mask("
            }
          ],
          "incomingEdges": [
            {
              "sourceNodeId": "node_Constant_62",
              "sourceNodeOutputId": "0",
              "targetNodeInputId": "0"
            },
            {
              "sourceNodeId": "node_Gather_259",
              "sourceNodeOutputId": "0",
              "targetNodeInputId": "1"
            },
            {
              "sourceNodeId": "node_Constant_105",
              "sourceNodeOutputId": "0",
              "targetNodeInputId": "2"
            }
          ],
          "outputsMetadata": [
            {
              "id": "0",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "val_197"
                },
                {
                  "key": "tensor_shape",
                  "value": "INT64[unk__17]"
                },
                {
                  "key": "param_name",
                  "value": "output"
                }
              ]
            }
          ],
          "inputsMetadata": [
            {
              "id": "0",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "val_27"
                },
                {
                  "key": "tensor_shape",
                  "value": "INT64[]"
                },
                {
                  "key": "param_name",
                  "value": "start"
                }
              ]
            },
            {
              "id": "1",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "val_196"
                },
                {
                  "key": "tensor_shape",
                  "value": "INT64[]"
                },
                {
                  "key": "param_name",
                  "value": "limit"
                }
              ]
            },
            {
              "id": "2",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "val_65"
                },
                {
                  "key": "tensor_shape",
                  "value": "INT64[]"
                },
                {
                  "key": "param_name",
                  "value": "delta"
                }
              ]
            }
          ],
          "style": null,
          "config": null
        },
        {
          "id": "node_Unsqueeze_265",
          "label": "Unsqueeze",
          "namespace": "main_graph/: transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/slice_scatter_1: aten.slice_scatter.default",
          "subgraphIds": [],
          "attrs": [
            {
              "key": "[metadata] namespace",
              "value": ": transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/slice_scatter_1: aten.slice_scatter.default"
            },
            {
              "key": "[metadata] pkg.torch.onnx.class_hierarchy",
              "value": "['transformers.models.llama.modeling_llama.LlamaForCausalLM', 'transformers.models.llama.modeling_llama.LlamaModel', 'aten.slice_scatter.default']"
            },
            {
              "key": "[metadata] pkg.torch.onnx.fx_node",
              "value": "%slice_scatter_1 : [num_users=1] = call_function[target=torch.ops.aten.slice_scatter.default](args = (%slice_18, %slice_scatter, 1, 0, 9223372036854775807), kwargs = {})"
            },
            {
              "key": "[metadata] pkg.torch.onnx.name_scopes",
              "value": "['', 'model', 'slice_scatter_1']"
            },
            {
              "key": "[metadata] pkg.torch.onnx.stack_trace",
              "value": "File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 688, in forward\n    outputs: BaseModelOutputWithPast = self.model(\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 436, in forward\n    causal_mask = self._update_causal_mask("
            }
          ],
          "incomingEdges": [
            {
              "sourceNodeId": "node_Range_260",
              "sourceNodeOutputId": "0",
              "targetNodeInputId": "0"
            },
            {
              "sourceNodeId": "node_Constant_90",
              "sourceNodeOutputId": "0",
              "targetNodeInputId": "1"
            }
          ],
          "outputsMetadata": [
            {
              "id": "0",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "val_202"
                },
                {
                  "key": "tensor_shape",
                  "value": "INT64[unk__17,1]"
                },
                {
                  "key": "param_name",
                  "value": "expanded"
                }
              ]
            }
          ],
          "inputsMetadata": [
            {
              "id": "0",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "val_197"
                },
                {
                  "key": "tensor_shape",
                  "value": "INT64[unk__17]"
                },
                {
                  "key": "param_name",
                  "value": "data"
                }
              ]
            },
            {
              "id": "1",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "val_53"
                },
                {
                  "key": "tensor_shape",
                  "value": "INT64[1]"
                },
                {
                  "key": "param_name",
                  "value": "axes"
                }
              ]
            }
          ],
          "style": null,
          "config": null
        },
        {
          "id": "node_Transpose_1025",
          "label": "Transpose",
          "namespace": "main_graph",
          "subgraphIds": [],
          "attrs": [
            {
              "key": "perm",
              "value": "[1, 2, 0, 3]"
            }
          ],
          "incomingEdges": [
            {
              "sourceNodeId": "node_ScatterND_255",
              "sourceNodeOutputId": "0",
              "targetNodeInputId": "0"
            }
          ],
          "outputsMetadata": [
            {
              "id": "0",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "val_203"
                },
                {
                  "key": "tensor_shape",
                  "value": "FLOAT[1,s34,s16,s16 + s17]"
                },
                {
                  "key": "param_name",
                  "value": "transposed"
                }
              ]
            }
          ],
          "inputsMetadata": [
            {
              "id": "0",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "val_193"
                },
                {
                  "key": "tensor_shape",
                  "value": "FLOAT[s16,1,s34,s16 + s17]"
                },
                {
                  "key": "param_name",
                  "value": "data"
                }
              ]
            }
          ],
          "style": null,
          "config": null
        },
        {
          "id": "node_Transpose_267",
          "label": "Transpose",
          "namespace": "main_graph/: transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/slice_scatter_1: aten.slice_scatter.default",
          "subgraphIds": [],
          "attrs": [
            {
              "key": "perm",
              "value": "[1, 0, 2, 3]"
            },
            {
              "key": "[metadata] namespace",
              "value": ": transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/slice_scatter_1: aten.slice_scatter.default"
            },
            {
              "key": "[metadata] pkg.torch.onnx.class_hierarchy",
              "value": "['transformers.models.llama.modeling_llama.LlamaForCausalLM', 'transformers.models.llama.modeling_llama.LlamaModel', 'aten.slice_scatter.default']"
            },
            {
              "key": "[metadata] pkg.torch.onnx.fx_node",
              "value": "%slice_scatter_1 : [num_users=1] = call_function[target=torch.ops.aten.slice_scatter.default](args = (%slice_18, %slice_scatter, 1, 0, 9223372036854775807), kwargs = {})"
            },
            {
              "key": "[metadata] pkg.torch.onnx.name_scopes",
              "value": "['', 'model', 'slice_scatter_1']"
            },
            {
              "key": "[metadata] pkg.torch.onnx.stack_trace",
              "value": "File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 688, in forward\n    outputs: BaseModelOutputWithPast = self.model(\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 436, in forward\n    causal_mask = self._update_causal_mask("
            }
          ],
          "incomingEdges": [
            {
              "sourceNodeId": "node_Expand_94",
              "sourceNodeOutputId": "0",
              "targetNodeInputId": "0"
            }
          ],
          "outputsMetadata": [
            {
              "id": "0",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "val_204"
                },
                {
                  "key": "tensor_shape",
                  "value": "FLOAT[1,s34,s16,s16 + s17]"
                },
                {
                  "key": "param_name",
                  "value": "transposed"
                }
              ]
            }
          ],
          "inputsMetadata": [
            {
              "id": "0",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "expand_1"
                },
                {
                  "key": "tensor_shape",
                  "value": "FLOAT[s34,1,s16,s16 + s17]"
                },
                {
                  "key": "param_name",
                  "value": "data"
                }
              ]
            }
          ],
          "style": null,
          "config": null
        },
        {
          "id": "node_ScatterND_268",
          "label": "ScatterND",
          "namespace": "main_graph/: transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/slice_scatter_1: aten.slice_scatter.default",
          "subgraphIds": [],
          "attrs": [
            {
              "key": "reduction",
              "value": "none"
            },
            {
              "key": "[metadata] namespace",
              "value": ": transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/slice_scatter_1: aten.slice_scatter.default"
            },
            {
              "key": "[metadata] pkg.torch.onnx.class_hierarchy",
              "value": "['transformers.models.llama.modeling_llama.LlamaForCausalLM', 'transformers.models.llama.modeling_llama.LlamaModel', 'aten.slice_scatter.default']"
            },
            {
              "key": "[metadata] pkg.torch.onnx.fx_node",
              "value": "%slice_scatter_1 : [num_users=1] = call_function[target=torch.ops.aten.slice_scatter.default](args = (%slice_18, %slice_scatter, 1, 0, 9223372036854775807), kwargs = {})"
            },
            {
              "key": "[metadata] pkg.torch.onnx.name_scopes",
              "value": "['', 'model', 'slice_scatter_1']"
            },
            {
              "key": "[metadata] pkg.torch.onnx.stack_trace",
              "value": "File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 688, in forward\n    outputs: BaseModelOutputWithPast = self.model(\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 436, in forward\n    causal_mask = self._update_causal_mask("
            }
          ],
          "incomingEdges": [
            {
              "sourceNodeId": "node_Transpose_267",
              "sourceNodeOutputId": "0",
              "targetNodeInputId": "0"
            },
            {
              "sourceNodeId": "node_Unsqueeze_265",
              "sourceNodeOutputId": "0",
              "targetNodeInputId": "1"
            },
            {
              "sourceNodeId": "node_Transpose_1025",
              "sourceNodeOutputId": "0",
              "targetNodeInputId": "2"
            }
          ],
          "outputsMetadata": [
            {
              "id": "0",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "val_205"
                },
                {
                  "key": "tensor_shape",
                  "value": "FLOAT[1,s34,s16,s16 + s17]"
                },
                {
                  "key": "param_name",
                  "value": "output"
                }
              ]
            }
          ],
          "inputsMetadata": [
            {
              "id": "0",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "val_204"
                },
                {
                  "key": "tensor_shape",
                  "value": "FLOAT[1,s34,s16,s16 + s17]"
                },
                {
                  "key": "param_name",
                  "value": "data"
                }
              ]
            },
            {
              "id": "1",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "val_202"
                },
                {
                  "key": "tensor_shape",
                  "value": "INT64[unk__17,1]"
                },
                {
                  "key": "param_name",
                  "value": "indices"
                }
              ]
            },
            {
              "id": "2",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "val_203"
                },
                {
                  "key": "tensor_shape",
                  "value": "FLOAT[1,s34,s16,s16 + s17]"
                },
                {
                  "key": "param_name",
                  "value": "updates"
                }
              ]
            }
          ],
          "style": null,
          "config": null
        },
        {
          "id": "node_Transpose_269",
          "label": "Transpose",
          "namespace": "main_graph/: transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/slice_scatter_1: aten.slice_scatter.default",
          "subgraphIds": [],
          "attrs": [
            {
              "key": "perm",
              "value": "[1, 0, 2, 3]"
            },
            {
              "key": "[metadata] namespace",
              "value": ": transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/slice_scatter_1: aten.slice_scatter.default"
            },
            {
              "key": "[metadata] pkg.torch.onnx.class_hierarchy",
              "value": "['transformers.models.llama.modeling_llama.LlamaForCausalLM', 'transformers.models.llama.modeling_llama.LlamaModel', 'aten.slice_scatter.default']"
            },
            {
              "key": "[metadata] pkg.torch.onnx.fx_node",
              "value": "%slice_scatter_1 : [num_users=1] = call_function[target=torch.ops.aten.slice_scatter.default](args = (%slice_18, %slice_scatter, 1, 0, 9223372036854775807), kwargs = {})"
            },
            {
              "key": "[metadata] pkg.torch.onnx.name_scopes",
              "value": "['', 'model', 'slice_scatter_1']"
            },
            {
              "key": "[metadata] pkg.torch.onnx.stack_trace",
              "value": "File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 688, in forward\n    outputs: BaseModelOutputWithPast = self.model(\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 436, in forward\n    causal_mask = self._update_causal_mask("
            }
          ],
          "incomingEdges": [
            {
              "sourceNodeId": "node_ScatterND_268",
              "sourceNodeOutputId": "0",
              "targetNodeInputId": "0"
            }
          ],
          "outputsMetadata": [
            {
              "id": "0",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "slice_scatter_1"
                },
                {
                  "key": "tensor_shape",
                  "value": "FLOAT[s34,1,s16,s16 + s17]"
                },
                {
                  "key": "param_name",
                  "value": "transposed"
                }
              ]
            }
          ],
          "inputsMetadata": [
            {
              "id": "0",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "val_205"
                },
                {
                  "key": "tensor_shape",
                  "value": "FLOAT[1,s34,s16,s16 + s17]"
                },
                {
                  "key": "param_name",
                  "value": "data"
                }
              ]
            }
          ],
          "style": null,
          "config": null
        },
        {
          "id": "node_Gather_272",
          "label": "Gather",
          "namespace": "main_graph/: transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/slice_scatter_2: aten.slice_scatter.default",
          "subgraphIds": [],
          "attrs": [
            {
              "key": "axis",
              "value": "0"
            },
            {
              "key": "[metadata] namespace",
              "value": ": transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/slice_scatter_2: aten.slice_scatter.default"
            },
            {
              "key": "[metadata] pkg.torch.onnx.class_hierarchy",
              "value": "['transformers.models.llama.modeling_llama.LlamaForCausalLM', 'transformers.models.llama.modeling_llama.LlamaModel', 'aten.slice_scatter.default']"
            },
            {
              "key": "[metadata] pkg.torch.onnx.fx_node",
              "value": "%slice_scatter_2 : [num_users=2] = call_function[target=torch.ops.aten.slice_scatter.default](args = (%clone, %slice_scatter_1, 0, 0, 9223372036854775807), kwargs = {})"
            },
            {
              "key": "[metadata] pkg.torch.onnx.name_scopes",
              "value": "['', 'model', 'slice_scatter_2']"
            },
            {
              "key": "[metadata] pkg.torch.onnx.stack_trace",
              "value": "File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 688, in forward\n    outputs: BaseModelOutputWithPast = self.model(\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 436, in forward\n    causal_mask = self._update_causal_mask("
            }
          ],
          "incomingEdges": [
            {
              "sourceNodeId": "node_Shape_245",
              "sourceNodeOutputId": "0",
              "targetNodeInputId": "0"
            },
            {
              "sourceNodeId": "node_Constant_62",
              "sourceNodeOutputId": "0",
              "targetNodeInputId": "1"
            }
          ],
          "outputsMetadata": [
            {
              "id": "0",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "val_208"
                },
                {
                  "key": "tensor_shape",
                  "value": "INT64[]"
                },
                {
                  "key": "param_name",
                  "value": "output"
                }
              ]
            }
          ],
          "inputsMetadata": [
            {
              "id": "0",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "val_183"
                },
                {
                  "key": "tensor_shape",
                  "value": "INT64[4]"
                },
                {
                  "key": "param_name",
                  "value": "data"
                }
              ]
            },
            {
              "id": "1",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "val_27"
                },
                {
                  "key": "tensor_shape",
                  "value": "INT64[]"
                },
                {
                  "key": "param_name",
                  "value": "indices"
                }
              ]
            }
          ],
          "style": null,
          "config": null
        },
        {
          "id": "node_Range_273",
          "label": "Range",
          "namespace": "main_graph/: transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/slice_scatter_2: aten.slice_scatter.default",
          "subgraphIds": [],
          "attrs": [
            {
              "key": "[metadata] namespace",
              "value": ": transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/slice_scatter_2: aten.slice_scatter.default"
            },
            {
              "key": "[metadata] pkg.torch.onnx.class_hierarchy",
              "value": "['transformers.models.llama.modeling_llama.LlamaForCausalLM', 'transformers.models.llama.modeling_llama.LlamaModel', 'aten.slice_scatter.default']"
            },
            {
              "key": "[metadata] pkg.torch.onnx.fx_node",
              "value": "%slice_scatter_2 : [num_users=2] = call_function[target=torch.ops.aten.slice_scatter.default](args = (%clone, %slice_scatter_1, 0, 0, 9223372036854775807), kwargs = {})"
            },
            {
              "key": "[metadata] pkg.torch.onnx.name_scopes",
              "value": "['', 'model', 'slice_scatter_2']"
            },
            {
              "key": "[metadata] pkg.torch.onnx.stack_trace",
              "value": "File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 688, in forward\n    outputs: BaseModelOutputWithPast = self.model(\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 436, in forward\n    causal_mask = self._update_causal_mask("
            }
          ],
          "incomingEdges": [
            {
              "sourceNodeId": "node_Constant_62",
              "sourceNodeOutputId": "0",
              "targetNodeInputId": "0"
            },
            {
              "sourceNodeId": "node_Gather_272",
              "sourceNodeOutputId": "0",
              "targetNodeInputId": "1"
            },
            {
              "sourceNodeId": "node_Constant_105",
              "sourceNodeOutputId": "0",
              "targetNodeInputId": "2"
            }
          ],
          "outputsMetadata": [
            {
              "id": "0",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "val_209"
                },
                {
                  "key": "tensor_shape",
                  "value": "INT64[unk__18]"
                },
                {
                  "key": "param_name",
                  "value": "output"
                }
              ]
            }
          ],
          "inputsMetadata": [
            {
              "id": "0",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "val_27"
                },
                {
                  "key": "tensor_shape",
                  "value": "INT64[]"
                },
                {
                  "key": "param_name",
                  "value": "start"
                }
              ]
            },
            {
              "id": "1",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "val_208"
                },
                {
                  "key": "tensor_shape",
                  "value": "INT64[]"
                },
                {
                  "key": "param_name",
                  "value": "limit"
                }
              ]
            },
            {
              "id": "2",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "val_65"
                },
                {
                  "key": "tensor_shape",
                  "value": "INT64[]"
                },
                {
                  "key": "param_name",
                  "value": "delta"
                }
              ]
            }
          ],
          "style": null,
          "config": null
        },
        {
          "id": "node_Unsqueeze_278",
          "label": "Unsqueeze",
          "namespace": "main_graph/: transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/slice_scatter_2: aten.slice_scatter.default",
          "subgraphIds": [],
          "attrs": [
            {
              "key": "[metadata] namespace",
              "value": ": transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/slice_scatter_2: aten.slice_scatter.default"
            },
            {
              "key": "[metadata] pkg.torch.onnx.class_hierarchy",
              "value": "['transformers.models.llama.modeling_llama.LlamaForCausalLM', 'transformers.models.llama.modeling_llama.LlamaModel', 'aten.slice_scatter.default']"
            },
            {
              "key": "[metadata] pkg.torch.onnx.fx_node",
              "value": "%slice_scatter_2 : [num_users=2] = call_function[target=torch.ops.aten.slice_scatter.default](args = (%clone, %slice_scatter_1, 0, 0, 9223372036854775807), kwargs = {})"
            },
            {
              "key": "[metadata] pkg.torch.onnx.name_scopes",
              "value": "['', 'model', 'slice_scatter_2']"
            },
            {
              "key": "[metadata] pkg.torch.onnx.stack_trace",
              "value": "File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 688, in forward\n    outputs: BaseModelOutputWithPast = self.model(\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 436, in forward\n    causal_mask = self._update_causal_mask("
            }
          ],
          "incomingEdges": [
            {
              "sourceNodeId": "node_Range_273",
              "sourceNodeOutputId": "0",
              "targetNodeInputId": "0"
            },
            {
              "sourceNodeId": "node_Constant_90",
              "sourceNodeOutputId": "0",
              "targetNodeInputId": "1"
            }
          ],
          "outputsMetadata": [
            {
              "id": "0",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "val_214"
                },
                {
                  "key": "tensor_shape",
                  "value": "INT64[unk__18,1]"
                },
                {
                  "key": "param_name",
                  "value": "expanded"
                }
              ]
            }
          ],
          "inputsMetadata": [
            {
              "id": "0",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "val_209"
                },
                {
                  "key": "tensor_shape",
                  "value": "INT64[unk__18]"
                },
                {
                  "key": "param_name",
                  "value": "data"
                }
              ]
            },
            {
              "id": "1",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "val_53"
                },
                {
                  "key": "tensor_shape",
                  "value": "INT64[1]"
                },
                {
                  "key": "param_name",
                  "value": "axes"
                }
              ]
            }
          ],
          "style": null,
          "config": null
        },
        {
          "id": "node_ScatterND_279",
          "label": "ScatterND",
          "namespace": "main_graph/: transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/slice_scatter_2: aten.slice_scatter.default",
          "subgraphIds": [],
          "attrs": [
            {
              "key": "reduction",
              "value": "none"
            },
            {
              "key": "[metadata] namespace",
              "value": ": transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/slice_scatter_2: aten.slice_scatter.default"
            },
            {
              "key": "[metadata] pkg.torch.onnx.class_hierarchy",
              "value": "['transformers.models.llama.modeling_llama.LlamaForCausalLM', 'transformers.models.llama.modeling_llama.LlamaModel', 'aten.slice_scatter.default']"
            },
            {
              "key": "[metadata] pkg.torch.onnx.fx_node",
              "value": "%slice_scatter_2 : [num_users=2] = call_function[target=torch.ops.aten.slice_scatter.default](args = (%clone, %slice_scatter_1, 0, 0, 9223372036854775807), kwargs = {})"
            },
            {
              "key": "[metadata] pkg.torch.onnx.name_scopes",
              "value": "['', 'model', 'slice_scatter_2']"
            },
            {
              "key": "[metadata] pkg.torch.onnx.stack_trace",
              "value": "File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 688, in forward\n    outputs: BaseModelOutputWithPast = self.model(\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 436, in forward\n    causal_mask = self._update_causal_mask("
            }
          ],
          "incomingEdges": [
            {
              "sourceNodeId": "node_Expand_94",
              "sourceNodeOutputId": "0",
              "targetNodeInputId": "0"
            },
            {
              "sourceNodeId": "node_Unsqueeze_278",
              "sourceNodeOutputId": "0",
              "targetNodeInputId": "1"
            },
            {
              "sourceNodeId": "node_Transpose_269",
              "sourceNodeOutputId": "0",
              "targetNodeInputId": "2"
            }
          ],
          "outputsMetadata": [
            {
              "id": "0",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "slice_scatter_2"
                },
                {
                  "key": "tensor_shape",
                  "value": "FLOAT[s34,1,s16,s16 + s17]"
                },
                {
                  "key": "param_name",
                  "value": "output"
                }
              ]
            }
          ],
          "inputsMetadata": [
            {
              "id": "0",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "expand_1"
                },
                {
                  "key": "tensor_shape",
                  "value": "FLOAT[s34,1,s16,s16 + s17]"
                },
                {
                  "key": "param_name",
                  "value": "data"
                }
              ]
            },
            {
              "id": "1",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "val_214"
                },
                {
                  "key": "tensor_shape",
                  "value": "INT64[unk__18,1]"
                },
                {
                  "key": "param_name",
                  "value": "indices"
                }
              ]
            },
            {
              "id": "2",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "slice_scatter_1"
                },
                {
                  "key": "tensor_shape",
                  "value": "FLOAT[s34,1,s16,s16 + s17]"
                },
                {
                  "key": "param_name",
                  "value": "updates"
                }
              ]
            }
          ],
          "style": null,
          "config": null
        },
        {
          "id": "node_SimplifiedLayerNormalization_16",
          "label": "SimplifiedLayerNormalization",
          "namespace": "main_graph",
          "subgraphIds": [],
          "attrs": [
            {
              "key": "axis",
              "value": "-1"
            },
            {
              "key": "epsilon",
              "value": "9.999999747378752e-06"
            },
            {
              "key": "stash_type",
              "value": "1"
            }
          ],
          "incomingEdges": [
            {
              "sourceNodeId": "node_Gather_20",
              "sourceNodeOutputId": "0",
              "targetNodeInputId": "0"
            },
            {
              "sourceNodeId": "[value] model.layers.0.input_layernorm.weight",
              "sourceNodeOutputId": "0",
              "targetNodeInputId": "1"
            }
          ],
          "outputsMetadata": [
            {
              "id": "0",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "mul_173"
                },
                {
                  "key": "tensor_shape",
                  "value": "FLOAT[s34,s16,2048]"
                }
              ]
            }
          ],
          "inputsMetadata": [
            {
              "id": "0",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "embedding"
                },
                {
                  "key": "tensor_shape",
                  "value": "FLOAT[s34,s16,2048]"
                }
              ]
            },
            {
              "id": "1",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "model.layers.0.input_layernorm.weight"
                },
                {
                  "key": "tensor_shape",
                  "value": "FLOAT[2048]"
                }
              ]
            }
          ],
          "style": null,
          "config": null
        },
        {
          "id": "node_MatMul_340",
          "label": "MatMul",
          "namespace": "main_graph/: transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/model.layers.0: transformers.models.llama.modeling_llama.LlamaDecoderLayer/model.layers.0.self_attn: transformers.models.llama.modeling_llama.LlamaAttention/model.layers.0.self_attn.q_proj: torch.nn.modules.linear.Linear/linear: aten.linear.default",
          "subgraphIds": [],
          "attrs": [
            {
              "key": "[metadata] namespace",
              "value": ": transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/model.layers.0: transformers.models.llama.modeling_llama.LlamaDecoderLayer/model.layers.0.self_attn: transformers.models.llama.modeling_llama.LlamaAttention/model.layers.0.self_attn.q_proj: torch.nn.modules.linear.Linear/linear: aten.linear.default"
            },
            {
              "key": "[metadata] pkg.torch.onnx.class_hierarchy",
              "value": "['transformers.models.llama.modeling_llama.LlamaForCausalLM', 'transformers.models.llama.modeling_llama.LlamaModel', 'transformers.models.llama.modeling_llama.LlamaDecoderLayer', 'transformers.models.llama.modeling_llama.LlamaAttention', 'torch.nn.modules.linear.Linear', 'aten.linear.default']"
            },
            {
              "key": "[metadata] pkg.torch.onnx.fx_node",
              "value": "%linear : [num_users=1] = call_function[target=torch.ops.aten.linear.default](args = (%mul_173, %p_model_layers_0_self_attn_q_proj_weight), kwargs = {})"
            },
            {
              "key": "[metadata] pkg.torch.onnx.name_scopes",
              "value": "['', 'model', 'model.layers.0', 'model.layers.0.self_attn', 'model.layers.0.self_attn.q_proj', 'linear']"
            },
            {
              "key": "[metadata] pkg.torch.onnx.stack_trace",
              "value": "File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 688, in forward\n    outputs: BaseModelOutputWithPast = self.model(\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 453, in forward\n    layer_outputs = decoder_layer(\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 308, in forward\n    hidden_states, self_attn_weights = self.self_attn(\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 242, in forward\n    query_states = self.q_proj(hidden_states).view(hidden_shape).transpose(1, 2)\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/torch/nn/modules/linear.py\", line 125, in forward\n    return F.linear(input, self.weight, self.bias)"
            }
          ],
          "incomingEdges": [
            {
              "sourceNodeId": "node_SimplifiedLayerNormalization_16",
              "sourceNodeOutputId": "0",
              "targetNodeInputId": "0"
            },
            {
              "sourceNodeId": "[value] val_253",
              "sourceNodeOutputId": "0",
              "targetNodeInputId": "1"
            }
          ],
          "outputsMetadata": [
            {
              "id": "0",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "linear"
                },
                {
                  "key": "tensor_shape",
                  "value": "FLOAT[s34,s16,2048]"
                },
                {
                  "key": "param_name",
                  "value": "Y"
                }
              ]
            }
          ],
          "inputsMetadata": [
            {
              "id": "0",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "mul_173"
                },
                {
                  "key": "tensor_shape",
                  "value": "FLOAT[s34,s16,2048]"
                },
                {
                  "key": "param_name",
                  "value": "A"
                }
              ]
            },
            {
              "id": "1",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "val_253"
                },
                {
                  "key": "tensor_shape",
                  "value": "FLOAT[2048,2048]"
                },
                {
                  "key": "param_name",
                  "value": "B"
                }
              ]
            }
          ],
          "style": null,
          "config": null
        },
        {
          "id": "node_MatMul_351",
          "label": "MatMul",
          "namespace": "main_graph/: transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/model.layers.0: transformers.models.llama.modeling_llama.LlamaDecoderLayer/model.layers.0.self_attn: transformers.models.llama.modeling_llama.LlamaAttention/model.layers.0.self_attn.k_proj: torch.nn.modules.linear.Linear/linear_1: aten.linear.default",
          "subgraphIds": [],
          "attrs": [
            {
              "key": "[metadata] namespace",
              "value": ": transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/model.layers.0: transformers.models.llama.modeling_llama.LlamaDecoderLayer/model.layers.0.self_attn: transformers.models.llama.modeling_llama.LlamaAttention/model.layers.0.self_attn.k_proj: torch.nn.modules.linear.Linear/linear_1: aten.linear.default"
            },
            {
              "key": "[metadata] pkg.torch.onnx.class_hierarchy",
              "value": "['transformers.models.llama.modeling_llama.LlamaForCausalLM', 'transformers.models.llama.modeling_llama.LlamaModel', 'transformers.models.llama.modeling_llama.LlamaDecoderLayer', 'transformers.models.llama.modeling_llama.LlamaAttention', 'torch.nn.modules.linear.Linear', 'aten.linear.default']"
            },
            {
              "key": "[metadata] pkg.torch.onnx.fx_node",
              "value": "%linear_1 : [num_users=1] = call_function[target=torch.ops.aten.linear.default](args = (%mul_173, %p_model_layers_0_self_attn_k_proj_weight), kwargs = {})"
            },
            {
              "key": "[metadata] pkg.torch.onnx.name_scopes",
              "value": "['', 'model', 'model.layers.0', 'model.layers.0.self_attn', 'model.layers.0.self_attn.k_proj', 'linear_1']"
            },
            {
              "key": "[metadata] pkg.torch.onnx.stack_trace",
              "value": "File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 688, in forward\n    outputs: BaseModelOutputWithPast = self.model(\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 453, in forward\n    layer_outputs = decoder_layer(\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 308, in forward\n    hidden_states, self_attn_weights = self.self_attn(\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 243, in forward\n    key_states = self.k_proj(hidden_states).view(hidden_shape).transpose(1, 2)\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/torch/nn/modules/linear.py\", line 125, in forward\n    return F.linear(input, self.weight, self.bias)"
            }
          ],
          "incomingEdges": [
            {
              "sourceNodeId": "node_SimplifiedLayerNormalization_16",
              "sourceNodeOutputId": "0",
              "targetNodeInputId": "0"
            },
            {
              "sourceNodeId": "[value] val_261",
              "sourceNodeOutputId": "0",
              "targetNodeInputId": "1"
            }
          ],
          "outputsMetadata": [
            {
              "id": "0",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "linear_1"
                },
                {
                  "key": "tensor_shape",
                  "value": "FLOAT[s34,s16,2048]"
                },
                {
                  "key": "param_name",
                  "value": "Y"
                }
              ]
            }
          ],
          "inputsMetadata": [
            {
              "id": "0",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "mul_173"
                },
                {
                  "key": "tensor_shape",
                  "value": "FLOAT[s34,s16,2048]"
                },
                {
                  "key": "param_name",
                  "value": "A"
                }
              ]
            },
            {
              "id": "1",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "val_261"
                },
                {
                  "key": "tensor_shape",
                  "value": "FLOAT[2048,2048]"
                },
                {
                  "key": "param_name",
                  "value": "B"
                }
              ]
            }
          ],
          "style": null,
          "config": null
        },
        {
          "id": "node_MatMul_361",
          "label": "MatMul",
          "namespace": "main_graph/: transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/model.layers.0: transformers.models.llama.modeling_llama.LlamaDecoderLayer/model.layers.0.self_attn: transformers.models.llama.modeling_llama.LlamaAttention/model.layers.0.self_attn.v_proj: torch.nn.modules.linear.Linear/linear_2: aten.linear.default",
          "subgraphIds": [],
          "attrs": [
            {
              "key": "[metadata] namespace",
              "value": ": transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/model.layers.0: transformers.models.llama.modeling_llama.LlamaDecoderLayer/model.layers.0.self_attn: transformers.models.llama.modeling_llama.LlamaAttention/model.layers.0.self_attn.v_proj: torch.nn.modules.linear.Linear/linear_2: aten.linear.default"
            },
            {
              "key": "[metadata] pkg.torch.onnx.class_hierarchy",
              "value": "['transformers.models.llama.modeling_llama.LlamaForCausalLM', 'transformers.models.llama.modeling_llama.LlamaModel', 'transformers.models.llama.modeling_llama.LlamaDecoderLayer', 'transformers.models.llama.modeling_llama.LlamaAttention', 'torch.nn.modules.linear.Linear', 'aten.linear.default']"
            },
            {
              "key": "[metadata] pkg.torch.onnx.fx_node",
              "value": "%linear_2 : [num_users=1] = call_function[target=torch.ops.aten.linear.default](args = (%mul_173, %p_model_layers_0_self_attn_v_proj_weight), kwargs = {})"
            },
            {
              "key": "[metadata] pkg.torch.onnx.name_scopes",
              "value": "['', 'model', 'model.layers.0', 'model.layers.0.self_attn', 'model.layers.0.self_attn.v_proj', 'linear_2']"
            },
            {
              "key": "[metadata] pkg.torch.onnx.stack_trace",
              "value": "File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 688, in forward\n    outputs: BaseModelOutputWithPast = self.model(\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 453, in forward\n    layer_outputs = decoder_layer(\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 308, in forward\n    hidden_states, self_attn_weights = self.self_attn(\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 244, in forward\n    value_states = self.v_proj(hidden_states).view(hidden_shape).transpose(1, 2)\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/torch/nn/modules/linear.py\", line 125, in forward\n    return F.linear(input, self.weight, self.bias)"
            }
          ],
          "incomingEdges": [
            {
              "sourceNodeId": "node_SimplifiedLayerNormalization_16",
              "sourceNodeOutputId": "0",
              "targetNodeInputId": "0"
            },
            {
              "sourceNodeId": "[value] val_268",
              "sourceNodeOutputId": "0",
              "targetNodeInputId": "1"
            }
          ],
          "outputsMetadata": [
            {
              "id": "0",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "linear_2"
                },
                {
                  "key": "tensor_shape",
                  "value": "FLOAT[s34,s16,2048]"
                },
                {
                  "key": "param_name",
                  "value": "Y"
                }
              ]
            }
          ],
          "inputsMetadata": [
            {
              "id": "0",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "mul_173"
                },
                {
                  "key": "tensor_shape",
                  "value": "FLOAT[s34,s16,2048]"
                },
                {
                  "key": "param_name",
                  "value": "A"
                }
              ]
            },
            {
              "id": "1",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "val_268"
                },
                {
                  "key": "tensor_shape",
                  "value": "FLOAT[2048,2048]"
                },
                {
                  "key": "param_name",
                  "value": "B"
                }
              ]
            }
          ],
          "style": null,
          "config": null
        },
        {
          "id": "node_ReduceMax_31",
          "label": "ReduceMax",
          "namespace": "main_graph",
          "subgraphIds": [],
          "attrs": [
            {
              "key": "keepdims",
              "value": "0"
            }
          ],
          "incomingEdges": [
            {
              "sourceNodeId": "node_Range_36",
              "sourceNodeOutputId": "0",
              "targetNodeInputId": "0"
            }
          ],
          "outputsMetadata": [
            {
              "id": "0",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "val_20"
                },
                {
                  "key": "tensor_shape",
                  "value": "INT64[]"
                },
                {
                  "key": "param_name",
                  "value": "reduced"
                }
              ]
            }
          ],
          "inputsMetadata": [
            {
              "id": "0",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "arange"
                },
                {
                  "key": "tensor_shape",
                  "value": "INT64[s16]"
                },
                {
                  "key": "param_name",
                  "value": "data"
                }
              ]
            }
          ],
          "style": null,
          "config": null
        },
        {
          "id": "node_Add_34",
          "label": "Add",
          "namespace": "main_graph",
          "subgraphIds": [],
          "attrs": [],
          "incomingEdges": [
            {
              "sourceNodeId": "node_ReduceMax_31",
              "sourceNodeOutputId": "0",
              "targetNodeInputId": "0"
            },
            {
              "sourceNodeId": "n0",
              "sourceNodeOutputId": "0",
              "targetNodeInputId": "1"
            }
          ],
          "outputsMetadata": [
            {
              "id": "0",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "val_24"
                },
                {
                  "key": "tensor_shape",
                  "value": "INT64[]"
                },
                {
                  "key": "param_name",
                  "value": "C"
                }
              ]
            }
          ],
          "inputsMetadata": [
            {
              "id": "0",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "val_20"
                },
                {
                  "key": "tensor_shape",
                  "value": "INT64[]"
                },
                {
                  "key": "param_name",
                  "value": "A"
                }
              ]
            },
            {
              "id": "1",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "diagonal"
                },
                {
                  "key": "tensor_shape",
                  "value": "INT64[]"
                },
                {
                  "key": "param_name",
                  "value": "B"
                }
              ]
            }
          ],
          "style": null,
          "config": null
        },
        {
          "id": "node_Constant_35",
          "label": "Constant",
          "namespace": "main_graph",
          "subgraphIds": [],
          "attrs": [
            {
              "key": "__value",
              "value": "0"
            },
            {
              "key": "value_int",
              "value": "0"
            }
          ],
          "incomingEdges": [],
          "outputsMetadata": [
            {
              "id": "0",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "val_28"
                },
                {
                  "key": "tensor_shape",
                  "value": "INT64[]"
                },
                {
                  "key": "param_name",
                  "value": "output"
                }
              ]
            }
          ],
          "inputsMetadata": [],
          "style": null,
          "config": null
        },
        {
          "id": "node_Range_37",
          "label": "Range",
          "namespace": "main_graph",
          "subgraphIds": [],
          "attrs": [],
          "incomingEdges": [
            {
              "sourceNodeId": "node_Constant_35",
              "sourceNodeOutputId": "0",
              "targetNodeInputId": "0"
            },
            {
              "sourceNodeId": "node_Add_34",
              "sourceNodeOutputId": "0",
              "targetNodeInputId": "1"
            },
            {
              "sourceNodeId": "n0",
              "sourceNodeOutputId": "0",
              "targetNodeInputId": "2"
            }
          ],
          "outputsMetadata": [
            {
              "id": "0",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "val_30"
                },
                {
                  "key": "tensor_shape",
                  "value": "INT64[unk__25]"
                },
                {
                  "key": "param_name",
                  "value": "output"
                }
              ]
            }
          ],
          "inputsMetadata": [
            {
              "id": "0",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "val_28"
                },
                {
                  "key": "tensor_shape",
                  "value": "INT64[]"
                },
                {
                  "key": "param_name",
                  "value": "start"
                }
              ]
            },
            {
              "id": "1",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "val_24"
                },
                {
                  "key": "tensor_shape",
                  "value": "INT64[]"
                },
                {
                  "key": "param_name",
                  "value": "limit"
                }
              ]
            },
            {
              "id": "2",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "diagonal"
                },
                {
                  "key": "tensor_shape",
                  "value": "INT64[]"
                },
                {
                  "key": "param_name",
                  "value": "delta"
                }
              ]
            }
          ],
          "style": null,
          "config": null
        },
        {
          "id": "node_Constant_38",
          "label": "Constant",
          "namespace": "main_graph",
          "subgraphIds": [],
          "attrs": [
            {
              "key": "__value",
              "value": "[-1,1]"
            },
            {
              "key": "value_ints",
              "value": "[-1, 1]"
            }
          ],
          "incomingEdges": [],
          "outputsMetadata": [
            {
              "id": "0",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "val_31"
                },
                {
                  "key": "tensor_shape",
                  "value": "INT64[2]"
                },
                {
                  "key": "param_name",
                  "value": "output"
                }
              ]
            }
          ],
          "inputsMetadata": [],
          "style": null,
          "config": null
        },
        {
          "id": "node_Reshape_39",
          "label": "Reshape",
          "namespace": "main_graph",
          "subgraphIds": [],
          "attrs": [],
          "incomingEdges": [
            {
              "sourceNodeId": "node_Range_37",
              "sourceNodeOutputId": "0",
              "targetNodeInputId": "0"
            },
            {
              "sourceNodeId": "node_Constant_38",
              "sourceNodeOutputId": "0",
              "targetNodeInputId": "1"
            }
          ],
          "outputsMetadata": [
            {
              "id": "0",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "val_32"
                },
                {
                  "key": "tensor_shape",
                  "value": "INT64[unk__26,1]"
                },
                {
                  "key": "param_name",
                  "value": "reshaped"
                }
              ]
            }
          ],
          "inputsMetadata": [
            {
              "id": "0",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "val_30"
                },
                {
                  "key": "tensor_shape",
                  "value": "INT64[unk__25]"
                },
                {
                  "key": "param_name",
                  "value": "data"
                }
              ]
            },
            {
              "id": "1",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "val_31"
                },
                {
                  "key": "tensor_shape",
                  "value": "INT64[2]"
                },
                {
                  "key": "param_name",
                  "value": "shape"
                }
              ]
            }
          ],
          "style": null,
          "config": null
        },
        {
          "id": "node_Cast_40",
          "label": "Cast",
          "namespace": "main_graph",
          "subgraphIds": [],
          "attrs": [
            {
              "key": "to",
              "value": "FLOAT"
            }
          ],
          "incomingEdges": [
            {
              "sourceNodeId": "node_Reshape_39",
              "sourceNodeOutputId": "0",
              "targetNodeInputId": "0"
            }
          ],
          "outputsMetadata": [
            {
              "id": "0",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "val_33"
                },
                {
                  "key": "tensor_shape",
                  "value": "FLOAT[unk__26,1]"
                },
                {
                  "key": "param_name",
                  "value": "output"
                }
              ]
            }
          ],
          "inputsMetadata": [
            {
              "id": "0",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "val_32"
                },
                {
                  "key": "tensor_shape",
                  "value": "INT64[unk__26,1]"
                },
                {
                  "key": "param_name",
                  "value": "input"
                }
              ]
            }
          ],
          "style": null,
          "config": null
        },
        {
          "id": "node_MatMul_41",
          "label": "MatMul",
          "namespace": "main_graph",
          "subgraphIds": [],
          "attrs": [],
          "incomingEdges": [
            {
              "sourceNodeId": "node_Cast_40",
              "sourceNodeOutputId": "0",
              "targetNodeInputId": "0"
            },
            {
              "sourceNodeId": "[value] val_16",
              "sourceNodeOutputId": "0",
              "targetNodeInputId": "1"
            }
          ],
          "outputsMetadata": [
            {
              "id": "0",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "val_34"
                },
                {
                  "key": "tensor_shape",
                  "value": "FLOAT[unk__26,32]"
                },
                {
                  "key": "param_name",
                  "value": "Y"
                }
              ]
            }
          ],
          "inputsMetadata": [
            {
              "id": "0",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "val_33"
                },
                {
                  "key": "tensor_shape",
                  "value": "FLOAT[unk__26,1]"
                },
                {
                  "key": "param_name",
                  "value": "A"
                }
              ]
            },
            {
              "id": "1",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "val_16"
                },
                {
                  "key": "tensor_shape",
                  "value": "FLOAT[1,32]"
                },
                {
                  "key": "param_name",
                  "value": "B"
                }
              ]
            }
          ],
          "style": null,
          "config": null
        },
        {
          "id": "node_Cos_42",
          "label": "Cos",
          "namespace": "main_graph",
          "subgraphIds": [],
          "attrs": [],
          "incomingEdges": [
            {
              "sourceNodeId": "node_MatMul_41",
              "sourceNodeOutputId": "0",
              "targetNodeInputId": "0"
            }
          ],
          "outputsMetadata": [
            {
              "id": "0",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "val_36"
                },
                {
                  "key": "tensor_shape",
                  "value": "FLOAT[unk__26,32]"
                },
                {
                  "key": "param_name",
                  "value": "output"
                }
              ]
            }
          ],
          "inputsMetadata": [
            {
              "id": "0",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "val_34"
                },
                {
                  "key": "tensor_shape",
                  "value": "FLOAT[unk__26,32]"
                },
                {
                  "key": "param_name",
                  "value": "input"
                }
              ]
            }
          ],
          "style": null,
          "config": null
        },
        {
          "id": "node_Sin_43",
          "label": "Sin",
          "namespace": "main_graph",
          "subgraphIds": [],
          "attrs": [],
          "incomingEdges": [
            {
              "sourceNodeId": "node_MatMul_41",
              "sourceNodeOutputId": "0",
              "targetNodeInputId": "0"
            }
          ],
          "outputsMetadata": [
            {
              "id": "0",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "val_37"
                },
                {
                  "key": "tensor_shape",
                  "value": "FLOAT[unk__26,32]"
                },
                {
                  "key": "param_name",
                  "value": "output"
                }
              ]
            }
          ],
          "inputsMetadata": [
            {
              "id": "0",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "val_34"
                },
                {
                  "key": "tensor_shape",
                  "value": "FLOAT[unk__26,32]"
                },
                {
                  "key": "param_name",
                  "value": "input"
                }
              ]
            }
          ],
          "style": null,
          "config": null
        },
        {
          "id": "node_Constant_921",
          "label": "Constant",
          "namespace": "main_graph/: transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/model.layers.0: transformers.models.llama.modeling_llama.LlamaDecoderLayer/model.layers.0.self_attn: transformers.models.llama.modeling_llama.LlamaAttention/slice_37: aten.slice.Tensor",
          "subgraphIds": [],
          "attrs": [
            {
              "key": "__value",
              "value": "[3]"
            },
            {
              "key": "value",
              "value": "TensorProtoTensor<INT64,[1]>(array([3]), name='val_341')"
            }
          ],
          "incomingEdges": [],
          "outputsMetadata": [
            {
              "id": "0",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "val_341"
                },
                {
                  "key": "tensor_shape",
                  "value": "INT64[1]"
                },
                {
                  "key": "param_name",
                  "value": "output"
                }
              ]
            }
          ],
          "inputsMetadata": [],
          "style": null,
          "config": null
        },
        {
          "id": "node_Slice_462",
          "label": "Slice",
          "namespace": "main_graph/: transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/model.layers.0: transformers.models.llama.modeling_llama.LlamaDecoderLayer/model.layers.0.self_attn: transformers.models.llama.modeling_llama.LlamaAttention/slice_37: aten.slice.Tensor",
          "subgraphIds": [],
          "attrs": [
            {
              "key": "[metadata] namespace",
              "value": ": transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/model.layers.0: transformers.models.llama.modeling_llama.LlamaDecoderLayer/model.layers.0.self_attn: transformers.models.llama.modeling_llama.LlamaAttention/slice_37: aten.slice.Tensor"
            },
            {
              "key": "[metadata] pkg.torch.onnx.class_hierarchy",
              "value": "['transformers.models.llama.modeling_llama.LlamaForCausalLM', 'transformers.models.llama.modeling_llama.LlamaModel', 'transformers.models.llama.modeling_llama.LlamaDecoderLayer', 'transformers.models.llama.modeling_llama.LlamaAttention', 'aten.slice.Tensor']"
            },
            {
              "key": "[metadata] pkg.torch.onnx.fx_node",
              "value": "%slice_37 : [num_users=1] = call_function[target=torch.ops.aten.slice.Tensor](args = (%slice_36, 3, None, %add_4), kwargs = {})"
            },
            {
              "key": "[metadata] pkg.torch.onnx.name_scopes",
              "value": "['', 'model', 'model.layers.0', 'model.layers.0.self_attn', 'slice_37']"
            },
            {
              "key": "[metadata] pkg.torch.onnx.stack_trace",
              "value": "File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 688, in forward\n    outputs: BaseModelOutputWithPast = self.model(\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 453, in forward\n    layer_outputs = decoder_layer(\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 308, in forward\n    hidden_states, self_attn_weights = self.self_attn(\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 265, in forward\n    attn_output, attn_weights = attention_interface("
            }
          ],
          "incomingEdges": [
            {
              "sourceNodeId": "node_ScatterND_279",
              "sourceNodeOutputId": "0",
              "targetNodeInputId": "0"
            },
            {
              "sourceNodeId": "node_Constant_118",
              "sourceNodeOutputId": "0",
              "targetNodeInputId": "1"
            },
            {
              "sourceNodeId": "node_Reshape_121",
              "sourceNodeOutputId": "0",
              "targetNodeInputId": "2"
            },
            {
              "sourceNodeId": "node_Constant_921",
              "sourceNodeOutputId": "0",
              "targetNodeInputId": "3"
            },
            {
              "sourceNodeId": "node_Constant_125",
              "sourceNodeOutputId": "0",
              "targetNodeInputId": "4"
            }
          ],
          "outputsMetadata": [
            {
              "id": "0",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "slice_37"
                },
                {
                  "key": "tensor_shape",
                  "value": "FLOAT[s34,1,s16,s16 + s17]"
                },
                {
                  "key": "param_name",
                  "value": "output"
                }
              ]
            }
          ],
          "inputsMetadata": [
            {
              "id": "0",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "slice_scatter_2"
                },
                {
                  "key": "tensor_shape",
                  "value": "FLOAT[s34,1,s16,s16 + s17]"
                },
                {
                  "key": "param_name",
                  "value": "data"
                }
              ]
            },
            {
              "id": "1",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "val_76"
                },
                {
                  "key": "tensor_shape",
                  "value": "INT64[1]"
                },
                {
                  "key": "param_name",
                  "value": "starts"
                }
              ]
            },
            {
              "id": "2",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "val_79"
                },
                {
                  "key": "tensor_shape",
                  "value": "INT64[1]"
                },
                {
                  "key": "param_name",
                  "value": "ends"
                }
              ]
            },
            {
              "id": "3",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "val_341"
                },
                {
                  "key": "tensor_shape",
                  "value": "INT64[1]"
                },
                {
                  "key": "param_name",
                  "value": "axes"
                }
              ]
            },
            {
              "id": "4",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "val_83"
                },
                {
                  "key": "tensor_shape",
                  "value": "INT64[1]"
                },
                {
                  "key": "param_name",
                  "value": "steps"
                }
              ]
            }
          ],
          "style": null,
          "config": null
        },
        {
          "id": "node_Unsqueeze_59",
          "label": "Unsqueeze",
          "namespace": "main_graph",
          "subgraphIds": [],
          "attrs": [],
          "incomingEdges": [
            {
              "sourceNodeId": "node_Range_36",
              "sourceNodeOutputId": "0",
              "targetNodeInputId": "0"
            },
            {
              "sourceNodeId": "node_Constant_118",
              "sourceNodeOutputId": "0",
              "targetNodeInputId": "1"
            }
          ],
          "outputsMetadata": [
            {
              "id": "0",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "val_47"
                },
                {
                  "key": "tensor_shape",
                  "value": "INT64[1,s16]"
                },
                {
                  "key": "param_name",
                  "value": "expanded"
                }
              ]
            }
          ],
          "inputsMetadata": [
            {
              "id": "0",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "arange"
                },
                {
                  "key": "tensor_shape",
                  "value": "INT64[s16]"
                },
                {
                  "key": "param_name",
                  "value": "data"
                }
              ]
            },
            {
              "id": "1",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "val_76"
                },
                {
                  "key": "tensor_shape",
                  "value": "INT64[1]"
                },
                {
                  "key": "param_name",
                  "value": "axes"
                }
              ]
            }
          ],
          "style": null,
          "config": null
        },
        {
          "id": "node_RotaryEmbedding_60",
          "label": "com.microsoft::RotaryEmbedding",
          "namespace": "main_graph",
          "subgraphIds": [],
          "attrs": [],
          "incomingEdges": [
            {
              "sourceNodeId": "node_MatMul_340",
              "sourceNodeOutputId": "0",
              "targetNodeInputId": "0"
            },
            {
              "sourceNodeId": "node_Unsqueeze_59",
              "sourceNodeOutputId": "0",
              "targetNodeInputId": "1"
            },
            {
              "sourceNodeId": "node_Cos_42",
              "sourceNodeOutputId": "0",
              "targetNodeInputId": "2"
            },
            {
              "sourceNodeId": "node_Sin_43",
              "sourceNodeOutputId": "0",
              "targetNodeInputId": "3"
            }
          ],
          "outputsMetadata": [
            {
              "id": "0",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "val_48"
                },
                {
                  "key": "tensor_shape",
                  "value": "?[?]"
                }
              ]
            }
          ],
          "inputsMetadata": [
            {
              "id": "0",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "linear"
                },
                {
                  "key": "tensor_shape",
                  "value": "FLOAT[s34,s16,2048]"
                }
              ]
            },
            {
              "id": "1",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "val_47"
                },
                {
                  "key": "tensor_shape",
                  "value": "INT64[1,s16]"
                }
              ]
            },
            {
              "id": "2",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "val_36"
                },
                {
                  "key": "tensor_shape",
                  "value": "FLOAT[unk__26,32]"
                }
              ]
            },
            {
              "id": "3",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "val_37"
                },
                {
                  "key": "tensor_shape",
                  "value": "FLOAT[unk__26,32]"
                }
              ]
            }
          ],
          "style": null,
          "config": null
        },
        {
          "id": "node_RotaryEmbedding_61",
          "label": "com.microsoft::RotaryEmbedding",
          "namespace": "main_graph",
          "subgraphIds": [],
          "attrs": [],
          "incomingEdges": [
            {
              "sourceNodeId": "node_MatMul_351",
              "sourceNodeOutputId": "0",
              "targetNodeInputId": "0"
            },
            {
              "sourceNodeId": "node_Unsqueeze_59",
              "sourceNodeOutputId": "0",
              "targetNodeInputId": "1"
            },
            {
              "sourceNodeId": "node_Cos_42",
              "sourceNodeOutputId": "0",
              "targetNodeInputId": "2"
            },
            {
              "sourceNodeId": "node_Sin_43",
              "sourceNodeOutputId": "0",
              "targetNodeInputId": "3"
            }
          ],
          "outputsMetadata": [
            {
              "id": "0",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "val_49"
                },
                {
                  "key": "tensor_shape",
                  "value": "?[?]"
                }
              ]
            }
          ],
          "inputsMetadata": [
            {
              "id": "0",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "linear_1"
                },
                {
                  "key": "tensor_shape",
                  "value": "FLOAT[s34,s16,2048]"
                }
              ]
            },
            {
              "id": "1",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "val_47"
                },
                {
                  "key": "tensor_shape",
                  "value": "INT64[1,s16]"
                }
              ]
            },
            {
              "id": "2",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "val_36"
                },
                {
                  "key": "tensor_shape",
                  "value": "FLOAT[unk__26,32]"
                }
              ]
            },
            {
              "id": "3",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "val_37"
                },
                {
                  "key": "tensor_shape",
                  "value": "FLOAT[unk__26,32]"
                }
              ]
            }
          ],
          "style": null,
          "config": null
        },
        {
          "id": "node_MultiHeadAttention_62",
          "label": "com.microsoft::MultiHeadAttention",
          "namespace": "main_graph",
          "subgraphIds": [],
          "attrs": [
            {
              "key": "num_heads",
              "value": "32"
            }
          ],
          "incomingEdges": [
            {
              "sourceNodeId": "node_RotaryEmbedding_60",
              "sourceNodeOutputId": "0",
              "targetNodeInputId": "0"
            },
            {
              "sourceNodeId": "node_RotaryEmbedding_61",
              "sourceNodeOutputId": "0",
              "targetNodeInputId": "1"
            },
            {
              "sourceNodeId": "node_MatMul_361",
              "sourceNodeOutputId": "0",
              "targetNodeInputId": "2"
            },
            {
              "sourceNodeId": "node_Slice_462",
              "sourceNodeOutputId": "0",
              "targetNodeInputId": "5"
            },
            {
              "sourceNodeId": "[value] past_key_values_key_cache_0",
              "sourceNodeOutputId": "0",
              "targetNodeInputId": "6"
            },
            {
              "sourceNodeId": "[value] past_key_values_value_cache_0",
              "sourceNodeOutputId": "0",
              "targetNodeInputId": "7"
            }
          ],
          "outputsMetadata": [
            {
              "id": "0",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "view_4"
                },
                {
                  "key": "tensor_shape",
                  "value": "FLOAT[s34,s16,2048]"
                }
              ]
            },
            {
              "id": "1",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "cat_3"
                },
                {
                  "key": "tensor_shape",
                  "value": "FLOAT[s34,32,s16 + s17,64]"
                }
              ]
            },
            {
              "id": "2",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "cat_4"
                },
                {
                  "key": "tensor_shape",
                  "value": "FLOAT[s34,32,s16 + s17,64]"
                }
              ]
            }
          ],
          "inputsMetadata": [
            {
              "id": "0",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "val_48"
                },
                {
                  "key": "tensor_shape",
                  "value": "?[?]"
                }
              ]
            },
            {
              "id": "1",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "val_49"
                },
                {
                  "key": "tensor_shape",
                  "value": "?[?]"
                }
              ]
            },
            {
              "id": "2",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "linear_2"
                },
                {
                  "key": "tensor_shape",
                  "value": "FLOAT[s34,s16,2048]"
                }
              ]
            },
            {
              "id": "3",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "None"
                }
              ]
            },
            {
              "id": "4",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "None"
                }
              ]
            },
            {
              "id": "5",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "slice_37"
                },
                {
                  "key": "tensor_shape",
                  "value": "FLOAT[s34,1,s16,s16 + s17]"
                }
              ]
            },
            {
              "id": "6",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "past_key_values_key_cache_0"
                },
                {
                  "key": "tensor_shape",
                  "value": "FLOAT[s34,32,s17,64]"
                },
                {
                  "key": "[metadata] pkg.torch.export.graph_signature.InputSpec.kind",
                  "value": "USER_INPUT"
                },
                {
                  "key": "[metadata] pkg.torch.export.graph_signature.InputSpec.persistent",
                  "value": "None"
                }
              ]
            },
            {
              "id": "7",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "past_key_values_value_cache_0"
                },
                {
                  "key": "tensor_shape",
                  "value": "FLOAT[s34,32,s17,64]"
                },
                {
                  "key": "[metadata] pkg.torch.export.graph_signature.InputSpec.kind",
                  "value": "USER_INPUT"
                },
                {
                  "key": "[metadata] pkg.torch.export.graph_signature.InputSpec.persistent",
                  "value": "None"
                }
              ]
            }
          ],
          "style": null,
          "config": null
        },
        {
          "id": "node_MatMul_478",
          "label": "MatMul",
          "namespace": "main_graph/: transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/model.layers.0: transformers.models.llama.modeling_llama.LlamaDecoderLayer/model.layers.0.self_attn: transformers.models.llama.modeling_llama.LlamaAttention/model.layers.0.self_attn.o_proj: torch.nn.modules.linear.Linear/linear_3: aten.linear.default",
          "subgraphIds": [],
          "attrs": [
            {
              "key": "[metadata] namespace",
              "value": ": transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/model.layers.0: transformers.models.llama.modeling_llama.LlamaDecoderLayer/model.layers.0.self_attn: transformers.models.llama.modeling_llama.LlamaAttention/model.layers.0.self_attn.o_proj: torch.nn.modules.linear.Linear/linear_3: aten.linear.default"
            },
            {
              "key": "[metadata] pkg.torch.onnx.class_hierarchy",
              "value": "['transformers.models.llama.modeling_llama.LlamaForCausalLM', 'transformers.models.llama.modeling_llama.LlamaModel', 'transformers.models.llama.modeling_llama.LlamaDecoderLayer', 'transformers.models.llama.modeling_llama.LlamaAttention', 'torch.nn.modules.linear.Linear', 'aten.linear.default']"
            },
            {
              "key": "[metadata] pkg.torch.onnx.fx_node",
              "value": "%linear_3 : [num_users=1] = call_function[target=torch.ops.aten.linear.default](args = (%view_4, %p_model_layers_0_self_attn_o_proj_weight), kwargs = {})"
            },
            {
              "key": "[metadata] pkg.torch.onnx.name_scopes",
              "value": "['', 'model', 'model.layers.0', 'model.layers.0.self_attn', 'model.layers.0.self_attn.o_proj', 'linear_3']"
            },
            {
              "key": "[metadata] pkg.torch.onnx.stack_trace",
              "value": "File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 688, in forward\n    outputs: BaseModelOutputWithPast = self.model(\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 453, in forward\n    layer_outputs = decoder_layer(\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 308, in forward\n    hidden_states, self_attn_weights = self.self_attn(\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 277, in forward\n    attn_output = self.o_proj(attn_output)\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/torch/nn/modules/linear.py\", line 125, in forward\n    return F.linear(input, self.weight, self.bias)"
            }
          ],
          "incomingEdges": [
            {
              "sourceNodeId": "node_MultiHeadAttention_62",
              "sourceNodeOutputId": "0",
              "targetNodeInputId": "0"
            },
            {
              "sourceNodeId": "[value] val_350",
              "sourceNodeOutputId": "0",
              "targetNodeInputId": "1"
            }
          ],
          "outputsMetadata": [
            {
              "id": "0",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "linear_3"
                },
                {
                  "key": "tensor_shape",
                  "value": "FLOAT[s34,s16,2048]"
                },
                {
                  "key": "param_name",
                  "value": "Y"
                }
              ]
            }
          ],
          "inputsMetadata": [
            {
              "id": "0",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "view_4"
                },
                {
                  "key": "tensor_shape",
                  "value": "FLOAT[s34,s16,2048]"
                },
                {
                  "key": "param_name",
                  "value": "A"
                }
              ]
            },
            {
              "id": "1",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "val_350"
                },
                {
                  "key": "tensor_shape",
                  "value": "FLOAT[2048,2048]"
                },
                {
                  "key": "param_name",
                  "value": "B"
                }
              ]
            }
          ],
          "style": null,
          "config": null
        },
        {
          "id": "node_SkipSimplifiedLayerNormalization_21",
          "label": "com.microsoft::SkipSimplifiedLayerNormalization",
          "namespace": "main_graph",
          "subgraphIds": [],
          "attrs": [
            {
              "key": "epsilon",
              "value": "9.999999747378752e-06"
            }
          ],
          "incomingEdges": [
            {
              "sourceNodeId": "node_MatMul_478",
              "sourceNodeOutputId": "0",
              "targetNodeInputId": "0"
            },
            {
              "sourceNodeId": "node_Gather_20",
              "sourceNodeOutputId": "0",
              "targetNodeInputId": "1"
            },
            {
              "sourceNodeId": "[value] model.layers.0.post_attention_layernorm.weight",
              "sourceNodeOutputId": "0",
              "targetNodeInputId": "2"
            }
          ],
          "outputsMetadata": [
            {
              "id": "0",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "mul_352"
                },
                {
                  "key": "tensor_shape",
                  "value": "FLOAT[s34,s16,2048]"
                }
              ]
            },
            {
              "id": "1",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "val_2"
                },
                {
                  "key": "tensor_shape",
                  "value": "?[?]"
                },
                {
                  "key": "unused",
                  "value": "True"
                }
              ]
            },
            {
              "id": "2",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "val_3"
                },
                {
                  "key": "tensor_shape",
                  "value": "?[?]"
                },
                {
                  "key": "unused",
                  "value": "True"
                }
              ]
            },
            {
              "id": "3",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "add_413"
                },
                {
                  "key": "tensor_shape",
                  "value": "FLOAT[s34,s16,2048]"
                }
              ]
            }
          ],
          "inputsMetadata": [
            {
              "id": "0",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "linear_3"
                },
                {
                  "key": "tensor_shape",
                  "value": "FLOAT[s34,s16,2048]"
                }
              ]
            },
            {
              "id": "1",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "embedding"
                },
                {
                  "key": "tensor_shape",
                  "value": "FLOAT[s34,s16,2048]"
                }
              ]
            },
            {
              "id": "2",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "model.layers.0.post_attention_layernorm.weight"
                },
                {
                  "key": "tensor_shape",
                  "value": "FLOAT[2048]"
                }
              ]
            }
          ],
          "style": null,
          "config": null
        },
        {
          "id": "node_MatMul_491",
          "label": "MatMul",
          "namespace": "main_graph/: transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/model.layers.0: transformers.models.llama.modeling_llama.LlamaDecoderLayer/model.layers.0.mlp: transformers.models.llama.modeling_llama.LlamaMLP/model.layers.0.mlp.gate_proj: torch.nn.modules.linear.Linear/linear_4: aten.linear.default",
          "subgraphIds": [],
          "attrs": [
            {
              "key": "[metadata] namespace",
              "value": ": transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/model.layers.0: transformers.models.llama.modeling_llama.LlamaDecoderLayer/model.layers.0.mlp: transformers.models.llama.modeling_llama.LlamaMLP/model.layers.0.mlp.gate_proj: torch.nn.modules.linear.Linear/linear_4: aten.linear.default"
            },
            {
              "key": "[metadata] pkg.torch.onnx.class_hierarchy",
              "value": "['transformers.models.llama.modeling_llama.LlamaForCausalLM', 'transformers.models.llama.modeling_llama.LlamaModel', 'transformers.models.llama.modeling_llama.LlamaDecoderLayer', 'transformers.models.llama.modeling_llama.LlamaMLP', 'torch.nn.modules.linear.Linear', 'aten.linear.default']"
            },
            {
              "key": "[metadata] pkg.torch.onnx.fx_node",
              "value": "%linear_4 : [num_users=1] = call_function[target=torch.ops.aten.linear.default](args = (%mul_352, %p_model_layers_0_mlp_gate_proj_weight), kwargs = {})"
            },
            {
              "key": "[metadata] pkg.torch.onnx.name_scopes",
              "value": "['', 'model', 'model.layers.0', 'model.layers.0.mlp', 'model.layers.0.mlp.gate_proj', 'linear_4']"
            },
            {
              "key": "[metadata] pkg.torch.onnx.stack_trace",
              "value": "File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 688, in forward\n    outputs: BaseModelOutputWithPast = self.model(\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 453, in forward\n    layer_outputs = decoder_layer(\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 324, in forward\n    hidden_states = self.mlp(hidden_states)\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 162, in forward\n    down_proj = self.down_proj(self.act_fn(self.gate_proj(x)) * self.up_proj(x))\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/torch/nn/modules/linear.py\", line 125, in forward\n    return F.linear(input, self.weight, self.bias)"
            }
          ],
          "incomingEdges": [
            {
              "sourceNodeId": "node_SkipSimplifiedLayerNormalization_21",
              "sourceNodeOutputId": "0",
              "targetNodeInputId": "0"
            },
            {
              "sourceNodeId": "[value] val_355",
              "sourceNodeOutputId": "0",
              "targetNodeInputId": "1"
            }
          ],
          "outputsMetadata": [
            {
              "id": "0",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "linear_4"
                },
                {
                  "key": "tensor_shape",
                  "value": "FLOAT[s34,s16,8192]"
                },
                {
                  "key": "param_name",
                  "value": "Y"
                }
              ]
            }
          ],
          "inputsMetadata": [
            {
              "id": "0",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "mul_352"
                },
                {
                  "key": "tensor_shape",
                  "value": "FLOAT[s34,s16,2048]"
                },
                {
                  "key": "param_name",
                  "value": "A"
                }
              ]
            },
            {
              "id": "1",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "val_355"
                },
                {
                  "key": "tensor_shape",
                  "value": "FLOAT[2048,8192]"
                },
                {
                  "key": "param_name",
                  "value": "B"
                }
              ]
            }
          ],
          "style": null,
          "config": null
        },
        {
          "id": "node_Sigmoid_492",
          "label": "Sigmoid",
          "namespace": "main_graph/: transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/model.layers.0: transformers.models.llama.modeling_llama.LlamaDecoderLayer/model.layers.0.mlp: transformers.models.llama.modeling_llama.LlamaMLP/model.layers.0.mlp.act_fn: torch.nn.modules.activation.SiLU/silu: aten.silu.default",
          "subgraphIds": [],
          "attrs": [
            {
              "key": "[metadata] namespace",
              "value": ": transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/model.layers.0: transformers.models.llama.modeling_llama.LlamaDecoderLayer/model.layers.0.mlp: transformers.models.llama.modeling_llama.LlamaMLP/model.layers.0.mlp.act_fn: torch.nn.modules.activation.SiLU/silu: aten.silu.default"
            },
            {
              "key": "[metadata] pkg.torch.onnx.class_hierarchy",
              "value": "['transformers.models.llama.modeling_llama.LlamaForCausalLM', 'transformers.models.llama.modeling_llama.LlamaModel', 'transformers.models.llama.modeling_llama.LlamaDecoderLayer', 'transformers.models.llama.modeling_llama.LlamaMLP', 'torch.nn.modules.activation.SiLU', 'aten.silu.default']"
            },
            {
              "key": "[metadata] pkg.torch.onnx.fx_node",
              "value": "%silu : [num_users=1] = call_function[target=torch.ops.aten.silu.default](args = (%linear_4,), kwargs = {})"
            },
            {
              "key": "[metadata] pkg.torch.onnx.name_scopes",
              "value": "['', 'model', 'model.layers.0', 'model.layers.0.mlp', 'model.layers.0.mlp.act_fn', 'silu']"
            },
            {
              "key": "[metadata] pkg.torch.onnx.stack_trace",
              "value": "File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 688, in forward\n    outputs: BaseModelOutputWithPast = self.model(\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 453, in forward\n    layer_outputs = decoder_layer(\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 324, in forward\n    hidden_states = self.mlp(hidden_states)\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 162, in forward\n    down_proj = self.down_proj(self.act_fn(self.gate_proj(x)) * self.up_proj(x))\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/torch/nn/modules/activation.py\", line 434, in forward\n    return F.silu(input, inplace=self.inplace)"
            }
          ],
          "incomingEdges": [
            {
              "sourceNodeId": "node_MatMul_491",
              "sourceNodeOutputId": "0",
              "targetNodeInputId": "0"
            }
          ],
          "outputsMetadata": [
            {
              "id": "0",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "val_356"
                },
                {
                  "key": "tensor_shape",
                  "value": "FLOAT[s34,s16,8192]"
                },
                {
                  "key": "param_name",
                  "value": "Y"
                }
              ]
            }
          ],
          "inputsMetadata": [
            {
              "id": "0",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "linear_4"
                },
                {
                  "key": "tensor_shape",
                  "value": "FLOAT[s34,s16,8192]"
                },
                {
                  "key": "param_name",
                  "value": "X"
                }
              ]
            }
          ],
          "style": null,
          "config": null
        },
        {
          "id": "node_Mul_493",
          "label": "Mul",
          "namespace": "main_graph/: transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/model.layers.0: transformers.models.llama.modeling_llama.LlamaDecoderLayer/model.layers.0.mlp: transformers.models.llama.modeling_llama.LlamaMLP/model.layers.0.mlp.act_fn: torch.nn.modules.activation.SiLU/silu: aten.silu.default",
          "subgraphIds": [],
          "attrs": [
            {
              "key": "[metadata] namespace",
              "value": ": transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/model.layers.0: transformers.models.llama.modeling_llama.LlamaDecoderLayer/model.layers.0.mlp: transformers.models.llama.modeling_llama.LlamaMLP/model.layers.0.mlp.act_fn: torch.nn.modules.activation.SiLU/silu: aten.silu.default"
            },
            {
              "key": "[metadata] pkg.torch.onnx.class_hierarchy",
              "value": "['transformers.models.llama.modeling_llama.LlamaForCausalLM', 'transformers.models.llama.modeling_llama.LlamaModel', 'transformers.models.llama.modeling_llama.LlamaDecoderLayer', 'transformers.models.llama.modeling_llama.LlamaMLP', 'torch.nn.modules.activation.SiLU', 'aten.silu.default']"
            },
            {
              "key": "[metadata] pkg.torch.onnx.fx_node",
              "value": "%silu : [num_users=1] = call_function[target=torch.ops.aten.silu.default](args = (%linear_4,), kwargs = {})"
            },
            {
              "key": "[metadata] pkg.torch.onnx.name_scopes",
              "value": "['', 'model', 'model.layers.0', 'model.layers.0.mlp', 'model.layers.0.mlp.act_fn', 'silu']"
            },
            {
              "key": "[metadata] pkg.torch.onnx.stack_trace",
              "value": "File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 688, in forward\n    outputs: BaseModelOutputWithPast = self.model(\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 453, in forward\n    layer_outputs = decoder_layer(\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 324, in forward\n    hidden_states = self.mlp(hidden_states)\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 162, in forward\n    down_proj = self.down_proj(self.act_fn(self.gate_proj(x)) * self.up_proj(x))\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/torch/nn/modules/activation.py\", line 434, in forward\n    return F.silu(input, inplace=self.inplace)"
            }
          ],
          "incomingEdges": [
            {
              "sourceNodeId": "node_MatMul_491",
              "sourceNodeOutputId": "0",
              "targetNodeInputId": "0"
            },
            {
              "sourceNodeId": "node_Sigmoid_492",
              "sourceNodeOutputId": "0",
              "targetNodeInputId": "1"
            }
          ],
          "outputsMetadata": [
            {
              "id": "0",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "silu"
                },
                {
                  "key": "tensor_shape",
                  "value": "FLOAT[s34,s16,8192]"
                },
                {
                  "key": "param_name",
                  "value": "C"
                }
              ]
            }
          ],
          "inputsMetadata": [
            {
              "id": "0",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "linear_4"
                },
                {
                  "key": "tensor_shape",
                  "value": "FLOAT[s34,s16,8192]"
                },
                {
                  "key": "param_name",
                  "value": "A"
                }
              ]
            },
            {
              "id": "1",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "val_356"
                },
                {
                  "key": "tensor_shape",
                  "value": "FLOAT[s34,s16,8192]"
                },
                {
                  "key": "param_name",
                  "value": "B"
                }
              ]
            }
          ],
          "style": null,
          "config": null
        },
        {
          "id": "node_MatMul_495",
          "label": "MatMul",
          "namespace": "main_graph/: transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/model.layers.0: transformers.models.llama.modeling_llama.LlamaDecoderLayer/model.layers.0.mlp: transformers.models.llama.modeling_llama.LlamaMLP/model.layers.0.mlp.up_proj: torch.nn.modules.linear.Linear/linear_5: aten.linear.default",
          "subgraphIds": [],
          "attrs": [
            {
              "key": "[metadata] namespace",
              "value": ": transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/model.layers.0: transformers.models.llama.modeling_llama.LlamaDecoderLayer/model.layers.0.mlp: transformers.models.llama.modeling_llama.LlamaMLP/model.layers.0.mlp.up_proj: torch.nn.modules.linear.Linear/linear_5: aten.linear.default"
            },
            {
              "key": "[metadata] pkg.torch.onnx.class_hierarchy",
              "value": "['transformers.models.llama.modeling_llama.LlamaForCausalLM', 'transformers.models.llama.modeling_llama.LlamaModel', 'transformers.models.llama.modeling_llama.LlamaDecoderLayer', 'transformers.models.llama.modeling_llama.LlamaMLP', 'torch.nn.modules.linear.Linear', 'aten.linear.default']"
            },
            {
              "key": "[metadata] pkg.torch.onnx.fx_node",
              "value": "%linear_5 : [num_users=1] = call_function[target=torch.ops.aten.linear.default](args = (%mul_352, %p_model_layers_0_mlp_up_proj_weight), kwargs = {})"
            },
            {
              "key": "[metadata] pkg.torch.onnx.name_scopes",
              "value": "['', 'model', 'model.layers.0', 'model.layers.0.mlp', 'model.layers.0.mlp.up_proj', 'linear_5']"
            },
            {
              "key": "[metadata] pkg.torch.onnx.stack_trace",
              "value": "File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 688, in forward\n    outputs: BaseModelOutputWithPast = self.model(\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 453, in forward\n    layer_outputs = decoder_layer(\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 324, in forward\n    hidden_states = self.mlp(hidden_states)\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 162, in forward\n    down_proj = self.down_proj(self.act_fn(self.gate_proj(x)) * self.up_proj(x))\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/torch/nn/modules/linear.py\", line 125, in forward\n    return F.linear(input, self.weight, self.bias)"
            }
          ],
          "incomingEdges": [
            {
              "sourceNodeId": "node_SkipSimplifiedLayerNormalization_21",
              "sourceNodeOutputId": "0",
              "targetNodeInputId": "0"
            },
            {
              "sourceNodeId": "[value] val_357",
              "sourceNodeOutputId": "0",
              "targetNodeInputId": "1"
            }
          ],
          "outputsMetadata": [
            {
              "id": "0",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "linear_5"
                },
                {
                  "key": "tensor_shape",
                  "value": "FLOAT[s34,s16,8192]"
                },
                {
                  "key": "param_name",
                  "value": "Y"
                }
              ]
            }
          ],
          "inputsMetadata": [
            {
              "id": "0",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "mul_352"
                },
                {
                  "key": "tensor_shape",
                  "value": "FLOAT[s34,s16,2048]"
                },
                {
                  "key": "param_name",
                  "value": "A"
                }
              ]
            },
            {
              "id": "1",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "val_357"
                },
                {
                  "key": "tensor_shape",
                  "value": "FLOAT[2048,8192]"
                },
                {
                  "key": "param_name",
                  "value": "B"
                }
              ]
            }
          ],
          "style": null,
          "config": null
        },
        {
          "id": "node_Mul_496",
          "label": "Mul",
          "namespace": "main_graph/: transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/model.layers.0: transformers.models.llama.modeling_llama.LlamaDecoderLayer/model.layers.0.mlp: transformers.models.llama.modeling_llama.LlamaMLP/mul_365: aten.mul.Tensor",
          "subgraphIds": [],
          "attrs": [
            {
              "key": "[metadata] namespace",
              "value": ": transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/model.layers.0: transformers.models.llama.modeling_llama.LlamaDecoderLayer/model.layers.0.mlp: transformers.models.llama.modeling_llama.LlamaMLP/mul_365: aten.mul.Tensor"
            },
            {
              "key": "[metadata] pkg.torch.onnx.class_hierarchy",
              "value": "['transformers.models.llama.modeling_llama.LlamaForCausalLM', 'transformers.models.llama.modeling_llama.LlamaModel', 'transformers.models.llama.modeling_llama.LlamaDecoderLayer', 'transformers.models.llama.modeling_llama.LlamaMLP', 'aten.mul.Tensor']"
            },
            {
              "key": "[metadata] pkg.torch.onnx.fx_node",
              "value": "%mul_365 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%silu, %linear_5), kwargs = {})"
            },
            {
              "key": "[metadata] pkg.torch.onnx.name_scopes",
              "value": "['', 'model', 'model.layers.0', 'model.layers.0.mlp', 'mul_365']"
            },
            {
              "key": "[metadata] pkg.torch.onnx.stack_trace",
              "value": "File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 688, in forward\n    outputs: BaseModelOutputWithPast = self.model(\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 453, in forward\n    layer_outputs = decoder_layer(\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 324, in forward\n    hidden_states = self.mlp(hidden_states)\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 162, in forward\n    down_proj = self.down_proj(self.act_fn(self.gate_proj(x)) * self.up_proj(x))"
            }
          ],
          "incomingEdges": [
            {
              "sourceNodeId": "node_Mul_493",
              "sourceNodeOutputId": "0",
              "targetNodeInputId": "0"
            },
            {
              "sourceNodeId": "node_MatMul_495",
              "sourceNodeOutputId": "0",
              "targetNodeInputId": "1"
            }
          ],
          "outputsMetadata": [
            {
              "id": "0",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "mul_365"
                },
                {
                  "key": "tensor_shape",
                  "value": "FLOAT[s34,s16,8192]"
                },
                {
                  "key": "param_name",
                  "value": "C"
                }
              ]
            }
          ],
          "inputsMetadata": [
            {
              "id": "0",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "silu"
                },
                {
                  "key": "tensor_shape",
                  "value": "FLOAT[s34,s16,8192]"
                },
                {
                  "key": "param_name",
                  "value": "A"
                }
              ]
            },
            {
              "id": "1",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "linear_5"
                },
                {
                  "key": "tensor_shape",
                  "value": "FLOAT[s34,s16,8192]"
                },
                {
                  "key": "param_name",
                  "value": "B"
                }
              ]
            }
          ],
          "style": null,
          "config": null
        },
        {
          "id": "node_MatMul_498",
          "label": "MatMul",
          "namespace": "main_graph/: transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/model.layers.0: transformers.models.llama.modeling_llama.LlamaDecoderLayer/model.layers.0.mlp: transformers.models.llama.modeling_llama.LlamaMLP/model.layers.0.mlp.down_proj: torch.nn.modules.linear.Linear/linear_6: aten.linear.default",
          "subgraphIds": [],
          "attrs": [
            {
              "key": "[metadata] namespace",
              "value": ": transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/model.layers.0: transformers.models.llama.modeling_llama.LlamaDecoderLayer/model.layers.0.mlp: transformers.models.llama.modeling_llama.LlamaMLP/model.layers.0.mlp.down_proj: torch.nn.modules.linear.Linear/linear_6: aten.linear.default"
            },
            {
              "key": "[metadata] pkg.torch.onnx.class_hierarchy",
              "value": "['transformers.models.llama.modeling_llama.LlamaForCausalLM', 'transformers.models.llama.modeling_llama.LlamaModel', 'transformers.models.llama.modeling_llama.LlamaDecoderLayer', 'transformers.models.llama.modeling_llama.LlamaMLP', 'torch.nn.modules.linear.Linear', 'aten.linear.default']"
            },
            {
              "key": "[metadata] pkg.torch.onnx.fx_node",
              "value": "%linear_6 : [num_users=1] = call_function[target=torch.ops.aten.linear.default](args = (%mul_365, %p_model_layers_0_mlp_down_proj_weight), kwargs = {})"
            },
            {
              "key": "[metadata] pkg.torch.onnx.name_scopes",
              "value": "['', 'model', 'model.layers.0', 'model.layers.0.mlp', 'model.layers.0.mlp.down_proj', 'linear_6']"
            },
            {
              "key": "[metadata] pkg.torch.onnx.stack_trace",
              "value": "File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 688, in forward\n    outputs: BaseModelOutputWithPast = self.model(\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 453, in forward\n    layer_outputs = decoder_layer(\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 324, in forward\n    hidden_states = self.mlp(hidden_states)\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 162, in forward\n    down_proj = self.down_proj(self.act_fn(self.gate_proj(x)) * self.up_proj(x))\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/torch/nn/modules/linear.py\", line 125, in forward\n    return F.linear(input, self.weight, self.bias)"
            }
          ],
          "incomingEdges": [
            {
              "sourceNodeId": "node_Mul_496",
              "sourceNodeOutputId": "0",
              "targetNodeInputId": "0"
            },
            {
              "sourceNodeId": "[value] val_358",
              "sourceNodeOutputId": "0",
              "targetNodeInputId": "1"
            }
          ],
          "outputsMetadata": [
            {
              "id": "0",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "linear_6"
                },
                {
                  "key": "tensor_shape",
                  "value": "FLOAT[s34,s16,2048]"
                },
                {
                  "key": "param_name",
                  "value": "Y"
                }
              ]
            }
          ],
          "inputsMetadata": [
            {
              "id": "0",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "mul_365"
                },
                {
                  "key": "tensor_shape",
                  "value": "FLOAT[s34,s16,8192]"
                },
                {
                  "key": "param_name",
                  "value": "A"
                }
              ]
            },
            {
              "id": "1",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "val_358"
                },
                {
                  "key": "tensor_shape",
                  "value": "FLOAT[8192,2048]"
                },
                {
                  "key": "param_name",
                  "value": "B"
                }
              ]
            }
          ],
          "style": null,
          "config": null
        },
        {
          "id": "node_SkipSimplifiedLayerNormalization_22",
          "label": "com.microsoft::SkipSimplifiedLayerNormalization",
          "namespace": "main_graph",
          "subgraphIds": [],
          "attrs": [
            {
              "key": "epsilon",
              "value": "9.999999747378752e-06"
            }
          ],
          "incomingEdges": [
            {
              "sourceNodeId": "node_MatMul_498",
              "sourceNodeOutputId": "0",
              "targetNodeInputId": "0"
            },
            {
              "sourceNodeId": "node_SkipSimplifiedLayerNormalization_21",
              "sourceNodeOutputId": "3",
              "targetNodeInputId": "1"
            },
            {
              "sourceNodeId": "[value] model.layers.1.input_layernorm.weight",
              "sourceNodeOutputId": "0",
              "targetNodeInputId": "2"
            }
          ],
          "outputsMetadata": [
            {
              "id": "0",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "mul_388"
                },
                {
                  "key": "tensor_shape",
                  "value": "FLOAT[s34,s16,2048]"
                }
              ]
            },
            {
              "id": "1",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "val_4"
                },
                {
                  "key": "tensor_shape",
                  "value": "?[?]"
                },
                {
                  "key": "unused",
                  "value": "True"
                }
              ]
            },
            {
              "id": "2",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "val_7"
                },
                {
                  "key": "tensor_shape",
                  "value": "?[?]"
                },
                {
                  "key": "unused",
                  "value": "True"
                }
              ]
            },
            {
              "id": "3",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "add_463"
                },
                {
                  "key": "tensor_shape",
                  "value": "FLOAT[s34,s16,2048]"
                }
              ]
            }
          ],
          "inputsMetadata": [
            {
              "id": "0",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "linear_6"
                },
                {
                  "key": "tensor_shape",
                  "value": "FLOAT[s34,s16,2048]"
                }
              ]
            },
            {
              "id": "1",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "add_413"
                },
                {
                  "key": "tensor_shape",
                  "value": "FLOAT[s34,s16,2048]"
                }
              ]
            },
            {
              "id": "2",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "model.layers.1.input_layernorm.weight"
                },
                {
                  "key": "tensor_shape",
                  "value": "FLOAT[2048]"
                }
              ]
            }
          ],
          "style": null,
          "config": null
        },
        {
          "id": "node_MatMul_511",
          "label": "MatMul",
          "namespace": "main_graph/: transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/model.layers.1: transformers.models.llama.modeling_llama.LlamaDecoderLayer/model.layers.1.self_attn: transformers.models.llama.modeling_llama.LlamaAttention/model.layers.1.self_attn.q_proj: torch.nn.modules.linear.Linear/linear_7: aten.linear.default",
          "subgraphIds": [],
          "attrs": [
            {
              "key": "[metadata] namespace",
              "value": ": transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/model.layers.1: transformers.models.llama.modeling_llama.LlamaDecoderLayer/model.layers.1.self_attn: transformers.models.llama.modeling_llama.LlamaAttention/model.layers.1.self_attn.q_proj: torch.nn.modules.linear.Linear/linear_7: aten.linear.default"
            },
            {
              "key": "[metadata] pkg.torch.onnx.class_hierarchy",
              "value": "['transformers.models.llama.modeling_llama.LlamaForCausalLM', 'transformers.models.llama.modeling_llama.LlamaModel', 'transformers.models.llama.modeling_llama.LlamaDecoderLayer', 'transformers.models.llama.modeling_llama.LlamaAttention', 'torch.nn.modules.linear.Linear', 'aten.linear.default']"
            },
            {
              "key": "[metadata] pkg.torch.onnx.fx_node",
              "value": "%linear_7 : [num_users=1] = call_function[target=torch.ops.aten.linear.default](args = (%mul_388, %p_model_layers_1_self_attn_q_proj_weight), kwargs = {})"
            },
            {
              "key": "[metadata] pkg.torch.onnx.name_scopes",
              "value": "['', 'model', 'model.layers.1', 'model.layers.1.self_attn', 'model.layers.1.self_attn.q_proj', 'linear_7']"
            },
            {
              "key": "[metadata] pkg.torch.onnx.stack_trace",
              "value": "File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 688, in forward\n    outputs: BaseModelOutputWithPast = self.model(\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 453, in forward\n    layer_outputs = decoder_layer(\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 308, in forward\n    hidden_states, self_attn_weights = self.self_attn(\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 242, in forward\n    query_states = self.q_proj(hidden_states).view(hidden_shape).transpose(1, 2)\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/torch/nn/modules/linear.py\", line 125, in forward\n    return F.linear(input, self.weight, self.bias)"
            }
          ],
          "incomingEdges": [
            {
              "sourceNodeId": "node_SkipSimplifiedLayerNormalization_22",
              "sourceNodeOutputId": "0",
              "targetNodeInputId": "0"
            },
            {
              "sourceNodeId": "[value] val_363",
              "sourceNodeOutputId": "0",
              "targetNodeInputId": "1"
            }
          ],
          "outputsMetadata": [
            {
              "id": "0",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "linear_7"
                },
                {
                  "key": "tensor_shape",
                  "value": "FLOAT[s34,s16,2048]"
                },
                {
                  "key": "param_name",
                  "value": "Y"
                }
              ]
            }
          ],
          "inputsMetadata": [
            {
              "id": "0",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "mul_388"
                },
                {
                  "key": "tensor_shape",
                  "value": "FLOAT[s34,s16,2048]"
                },
                {
                  "key": "param_name",
                  "value": "A"
                }
              ]
            },
            {
              "id": "1",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "val_363"
                },
                {
                  "key": "tensor_shape",
                  "value": "FLOAT[2048,2048]"
                },
                {
                  "key": "param_name",
                  "value": "B"
                }
              ]
            }
          ],
          "style": null,
          "config": null
        },
        {
          "id": "node_MatMul_521",
          "label": "MatMul",
          "namespace": "main_graph/: transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/model.layers.1: transformers.models.llama.modeling_llama.LlamaDecoderLayer/model.layers.1.self_attn: transformers.models.llama.modeling_llama.LlamaAttention/model.layers.1.self_attn.k_proj: torch.nn.modules.linear.Linear/linear_8: aten.linear.default",
          "subgraphIds": [],
          "attrs": [
            {
              "key": "[metadata] namespace",
              "value": ": transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/model.layers.1: transformers.models.llama.modeling_llama.LlamaDecoderLayer/model.layers.1.self_attn: transformers.models.llama.modeling_llama.LlamaAttention/model.layers.1.self_attn.k_proj: torch.nn.modules.linear.Linear/linear_8: aten.linear.default"
            },
            {
              "key": "[metadata] pkg.torch.onnx.class_hierarchy",
              "value": "['transformers.models.llama.modeling_llama.LlamaForCausalLM', 'transformers.models.llama.modeling_llama.LlamaModel', 'transformers.models.llama.modeling_llama.LlamaDecoderLayer', 'transformers.models.llama.modeling_llama.LlamaAttention', 'torch.nn.modules.linear.Linear', 'aten.linear.default']"
            },
            {
              "key": "[metadata] pkg.torch.onnx.fx_node",
              "value": "%linear_8 : [num_users=1] = call_function[target=torch.ops.aten.linear.default](args = (%mul_388, %p_model_layers_1_self_attn_k_proj_weight), kwargs = {})"
            },
            {
              "key": "[metadata] pkg.torch.onnx.name_scopes",
              "value": "['', 'model', 'model.layers.1', 'model.layers.1.self_attn', 'model.layers.1.self_attn.k_proj', 'linear_8']"
            },
            {
              "key": "[metadata] pkg.torch.onnx.stack_trace",
              "value": "File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 688, in forward\n    outputs: BaseModelOutputWithPast = self.model(\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 453, in forward\n    layer_outputs = decoder_layer(\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 308, in forward\n    hidden_states, self_attn_weights = self.self_attn(\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 243, in forward\n    key_states = self.k_proj(hidden_states).view(hidden_shape).transpose(1, 2)\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/torch/nn/modules/linear.py\", line 125, in forward\n    return F.linear(input, self.weight, self.bias)"
            }
          ],
          "incomingEdges": [
            {
              "sourceNodeId": "node_SkipSimplifiedLayerNormalization_22",
              "sourceNodeOutputId": "0",
              "targetNodeInputId": "0"
            },
            {
              "sourceNodeId": "[value] val_370",
              "sourceNodeOutputId": "0",
              "targetNodeInputId": "1"
            }
          ],
          "outputsMetadata": [
            {
              "id": "0",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "linear_8"
                },
                {
                  "key": "tensor_shape",
                  "value": "FLOAT[s34,s16,2048]"
                },
                {
                  "key": "param_name",
                  "value": "Y"
                }
              ]
            }
          ],
          "inputsMetadata": [
            {
              "id": "0",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "mul_388"
                },
                {
                  "key": "tensor_shape",
                  "value": "FLOAT[s34,s16,2048]"
                },
                {
                  "key": "param_name",
                  "value": "A"
                }
              ]
            },
            {
              "id": "1",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "val_370"
                },
                {
                  "key": "tensor_shape",
                  "value": "FLOAT[2048,2048]"
                },
                {
                  "key": "param_name",
                  "value": "B"
                }
              ]
            }
          ],
          "style": null,
          "config": null
        },
        {
          "id": "node_MatMul_531",
          "label": "MatMul",
          "namespace": "main_graph/: transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/model.layers.1: transformers.models.llama.modeling_llama.LlamaDecoderLayer/model.layers.1.self_attn: transformers.models.llama.modeling_llama.LlamaAttention/model.layers.1.self_attn.v_proj: torch.nn.modules.linear.Linear/linear_9: aten.linear.default",
          "subgraphIds": [],
          "attrs": [
            {
              "key": "[metadata] namespace",
              "value": ": transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/model.layers.1: transformers.models.llama.modeling_llama.LlamaDecoderLayer/model.layers.1.self_attn: transformers.models.llama.modeling_llama.LlamaAttention/model.layers.1.self_attn.v_proj: torch.nn.modules.linear.Linear/linear_9: aten.linear.default"
            },
            {
              "key": "[metadata] pkg.torch.onnx.class_hierarchy",
              "value": "['transformers.models.llama.modeling_llama.LlamaForCausalLM', 'transformers.models.llama.modeling_llama.LlamaModel', 'transformers.models.llama.modeling_llama.LlamaDecoderLayer', 'transformers.models.llama.modeling_llama.LlamaAttention', 'torch.nn.modules.linear.Linear', 'aten.linear.default']"
            },
            {
              "key": "[metadata] pkg.torch.onnx.fx_node",
              "value": "%linear_9 : [num_users=1] = call_function[target=torch.ops.aten.linear.default](args = (%mul_388, %p_model_layers_1_self_attn_v_proj_weight), kwargs = {})"
            },
            {
              "key": "[metadata] pkg.torch.onnx.name_scopes",
              "value": "['', 'model', 'model.layers.1', 'model.layers.1.self_attn', 'model.layers.1.self_attn.v_proj', 'linear_9']"
            },
            {
              "key": "[metadata] pkg.torch.onnx.stack_trace",
              "value": "File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 688, in forward\n    outputs: BaseModelOutputWithPast = self.model(\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 453, in forward\n    layer_outputs = decoder_layer(\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 308, in forward\n    hidden_states, self_attn_weights = self.self_attn(\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 244, in forward\n    value_states = self.v_proj(hidden_states).view(hidden_shape).transpose(1, 2)\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/torch/nn/modules/linear.py\", line 125, in forward\n    return F.linear(input, self.weight, self.bias)"
            }
          ],
          "incomingEdges": [
            {
              "sourceNodeId": "node_SkipSimplifiedLayerNormalization_22",
              "sourceNodeOutputId": "0",
              "targetNodeInputId": "0"
            },
            {
              "sourceNodeId": "[value] val_377",
              "sourceNodeOutputId": "0",
              "targetNodeInputId": "1"
            }
          ],
          "outputsMetadata": [
            {
              "id": "0",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "linear_9"
                },
                {
                  "key": "tensor_shape",
                  "value": "FLOAT[s34,s16,2048]"
                },
                {
                  "key": "param_name",
                  "value": "Y"
                }
              ]
            }
          ],
          "inputsMetadata": [
            {
              "id": "0",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "mul_388"
                },
                {
                  "key": "tensor_shape",
                  "value": "FLOAT[s34,s16,2048]"
                },
                {
                  "key": "param_name",
                  "value": "A"
                }
              ]
            },
            {
              "id": "1",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "val_377"
                },
                {
                  "key": "tensor_shape",
                  "value": "FLOAT[2048,2048]"
                },
                {
                  "key": "param_name",
                  "value": "B"
                }
              ]
            }
          ],
          "style": null,
          "config": null
        },
        {
          "id": "node_Constant_977",
          "label": "Constant",
          "namespace": "main_graph/: transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/model.layers.1: transformers.models.llama.modeling_llama.LlamaDecoderLayer/model.layers.1.self_attn: transformers.models.llama.modeling_llama.LlamaAttention/slice_49: aten.slice.Tensor",
          "subgraphIds": [],
          "attrs": [
            {
              "key": "__value",
              "value": "[3]"
            },
            {
              "key": "value",
              "value": "TensorProtoTensor<INT64,[1]>(array([3]), name='val_448')"
            }
          ],
          "incomingEdges": [],
          "outputsMetadata": [
            {
              "id": "0",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "val_448"
                },
                {
                  "key": "tensor_shape",
                  "value": "INT64[1]"
                },
                {
                  "key": "param_name",
                  "value": "output"
                }
              ]
            }
          ],
          "inputsMetadata": [],
          "style": null,
          "config": null
        },
        {
          "id": "node_Slice_630",
          "label": "Slice",
          "namespace": "main_graph/: transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/model.layers.1: transformers.models.llama.modeling_llama.LlamaDecoderLayer/model.layers.1.self_attn: transformers.models.llama.modeling_llama.LlamaAttention/slice_49: aten.slice.Tensor",
          "subgraphIds": [],
          "attrs": [
            {
              "key": "[metadata] namespace",
              "value": ": transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/model.layers.1: transformers.models.llama.modeling_llama.LlamaDecoderLayer/model.layers.1.self_attn: transformers.models.llama.modeling_llama.LlamaAttention/slice_49: aten.slice.Tensor"
            },
            {
              "key": "[metadata] pkg.torch.onnx.class_hierarchy",
              "value": "['transformers.models.llama.modeling_llama.LlamaForCausalLM', 'transformers.models.llama.modeling_llama.LlamaModel', 'transformers.models.llama.modeling_llama.LlamaDecoderLayer', 'transformers.models.llama.modeling_llama.LlamaAttention', 'aten.slice.Tensor']"
            },
            {
              "key": "[metadata] pkg.torch.onnx.fx_node",
              "value": "%slice_49 : [num_users=1] = call_function[target=torch.ops.aten.slice.Tensor](args = (%slice_48, 3, None, %add_4), kwargs = {})"
            },
            {
              "key": "[metadata] pkg.torch.onnx.name_scopes",
              "value": "['', 'model', 'model.layers.1', 'model.layers.1.self_attn', 'slice_49']"
            },
            {
              "key": "[metadata] pkg.torch.onnx.stack_trace",
              "value": "File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 688, in forward\n    outputs: BaseModelOutputWithPast = self.model(\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 453, in forward\n    layer_outputs = decoder_layer(\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 308, in forward\n    hidden_states, self_attn_weights = self.self_attn(\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 265, in forward\n    attn_output, attn_weights = attention_interface("
            }
          ],
          "incomingEdges": [
            {
              "sourceNodeId": "node_ScatterND_279",
              "sourceNodeOutputId": "0",
              "targetNodeInputId": "0"
            },
            {
              "sourceNodeId": "node_Constant_118",
              "sourceNodeOutputId": "0",
              "targetNodeInputId": "1"
            },
            {
              "sourceNodeId": "node_Reshape_121",
              "sourceNodeOutputId": "0",
              "targetNodeInputId": "2"
            },
            {
              "sourceNodeId": "node_Constant_977",
              "sourceNodeOutputId": "0",
              "targetNodeInputId": "3"
            },
            {
              "sourceNodeId": "node_Constant_125",
              "sourceNodeOutputId": "0",
              "targetNodeInputId": "4"
            }
          ],
          "outputsMetadata": [
            {
              "id": "0",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "slice_49"
                },
                {
                  "key": "tensor_shape",
                  "value": "FLOAT[s34,1,s16,s16 + s17]"
                },
                {
                  "key": "param_name",
                  "value": "output"
                }
              ]
            }
          ],
          "inputsMetadata": [
            {
              "id": "0",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "slice_scatter_2"
                },
                {
                  "key": "tensor_shape",
                  "value": "FLOAT[s34,1,s16,s16 + s17]"
                },
                {
                  "key": "param_name",
                  "value": "data"
                }
              ]
            },
            {
              "id": "1",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "val_76"
                },
                {
                  "key": "tensor_shape",
                  "value": "INT64[1]"
                },
                {
                  "key": "param_name",
                  "value": "starts"
                }
              ]
            },
            {
              "id": "2",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "val_79"
                },
                {
                  "key": "tensor_shape",
                  "value": "INT64[1]"
                },
                {
                  "key": "param_name",
                  "value": "ends"
                }
              ]
            },
            {
              "id": "3",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "val_448"
                },
                {
                  "key": "tensor_shape",
                  "value": "INT64[1]"
                },
                {
                  "key": "param_name",
                  "value": "axes"
                }
              ]
            },
            {
              "id": "4",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "val_83"
                },
                {
                  "key": "tensor_shape",
                  "value": "INT64[1]"
                },
                {
                  "key": "param_name",
                  "value": "steps"
                }
              ]
            }
          ],
          "style": null,
          "config": null
        },
        {
          "id": "node_RotaryEmbedding_65",
          "label": "com.microsoft::RotaryEmbedding",
          "namespace": "main_graph",
          "subgraphIds": [],
          "attrs": [],
          "incomingEdges": [
            {
              "sourceNodeId": "node_MatMul_511",
              "sourceNodeOutputId": "0",
              "targetNodeInputId": "0"
            },
            {
              "sourceNodeId": "node_Unsqueeze_59",
              "sourceNodeOutputId": "0",
              "targetNodeInputId": "1"
            },
            {
              "sourceNodeId": "node_Cos_42",
              "sourceNodeOutputId": "0",
              "targetNodeInputId": "2"
            },
            {
              "sourceNodeId": "node_Sin_43",
              "sourceNodeOutputId": "0",
              "targetNodeInputId": "3"
            }
          ],
          "outputsMetadata": [
            {
              "id": "0",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "val_52"
                },
                {
                  "key": "tensor_shape",
                  "value": "?[?]"
                }
              ]
            }
          ],
          "inputsMetadata": [
            {
              "id": "0",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "linear_7"
                },
                {
                  "key": "tensor_shape",
                  "value": "FLOAT[s34,s16,2048]"
                }
              ]
            },
            {
              "id": "1",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "val_47"
                },
                {
                  "key": "tensor_shape",
                  "value": "INT64[1,s16]"
                }
              ]
            },
            {
              "id": "2",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "val_36"
                },
                {
                  "key": "tensor_shape",
                  "value": "FLOAT[unk__26,32]"
                }
              ]
            },
            {
              "id": "3",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "val_37"
                },
                {
                  "key": "tensor_shape",
                  "value": "FLOAT[unk__26,32]"
                }
              ]
            }
          ],
          "style": null,
          "config": null
        },
        {
          "id": "node_RotaryEmbedding_66",
          "label": "com.microsoft::RotaryEmbedding",
          "namespace": "main_graph",
          "subgraphIds": [],
          "attrs": [],
          "incomingEdges": [
            {
              "sourceNodeId": "node_MatMul_521",
              "sourceNodeOutputId": "0",
              "targetNodeInputId": "0"
            },
            {
              "sourceNodeId": "node_Unsqueeze_59",
              "sourceNodeOutputId": "0",
              "targetNodeInputId": "1"
            },
            {
              "sourceNodeId": "node_Cos_42",
              "sourceNodeOutputId": "0",
              "targetNodeInputId": "2"
            },
            {
              "sourceNodeId": "node_Sin_43",
              "sourceNodeOutputId": "0",
              "targetNodeInputId": "3"
            }
          ],
          "outputsMetadata": [
            {
              "id": "0",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "val_55"
                },
                {
                  "key": "tensor_shape",
                  "value": "?[?]"
                }
              ]
            }
          ],
          "inputsMetadata": [
            {
              "id": "0",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "linear_8"
                },
                {
                  "key": "tensor_shape",
                  "value": "FLOAT[s34,s16,2048]"
                }
              ]
            },
            {
              "id": "1",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "val_47"
                },
                {
                  "key": "tensor_shape",
                  "value": "INT64[1,s16]"
                }
              ]
            },
            {
              "id": "2",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "val_36"
                },
                {
                  "key": "tensor_shape",
                  "value": "FLOAT[unk__26,32]"
                }
              ]
            },
            {
              "id": "3",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "val_37"
                },
                {
                  "key": "tensor_shape",
                  "value": "FLOAT[unk__26,32]"
                }
              ]
            }
          ],
          "style": null,
          "config": null
        },
        {
          "id": "node_MultiHeadAttention_67",
          "label": "com.microsoft::MultiHeadAttention",
          "namespace": "main_graph",
          "subgraphIds": [],
          "attrs": [
            {
              "key": "num_heads",
              "value": "32"
            }
          ],
          "incomingEdges": [
            {
              "sourceNodeId": "node_RotaryEmbedding_65",
              "sourceNodeOutputId": "0",
              "targetNodeInputId": "0"
            },
            {
              "sourceNodeId": "node_RotaryEmbedding_66",
              "sourceNodeOutputId": "0",
              "targetNodeInputId": "1"
            },
            {
              "sourceNodeId": "node_MatMul_531",
              "sourceNodeOutputId": "0",
              "targetNodeInputId": "2"
            },
            {
              "sourceNodeId": "node_Slice_630",
              "sourceNodeOutputId": "0",
              "targetNodeInputId": "5"
            },
            {
              "sourceNodeId": "[value] past_key_values_key_cache_1",
              "sourceNodeOutputId": "0",
              "targetNodeInputId": "6"
            },
            {
              "sourceNodeId": "[value] past_key_values_value_cache_1",
              "sourceNodeOutputId": "0",
              "targetNodeInputId": "7"
            }
          ],
          "outputsMetadata": [
            {
              "id": "0",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "view_8"
                },
                {
                  "key": "tensor_shape",
                  "value": "FLOAT[s34,s16,2048]"
                }
              ]
            },
            {
              "id": "1",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "cat_7"
                },
                {
                  "key": "tensor_shape",
                  "value": "FLOAT[s34,32,s16 + s17,64]"
                }
              ]
            },
            {
              "id": "2",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "cat_8"
                },
                {
                  "key": "tensor_shape",
                  "value": "FLOAT[s34,32,s16 + s17,64]"
                }
              ]
            }
          ],
          "inputsMetadata": [
            {
              "id": "0",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "val_52"
                },
                {
                  "key": "tensor_shape",
                  "value": "?[?]"
                }
              ]
            },
            {
              "id": "1",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "val_55"
                },
                {
                  "key": "tensor_shape",
                  "value": "?[?]"
                }
              ]
            },
            {
              "id": "2",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "linear_9"
                },
                {
                  "key": "tensor_shape",
                  "value": "FLOAT[s34,s16,2048]"
                }
              ]
            },
            {
              "id": "3",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "None"
                }
              ]
            },
            {
              "id": "4",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "None"
                }
              ]
            },
            {
              "id": "5",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "slice_49"
                },
                {
                  "key": "tensor_shape",
                  "value": "FLOAT[s34,1,s16,s16 + s17]"
                }
              ]
            },
            {
              "id": "6",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "past_key_values_key_cache_1"
                },
                {
                  "key": "tensor_shape",
                  "value": "FLOAT[s34,32,s17,64]"
                },
                {
                  "key": "[metadata] pkg.torch.export.graph_signature.InputSpec.kind",
                  "value": "USER_INPUT"
                },
                {
                  "key": "[metadata] pkg.torch.export.graph_signature.InputSpec.persistent",
                  "value": "None"
                }
              ]
            },
            {
              "id": "7",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "past_key_values_value_cache_1"
                },
                {
                  "key": "tensor_shape",
                  "value": "FLOAT[s34,32,s17,64]"
                },
                {
                  "key": "[metadata] pkg.torch.export.graph_signature.InputSpec.kind",
                  "value": "USER_INPUT"
                },
                {
                  "key": "[metadata] pkg.torch.export.graph_signature.InputSpec.persistent",
                  "value": "None"
                }
              ]
            }
          ],
          "style": null,
          "config": null
        },
        {
          "id": "node_MatMul_646",
          "label": "MatMul",
          "namespace": "main_graph/: transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/model.layers.1: transformers.models.llama.modeling_llama.LlamaDecoderLayer/model.layers.1.self_attn: transformers.models.llama.modeling_llama.LlamaAttention/model.layers.1.self_attn.o_proj: torch.nn.modules.linear.Linear/linear_10: aten.linear.default",
          "subgraphIds": [],
          "attrs": [
            {
              "key": "[metadata] namespace",
              "value": ": transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/model.layers.1: transformers.models.llama.modeling_llama.LlamaDecoderLayer/model.layers.1.self_attn: transformers.models.llama.modeling_llama.LlamaAttention/model.layers.1.self_attn.o_proj: torch.nn.modules.linear.Linear/linear_10: aten.linear.default"
            },
            {
              "key": "[metadata] pkg.torch.onnx.class_hierarchy",
              "value": "['transformers.models.llama.modeling_llama.LlamaForCausalLM', 'transformers.models.llama.modeling_llama.LlamaModel', 'transformers.models.llama.modeling_llama.LlamaDecoderLayer', 'transformers.models.llama.modeling_llama.LlamaAttention', 'torch.nn.modules.linear.Linear', 'aten.linear.default']"
            },
            {
              "key": "[metadata] pkg.torch.onnx.fx_node",
              "value": "%linear_10 : [num_users=1] = call_function[target=torch.ops.aten.linear.default](args = (%view_8, %p_model_layers_1_self_attn_o_proj_weight), kwargs = {})"
            },
            {
              "key": "[metadata] pkg.torch.onnx.name_scopes",
              "value": "['', 'model', 'model.layers.1', 'model.layers.1.self_attn', 'model.layers.1.self_attn.o_proj', 'linear_10']"
            },
            {
              "key": "[metadata] pkg.torch.onnx.stack_trace",
              "value": "File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 688, in forward\n    outputs: BaseModelOutputWithPast = self.model(\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 453, in forward\n    layer_outputs = decoder_layer(\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 308, in forward\n    hidden_states, self_attn_weights = self.self_attn(\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 277, in forward\n    attn_output = self.o_proj(attn_output)\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/torch/nn/modules/linear.py\", line 125, in forward\n    return F.linear(input, self.weight, self.bias)"
            }
          ],
          "incomingEdges": [
            {
              "sourceNodeId": "node_MultiHeadAttention_67",
              "sourceNodeOutputId": "0",
              "targetNodeInputId": "0"
            },
            {
              "sourceNodeId": "[value] val_457",
              "sourceNodeOutputId": "0",
              "targetNodeInputId": "1"
            }
          ],
          "outputsMetadata": [
            {
              "id": "0",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "linear_10"
                },
                {
                  "key": "tensor_shape",
                  "value": "FLOAT[s34,s16,2048]"
                },
                {
                  "key": "param_name",
                  "value": "Y"
                }
              ]
            }
          ],
          "inputsMetadata": [
            {
              "id": "0",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "view_8"
                },
                {
                  "key": "tensor_shape",
                  "value": "FLOAT[s34,s16,2048]"
                },
                {
                  "key": "param_name",
                  "value": "A"
                }
              ]
            },
            {
              "id": "1",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "val_457"
                },
                {
                  "key": "tensor_shape",
                  "value": "FLOAT[2048,2048]"
                },
                {
                  "key": "param_name",
                  "value": "B"
                }
              ]
            }
          ],
          "style": null,
          "config": null
        },
        {
          "id": "node_SkipSimplifiedLayerNormalization_23",
          "label": "com.microsoft::SkipSimplifiedLayerNormalization",
          "namespace": "main_graph",
          "subgraphIds": [],
          "attrs": [
            {
              "key": "epsilon",
              "value": "9.999999747378752e-06"
            }
          ],
          "incomingEdges": [
            {
              "sourceNodeId": "node_MatMul_646",
              "sourceNodeOutputId": "0",
              "targetNodeInputId": "0"
            },
            {
              "sourceNodeId": "node_SkipSimplifiedLayerNormalization_22",
              "sourceNodeOutputId": "3",
              "targetNodeInputId": "1"
            },
            {
              "sourceNodeId": "[value] model.layers.1.post_attention_layernorm.weight",
              "sourceNodeOutputId": "0",
              "targetNodeInputId": "2"
            }
          ],
          "outputsMetadata": [
            {
              "id": "0",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "mul_567"
                },
                {
                  "key": "tensor_shape",
                  "value": "FLOAT[s34,s16,2048]"
                }
              ]
            },
            {
              "id": "1",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "val_8"
                },
                {
                  "key": "tensor_shape",
                  "value": "?[?]"
                },
                {
                  "key": "unused",
                  "value": "True"
                }
              ]
            },
            {
              "id": "2",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "val_9"
                },
                {
                  "key": "tensor_shape",
                  "value": "?[?]"
                },
                {
                  "key": "unused",
                  "value": "True"
                }
              ]
            },
            {
              "id": "3",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "add_697"
                },
                {
                  "key": "tensor_shape",
                  "value": "FLOAT[s34,s16,2048]"
                }
              ]
            }
          ],
          "inputsMetadata": [
            {
              "id": "0",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "linear_10"
                },
                {
                  "key": "tensor_shape",
                  "value": "FLOAT[s34,s16,2048]"
                }
              ]
            },
            {
              "id": "1",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "add_463"
                },
                {
                  "key": "tensor_shape",
                  "value": "FLOAT[s34,s16,2048]"
                }
              ]
            },
            {
              "id": "2",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "model.layers.1.post_attention_layernorm.weight"
                },
                {
                  "key": "tensor_shape",
                  "value": "FLOAT[2048]"
                }
              ]
            }
          ],
          "style": null,
          "config": null
        },
        {
          "id": "node_MatMul_659",
          "label": "MatMul",
          "namespace": "main_graph/: transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/model.layers.1: transformers.models.llama.modeling_llama.LlamaDecoderLayer/model.layers.1.mlp: transformers.models.llama.modeling_llama.LlamaMLP/model.layers.1.mlp.gate_proj: torch.nn.modules.linear.Linear/linear_11: aten.linear.default",
          "subgraphIds": [],
          "attrs": [
            {
              "key": "[metadata] namespace",
              "value": ": transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/model.layers.1: transformers.models.llama.modeling_llama.LlamaDecoderLayer/model.layers.1.mlp: transformers.models.llama.modeling_llama.LlamaMLP/model.layers.1.mlp.gate_proj: torch.nn.modules.linear.Linear/linear_11: aten.linear.default"
            },
            {
              "key": "[metadata] pkg.torch.onnx.class_hierarchy",
              "value": "['transformers.models.llama.modeling_llama.LlamaForCausalLM', 'transformers.models.llama.modeling_llama.LlamaModel', 'transformers.models.llama.modeling_llama.LlamaDecoderLayer', 'transformers.models.llama.modeling_llama.LlamaMLP', 'torch.nn.modules.linear.Linear', 'aten.linear.default']"
            },
            {
              "key": "[metadata] pkg.torch.onnx.fx_node",
              "value": "%linear_11 : [num_users=1] = call_function[target=torch.ops.aten.linear.default](args = (%mul_567, %p_model_layers_1_mlp_gate_proj_weight), kwargs = {})"
            },
            {
              "key": "[metadata] pkg.torch.onnx.name_scopes",
              "value": "['', 'model', 'model.layers.1', 'model.layers.1.mlp', 'model.layers.1.mlp.gate_proj', 'linear_11']"
            },
            {
              "key": "[metadata] pkg.torch.onnx.stack_trace",
              "value": "File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 688, in forward\n    outputs: BaseModelOutputWithPast = self.model(\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 453, in forward\n    layer_outputs = decoder_layer(\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 324, in forward\n    hidden_states = self.mlp(hidden_states)\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 162, in forward\n    down_proj = self.down_proj(self.act_fn(self.gate_proj(x)) * self.up_proj(x))\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/torch/nn/modules/linear.py\", line 125, in forward\n    return F.linear(input, self.weight, self.bias)"
            }
          ],
          "incomingEdges": [
            {
              "sourceNodeId": "node_SkipSimplifiedLayerNormalization_23",
              "sourceNodeOutputId": "0",
              "targetNodeInputId": "0"
            },
            {
              "sourceNodeId": "[value] val_462",
              "sourceNodeOutputId": "0",
              "targetNodeInputId": "1"
            }
          ],
          "outputsMetadata": [
            {
              "id": "0",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "linear_11"
                },
                {
                  "key": "tensor_shape",
                  "value": "FLOAT[s34,s16,8192]"
                },
                {
                  "key": "param_name",
                  "value": "Y"
                }
              ]
            }
          ],
          "inputsMetadata": [
            {
              "id": "0",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "mul_567"
                },
                {
                  "key": "tensor_shape",
                  "value": "FLOAT[s34,s16,2048]"
                },
                {
                  "key": "param_name",
                  "value": "A"
                }
              ]
            },
            {
              "id": "1",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "val_462"
                },
                {
                  "key": "tensor_shape",
                  "value": "FLOAT[2048,8192]"
                },
                {
                  "key": "param_name",
                  "value": "B"
                }
              ]
            }
          ],
          "style": null,
          "config": null
        },
        {
          "id": "node_Sigmoid_660",
          "label": "Sigmoid",
          "namespace": "main_graph/: transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/model.layers.1: transformers.models.llama.modeling_llama.LlamaDecoderLayer/model.layers.1.mlp: transformers.models.llama.modeling_llama.LlamaMLP/model.layers.1.mlp.act_fn: torch.nn.modules.activation.SiLU/silu_1: aten.silu.default",
          "subgraphIds": [],
          "attrs": [
            {
              "key": "[metadata] namespace",
              "value": ": transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/model.layers.1: transformers.models.llama.modeling_llama.LlamaDecoderLayer/model.layers.1.mlp: transformers.models.llama.modeling_llama.LlamaMLP/model.layers.1.mlp.act_fn: torch.nn.modules.activation.SiLU/silu_1: aten.silu.default"
            },
            {
              "key": "[metadata] pkg.torch.onnx.class_hierarchy",
              "value": "['transformers.models.llama.modeling_llama.LlamaForCausalLM', 'transformers.models.llama.modeling_llama.LlamaModel', 'transformers.models.llama.modeling_llama.LlamaDecoderLayer', 'transformers.models.llama.modeling_llama.LlamaMLP', 'torch.nn.modules.activation.SiLU', 'aten.silu.default']"
            },
            {
              "key": "[metadata] pkg.torch.onnx.fx_node",
              "value": "%silu_1 : [num_users=1] = call_function[target=torch.ops.aten.silu.default](args = (%linear_11,), kwargs = {})"
            },
            {
              "key": "[metadata] pkg.torch.onnx.name_scopes",
              "value": "['', 'model', 'model.layers.1', 'model.layers.1.mlp', 'model.layers.1.mlp.act_fn', 'silu_1']"
            },
            {
              "key": "[metadata] pkg.torch.onnx.stack_trace",
              "value": "File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 688, in forward\n    outputs: BaseModelOutputWithPast = self.model(\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 453, in forward\n    layer_outputs = decoder_layer(\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 324, in forward\n    hidden_states = self.mlp(hidden_states)\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 162, in forward\n    down_proj = self.down_proj(self.act_fn(self.gate_proj(x)) * self.up_proj(x))\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/torch/nn/modules/activation.py\", line 434, in forward\n    return F.silu(input, inplace=self.inplace)"
            }
          ],
          "incomingEdges": [
            {
              "sourceNodeId": "node_MatMul_659",
              "sourceNodeOutputId": "0",
              "targetNodeInputId": "0"
            }
          ],
          "outputsMetadata": [
            {
              "id": "0",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "val_463"
                },
                {
                  "key": "tensor_shape",
                  "value": "FLOAT[s34,s16,8192]"
                },
                {
                  "key": "param_name",
                  "value": "Y"
                }
              ]
            }
          ],
          "inputsMetadata": [
            {
              "id": "0",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "linear_11"
                },
                {
                  "key": "tensor_shape",
                  "value": "FLOAT[s34,s16,8192]"
                },
                {
                  "key": "param_name",
                  "value": "X"
                }
              ]
            }
          ],
          "style": null,
          "config": null
        },
        {
          "id": "node_Mul_661",
          "label": "Mul",
          "namespace": "main_graph/: transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/model.layers.1: transformers.models.llama.modeling_llama.LlamaDecoderLayer/model.layers.1.mlp: transformers.models.llama.modeling_llama.LlamaMLP/model.layers.1.mlp.act_fn: torch.nn.modules.activation.SiLU/silu_1: aten.silu.default",
          "subgraphIds": [],
          "attrs": [
            {
              "key": "[metadata] namespace",
              "value": ": transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/model.layers.1: transformers.models.llama.modeling_llama.LlamaDecoderLayer/model.layers.1.mlp: transformers.models.llama.modeling_llama.LlamaMLP/model.layers.1.mlp.act_fn: torch.nn.modules.activation.SiLU/silu_1: aten.silu.default"
            },
            {
              "key": "[metadata] pkg.torch.onnx.class_hierarchy",
              "value": "['transformers.models.llama.modeling_llama.LlamaForCausalLM', 'transformers.models.llama.modeling_llama.LlamaModel', 'transformers.models.llama.modeling_llama.LlamaDecoderLayer', 'transformers.models.llama.modeling_llama.LlamaMLP', 'torch.nn.modules.activation.SiLU', 'aten.silu.default']"
            },
            {
              "key": "[metadata] pkg.torch.onnx.fx_node",
              "value": "%silu_1 : [num_users=1] = call_function[target=torch.ops.aten.silu.default](args = (%linear_11,), kwargs = {})"
            },
            {
              "key": "[metadata] pkg.torch.onnx.name_scopes",
              "value": "['', 'model', 'model.layers.1', 'model.layers.1.mlp', 'model.layers.1.mlp.act_fn', 'silu_1']"
            },
            {
              "key": "[metadata] pkg.torch.onnx.stack_trace",
              "value": "File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 688, in forward\n    outputs: BaseModelOutputWithPast = self.model(\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 453, in forward\n    layer_outputs = decoder_layer(\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 324, in forward\n    hidden_states = self.mlp(hidden_states)\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 162, in forward\n    down_proj = self.down_proj(self.act_fn(self.gate_proj(x)) * self.up_proj(x))\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/torch/nn/modules/activation.py\", line 434, in forward\n    return F.silu(input, inplace=self.inplace)"
            }
          ],
          "incomingEdges": [
            {
              "sourceNodeId": "node_MatMul_659",
              "sourceNodeOutputId": "0",
              "targetNodeInputId": "0"
            },
            {
              "sourceNodeId": "node_Sigmoid_660",
              "sourceNodeOutputId": "0",
              "targetNodeInputId": "1"
            }
          ],
          "outputsMetadata": [
            {
              "id": "0",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "silu_1"
                },
                {
                  "key": "tensor_shape",
                  "value": "FLOAT[s34,s16,8192]"
                },
                {
                  "key": "param_name",
                  "value": "C"
                }
              ]
            }
          ],
          "inputsMetadata": [
            {
              "id": "0",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "linear_11"
                },
                {
                  "key": "tensor_shape",
                  "value": "FLOAT[s34,s16,8192]"
                },
                {
                  "key": "param_name",
                  "value": "A"
                }
              ]
            },
            {
              "id": "1",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "val_463"
                },
                {
                  "key": "tensor_shape",
                  "value": "FLOAT[s34,s16,8192]"
                },
                {
                  "key": "param_name",
                  "value": "B"
                }
              ]
            }
          ],
          "style": null,
          "config": null
        },
        {
          "id": "node_MatMul_663",
          "label": "MatMul",
          "namespace": "main_graph/: transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/model.layers.1: transformers.models.llama.modeling_llama.LlamaDecoderLayer/model.layers.1.mlp: transformers.models.llama.modeling_llama.LlamaMLP/model.layers.1.mlp.up_proj: torch.nn.modules.linear.Linear/linear_12: aten.linear.default",
          "subgraphIds": [],
          "attrs": [
            {
              "key": "[metadata] namespace",
              "value": ": transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/model.layers.1: transformers.models.llama.modeling_llama.LlamaDecoderLayer/model.layers.1.mlp: transformers.models.llama.modeling_llama.LlamaMLP/model.layers.1.mlp.up_proj: torch.nn.modules.linear.Linear/linear_12: aten.linear.default"
            },
            {
              "key": "[metadata] pkg.torch.onnx.class_hierarchy",
              "value": "['transformers.models.llama.modeling_llama.LlamaForCausalLM', 'transformers.models.llama.modeling_llama.LlamaModel', 'transformers.models.llama.modeling_llama.LlamaDecoderLayer', 'transformers.models.llama.modeling_llama.LlamaMLP', 'torch.nn.modules.linear.Linear', 'aten.linear.default']"
            },
            {
              "key": "[metadata] pkg.torch.onnx.fx_node",
              "value": "%linear_12 : [num_users=1] = call_function[target=torch.ops.aten.linear.default](args = (%mul_567, %p_model_layers_1_mlp_up_proj_weight), kwargs = {})"
            },
            {
              "key": "[metadata] pkg.torch.onnx.name_scopes",
              "value": "['', 'model', 'model.layers.1', 'model.layers.1.mlp', 'model.layers.1.mlp.up_proj', 'linear_12']"
            },
            {
              "key": "[metadata] pkg.torch.onnx.stack_trace",
              "value": "File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 688, in forward\n    outputs: BaseModelOutputWithPast = self.model(\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 453, in forward\n    layer_outputs = decoder_layer(\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 324, in forward\n    hidden_states = self.mlp(hidden_states)\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 162, in forward\n    down_proj = self.down_proj(self.act_fn(self.gate_proj(x)) * self.up_proj(x))\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/torch/nn/modules/linear.py\", line 125, in forward\n    return F.linear(input, self.weight, self.bias)"
            }
          ],
          "incomingEdges": [
            {
              "sourceNodeId": "node_SkipSimplifiedLayerNormalization_23",
              "sourceNodeOutputId": "0",
              "targetNodeInputId": "0"
            },
            {
              "sourceNodeId": "[value] val_464",
              "sourceNodeOutputId": "0",
              "targetNodeInputId": "1"
            }
          ],
          "outputsMetadata": [
            {
              "id": "0",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "linear_12"
                },
                {
                  "key": "tensor_shape",
                  "value": "FLOAT[s34,s16,8192]"
                },
                {
                  "key": "param_name",
                  "value": "Y"
                }
              ]
            }
          ],
          "inputsMetadata": [
            {
              "id": "0",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "mul_567"
                },
                {
                  "key": "tensor_shape",
                  "value": "FLOAT[s34,s16,2048]"
                },
                {
                  "key": "param_name",
                  "value": "A"
                }
              ]
            },
            {
              "id": "1",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "val_464"
                },
                {
                  "key": "tensor_shape",
                  "value": "FLOAT[2048,8192]"
                },
                {
                  "key": "param_name",
                  "value": "B"
                }
              ]
            }
          ],
          "style": null,
          "config": null
        },
        {
          "id": "node_Mul_664",
          "label": "Mul",
          "namespace": "main_graph/: transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/model.layers.1: transformers.models.llama.modeling_llama.LlamaDecoderLayer/model.layers.1.mlp: transformers.models.llama.modeling_llama.LlamaMLP/mul_580: aten.mul.Tensor",
          "subgraphIds": [],
          "attrs": [
            {
              "key": "[metadata] namespace",
              "value": ": transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/model.layers.1: transformers.models.llama.modeling_llama.LlamaDecoderLayer/model.layers.1.mlp: transformers.models.llama.modeling_llama.LlamaMLP/mul_580: aten.mul.Tensor"
            },
            {
              "key": "[metadata] pkg.torch.onnx.class_hierarchy",
              "value": "['transformers.models.llama.modeling_llama.LlamaForCausalLM', 'transformers.models.llama.modeling_llama.LlamaModel', 'transformers.models.llama.modeling_llama.LlamaDecoderLayer', 'transformers.models.llama.modeling_llama.LlamaMLP', 'aten.mul.Tensor']"
            },
            {
              "key": "[metadata] pkg.torch.onnx.fx_node",
              "value": "%mul_580 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%silu_1, %linear_12), kwargs = {})"
            },
            {
              "key": "[metadata] pkg.torch.onnx.name_scopes",
              "value": "['', 'model', 'model.layers.1', 'model.layers.1.mlp', 'mul_580']"
            },
            {
              "key": "[metadata] pkg.torch.onnx.stack_trace",
              "value": "File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 688, in forward\n    outputs: BaseModelOutputWithPast = self.model(\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 453, in forward\n    layer_outputs = decoder_layer(\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 324, in forward\n    hidden_states = self.mlp(hidden_states)\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 162, in forward\n    down_proj = self.down_proj(self.act_fn(self.gate_proj(x)) * self.up_proj(x))"
            }
          ],
          "incomingEdges": [
            {
              "sourceNodeId": "node_Mul_661",
              "sourceNodeOutputId": "0",
              "targetNodeInputId": "0"
            },
            {
              "sourceNodeId": "node_MatMul_663",
              "sourceNodeOutputId": "0",
              "targetNodeInputId": "1"
            }
          ],
          "outputsMetadata": [
            {
              "id": "0",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "mul_580"
                },
                {
                  "key": "tensor_shape",
                  "value": "FLOAT[s34,s16,8192]"
                },
                {
                  "key": "param_name",
                  "value": "C"
                }
              ]
            }
          ],
          "inputsMetadata": [
            {
              "id": "0",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "silu_1"
                },
                {
                  "key": "tensor_shape",
                  "value": "FLOAT[s34,s16,8192]"
                },
                {
                  "key": "param_name",
                  "value": "A"
                }
              ]
            },
            {
              "id": "1",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "linear_12"
                },
                {
                  "key": "tensor_shape",
                  "value": "FLOAT[s34,s16,8192]"
                },
                {
                  "key": "param_name",
                  "value": "B"
                }
              ]
            }
          ],
          "style": null,
          "config": null
        },
        {
          "id": "node_MatMul_666",
          "label": "MatMul",
          "namespace": "main_graph/: transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/model.layers.1: transformers.models.llama.modeling_llama.LlamaDecoderLayer/model.layers.1.mlp: transformers.models.llama.modeling_llama.LlamaMLP/model.layers.1.mlp.down_proj: torch.nn.modules.linear.Linear/linear_13: aten.linear.default",
          "subgraphIds": [],
          "attrs": [
            {
              "key": "[metadata] namespace",
              "value": ": transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/model.layers.1: transformers.models.llama.modeling_llama.LlamaDecoderLayer/model.layers.1.mlp: transformers.models.llama.modeling_llama.LlamaMLP/model.layers.1.mlp.down_proj: torch.nn.modules.linear.Linear/linear_13: aten.linear.default"
            },
            {
              "key": "[metadata] pkg.torch.onnx.class_hierarchy",
              "value": "['transformers.models.llama.modeling_llama.LlamaForCausalLM', 'transformers.models.llama.modeling_llama.LlamaModel', 'transformers.models.llama.modeling_llama.LlamaDecoderLayer', 'transformers.models.llama.modeling_llama.LlamaMLP', 'torch.nn.modules.linear.Linear', 'aten.linear.default']"
            },
            {
              "key": "[metadata] pkg.torch.onnx.fx_node",
              "value": "%linear_13 : [num_users=1] = call_function[target=torch.ops.aten.linear.default](args = (%mul_580, %p_model_layers_1_mlp_down_proj_weight), kwargs = {})"
            },
            {
              "key": "[metadata] pkg.torch.onnx.name_scopes",
              "value": "['', 'model', 'model.layers.1', 'model.layers.1.mlp', 'model.layers.1.mlp.down_proj', 'linear_13']"
            },
            {
              "key": "[metadata] pkg.torch.onnx.stack_trace",
              "value": "File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 688, in forward\n    outputs: BaseModelOutputWithPast = self.model(\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 453, in forward\n    layer_outputs = decoder_layer(\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 324, in forward\n    hidden_states = self.mlp(hidden_states)\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 162, in forward\n    down_proj = self.down_proj(self.act_fn(self.gate_proj(x)) * self.up_proj(x))\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/torch/nn/modules/linear.py\", line 125, in forward\n    return F.linear(input, self.weight, self.bias)"
            }
          ],
          "incomingEdges": [
            {
              "sourceNodeId": "node_Mul_664",
              "sourceNodeOutputId": "0",
              "targetNodeInputId": "0"
            },
            {
              "sourceNodeId": "[value] val_465",
              "sourceNodeOutputId": "0",
              "targetNodeInputId": "1"
            }
          ],
          "outputsMetadata": [
            {
              "id": "0",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "linear_13"
                },
                {
                  "key": "tensor_shape",
                  "value": "FLOAT[s34,s16,2048]"
                },
                {
                  "key": "param_name",
                  "value": "Y"
                }
              ]
            }
          ],
          "inputsMetadata": [
            {
              "id": "0",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "mul_580"
                },
                {
                  "key": "tensor_shape",
                  "value": "FLOAT[s34,s16,8192]"
                },
                {
                  "key": "param_name",
                  "value": "A"
                }
              ]
            },
            {
              "id": "1",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "val_465"
                },
                {
                  "key": "tensor_shape",
                  "value": "FLOAT[8192,2048]"
                },
                {
                  "key": "param_name",
                  "value": "B"
                }
              ]
            }
          ],
          "style": null,
          "config": null
        },
        {
          "id": "node_SkipSimplifiedLayerNormalization_24",
          "label": "com.microsoft::SkipSimplifiedLayerNormalization",
          "namespace": "main_graph",
          "subgraphIds": [],
          "attrs": [
            {
              "key": "epsilon",
              "value": "9.999999747378752e-06"
            }
          ],
          "incomingEdges": [
            {
              "sourceNodeId": "node_MatMul_666",
              "sourceNodeOutputId": "0",
              "targetNodeInputId": "0"
            },
            {
              "sourceNodeId": "node_SkipSimplifiedLayerNormalization_23",
              "sourceNodeOutputId": "3",
              "targetNodeInputId": "1"
            },
            {
              "sourceNodeId": "[value] model.norm.weight",
              "sourceNodeOutputId": "0",
              "targetNodeInputId": "2"
            }
          ],
          "outputsMetadata": [
            {
              "id": "0",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "mul_603"
                },
                {
                  "key": "tensor_shape",
                  "value": "FLOAT[s34,s16,2048]"
                }
              ]
            },
            {
              "id": "1",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "val_10"
                },
                {
                  "key": "tensor_shape",
                  "value": "?[?]"
                },
                {
                  "key": "unused",
                  "value": "True"
                }
              ]
            },
            {
              "id": "2",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "val_13"
                },
                {
                  "key": "tensor_shape",
                  "value": "?[?]"
                },
                {
                  "key": "unused",
                  "value": "True"
                }
              ]
            },
            {
              "id": "3",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "add_747"
                },
                {
                  "key": "tensor_shape",
                  "value": "FLOAT[s34,s16,2048]"
                },
                {
                  "key": "unused",
                  "value": "True"
                }
              ]
            }
          ],
          "inputsMetadata": [
            {
              "id": "0",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "linear_13"
                },
                {
                  "key": "tensor_shape",
                  "value": "FLOAT[s34,s16,2048]"
                }
              ]
            },
            {
              "id": "1",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "add_697"
                },
                {
                  "key": "tensor_shape",
                  "value": "FLOAT[s34,s16,2048]"
                }
              ]
            },
            {
              "id": "2",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "model.norm.weight"
                },
                {
                  "key": "tensor_shape",
                  "value": "FLOAT[2048]"
                }
              ]
            }
          ],
          "style": null,
          "config": null
        },
        {
          "id": "node_Transpose_701",
          "label": "Transpose",
          "namespace": "main_graph/: transformers.models.llama.modeling_llama.LlamaForCausalLM/lm_head: torch.nn.modules.linear.Linear/linear_14: aten.linear.default",
          "subgraphIds": [],
          "attrs": [
            {
              "key": "perm",
              "value": "[1, 0]"
            },
            {
              "key": "[metadata] namespace",
              "value": ": transformers.models.llama.modeling_llama.LlamaForCausalLM/lm_head: torch.nn.modules.linear.Linear/linear_14: aten.linear.default"
            },
            {
              "key": "[metadata] pkg.torch.onnx.class_hierarchy",
              "value": "['transformers.models.llama.modeling_llama.LlamaForCausalLM', 'torch.nn.modules.linear.Linear', 'aten.linear.default']"
            },
            {
              "key": "[metadata] pkg.torch.onnx.fx_node",
              "value": "%linear_14 : [num_users=1] = call_function[target=torch.ops.aten.linear.default](args = (%slice_52, %p_lm_head_weight), kwargs = {})"
            },
            {
              "key": "[metadata] pkg.torch.onnx.name_scopes",
              "value": "['', 'lm_head', 'linear_14']"
            },
            {
              "key": "[metadata] pkg.torch.onnx.stack_trace",
              "value": "File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 704, in forward\n    logits = self.lm_head(hidden_states[:, slice_indices, :])\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/torch/nn/modules/linear.py\", line 125, in forward\n    return F.linear(input, self.weight, self.bias)"
            }
          ],
          "incomingEdges": [
            {
              "sourceNodeId": "[value] lm_head.weight",
              "sourceNodeOutputId": "0",
              "targetNodeInputId": "0"
            }
          ],
          "outputsMetadata": [
            {
              "id": "0",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "val_490"
                },
                {
                  "key": "tensor_shape",
                  "value": "FLOAT[2048,49152]"
                },
                {
                  "key": "param_name",
                  "value": "transposed"
                }
              ]
            }
          ],
          "inputsMetadata": [
            {
              "id": "0",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "lm_head.weight"
                },
                {
                  "key": "tensor_shape",
                  "value": "FLOAT[49152,2048]"
                },
                {
                  "key": "param_name",
                  "value": "data"
                }
              ]
            }
          ],
          "style": null,
          "config": null
        },
        {
          "id": "node_MatMul_702",
          "label": "MatMul",
          "namespace": "main_graph/: transformers.models.llama.modeling_llama.LlamaForCausalLM/lm_head: torch.nn.modules.linear.Linear/linear_14: aten.linear.default",
          "subgraphIds": [],
          "attrs": [
            {
              "key": "[metadata] namespace",
              "value": ": transformers.models.llama.modeling_llama.LlamaForCausalLM/lm_head: torch.nn.modules.linear.Linear/linear_14: aten.linear.default"
            },
            {
              "key": "[metadata] pkg.torch.onnx.class_hierarchy",
              "value": "['transformers.models.llama.modeling_llama.LlamaForCausalLM', 'torch.nn.modules.linear.Linear', 'aten.linear.default']"
            },
            {
              "key": "[metadata] pkg.torch.onnx.fx_node",
              "value": "%linear_14 : [num_users=1] = call_function[target=torch.ops.aten.linear.default](args = (%slice_52, %p_lm_head_weight), kwargs = {})"
            },
            {
              "key": "[metadata] pkg.torch.onnx.name_scopes",
              "value": "['', 'lm_head', 'linear_14']"
            },
            {
              "key": "[metadata] pkg.torch.onnx.stack_trace",
              "value": "File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 704, in forward\n    logits = self.lm_head(hidden_states[:, slice_indices, :])\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/torch/nn/modules/linear.py\", line 125, in forward\n    return F.linear(input, self.weight, self.bias)"
            }
          ],
          "incomingEdges": [
            {
              "sourceNodeId": "node_SkipSimplifiedLayerNormalization_24",
              "sourceNodeOutputId": "0",
              "targetNodeInputId": "0"
            },
            {
              "sourceNodeId": "node_Transpose_701",
              "sourceNodeOutputId": "0",
              "targetNodeInputId": "1"
            }
          ],
          "outputsMetadata": [
            {
              "id": "0",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "linear_14"
                },
                {
                  "key": "tensor_shape",
                  "value": "FLOAT[s34,s16,49152]"
                },
                {
                  "key": "[metadata] pkg.torch.export.graph_signature.OutputSpec.kind",
                  "value": "USER_OUTPUT"
                },
                {
                  "key": "param_name",
                  "value": "Y"
                }
              ]
            }
          ],
          "inputsMetadata": [
            {
              "id": "0",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "mul_603"
                },
                {
                  "key": "tensor_shape",
                  "value": "FLOAT[s34,s16,2048]"
                },
                {
                  "key": "param_name",
                  "value": "A"
                }
              ]
            },
            {
              "id": "1",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "val_490"
                },
                {
                  "key": "tensor_shape",
                  "value": "FLOAT[2048,49152]"
                },
                {
                  "key": "param_name",
                  "value": "B"
                }
              ]
            }
          ],
          "style": null,
          "config": null
        },
        {
          "id": "[value] model.layers.0.input_layernorm.weight",
          "label": "Initializer",
          "namespace": "main_graph",
          "subgraphIds": [],
          "attrs": [],
          "incomingEdges": [],
          "outputsMetadata": [
            {
              "id": "0",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "model.layers.0.input_layernorm.weight"
                },
                {
                  "key": "tensor_shape",
                  "value": "FLOAT[2048]"
                },
                {
                  "key": "value",
                  "value": "ExternalTensor<FLOAT,[2048]>(location='model_SmolLM17b_optimized.onnx.data', name='model.layers.0.input_layernorm.weight', offset=0, length=8192, base_dir='')"
                }
              ]
            }
          ],
          "inputsMetadata": [],
          "style": null,
          "config": null
        },
        {
          "id": "[value] model.layers.0.post_attention_layernorm.weight",
          "label": "Initializer",
          "namespace": "main_graph",
          "subgraphIds": [],
          "attrs": [],
          "incomingEdges": [],
          "outputsMetadata": [
            {
              "id": "0",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "model.layers.0.post_attention_layernorm.weight"
                },
                {
                  "key": "tensor_shape",
                  "value": "FLOAT[2048]"
                },
                {
                  "key": "value",
                  "value": "ExternalTensor<FLOAT,[2048]>(location='model_SmolLM17b_optimized.onnx.data', name='model.layers.0.post_attention_layernorm.weight', offset=8192, length=8192, base_dir='')"
                }
              ]
            }
          ],
          "inputsMetadata": [],
          "style": null,
          "config": null
        },
        {
          "id": "[value] model.layers.1.input_layernorm.weight",
          "label": "Initializer",
          "namespace": "main_graph",
          "subgraphIds": [],
          "attrs": [],
          "incomingEdges": [],
          "outputsMetadata": [
            {
              "id": "0",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "model.layers.1.input_layernorm.weight"
                },
                {
                  "key": "tensor_shape",
                  "value": "FLOAT[2048]"
                },
                {
                  "key": "value",
                  "value": "ExternalTensor<FLOAT,[2048]>(location='model_SmolLM17b_optimized.onnx.data', name='model.layers.1.input_layernorm.weight', offset=16384, length=8192, base_dir='')"
                }
              ]
            }
          ],
          "inputsMetadata": [],
          "style": null,
          "config": null
        },
        {
          "id": "[value] model.layers.1.post_attention_layernorm.weight",
          "label": "Initializer",
          "namespace": "main_graph",
          "subgraphIds": [],
          "attrs": [],
          "incomingEdges": [],
          "outputsMetadata": [
            {
              "id": "0",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "model.layers.1.post_attention_layernorm.weight"
                },
                {
                  "key": "tensor_shape",
                  "value": "FLOAT[2048]"
                },
                {
                  "key": "value",
                  "value": "ExternalTensor<FLOAT,[2048]>(location='model_SmolLM17b_optimized.onnx.data', name='model.layers.1.post_attention_layernorm.weight', offset=24576, length=8192, base_dir='')"
                }
              ]
            }
          ],
          "inputsMetadata": [],
          "style": null,
          "config": null
        },
        {
          "id": "[value] model.norm.weight",
          "label": "Initializer",
          "namespace": "main_graph",
          "subgraphIds": [],
          "attrs": [],
          "incomingEdges": [],
          "outputsMetadata": [
            {
              "id": "0",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "model.norm.weight"
                },
                {
                  "key": "tensor_shape",
                  "value": "FLOAT[2048]"
                },
                {
                  "key": "value",
                  "value": "ExternalTensor<FLOAT,[2048]>(location='model_SmolLM17b_optimized.onnx.data', name='model.norm.weight', offset=32768, length=8192, base_dir='')"
                }
              ]
            }
          ],
          "inputsMetadata": [],
          "style": null,
          "config": null
        },
        {
          "id": "[value] lm_head.weight",
          "label": "Initializer",
          "namespace": "main_graph/: transformers.models.llama.modeling_llama.LlamaForCausalLM",
          "subgraphIds": [],
          "attrs": [],
          "incomingEdges": [],
          "outputsMetadata": [
            {
              "id": "0",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "lm_head.weight"
                },
                {
                  "key": "tensor_shape",
                  "value": "FLOAT[49152,2048]"
                },
                {
                  "key": "value",
                  "value": "ExternalTensor<FLOAT,[49152,2048]>(location='model_SmolLM17b_optimized.onnx.data', name='lm_head.weight', offset=536936448, length=402653184, base_dir='')"
                }
              ]
            }
          ],
          "inputsMetadata": [],
          "style": null,
          "config": null
        },
        {
          "id": "[value] val_253",
          "label": "Initializer",
          "namespace": "main_graph/: transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/model.layers.0: transformers.models.llama.modeling_llama.LlamaDecoderLayer/model.layers.0.self_attn: transformers.models.llama.modeling_llama.LlamaAttention/model.layers.0.self_attn.q_proj: torch.nn.modules.linear.Linear/linear: aten.linear.default",
          "subgraphIds": [],
          "attrs": [],
          "incomingEdges": [],
          "outputsMetadata": [
            {
              "id": "0",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "val_253"
                },
                {
                  "key": "tensor_shape",
                  "value": "FLOAT[2048,2048]"
                },
                {
                  "key": "value",
                  "value": "ExternalTensor<FLOAT,[2048,2048]>(location='model_SmolLM17b_optimized.onnx.data', name='val_253', offset=65536, length=16777216, base_dir='')"
                }
              ]
            }
          ],
          "inputsMetadata": [],
          "style": null,
          "config": null
        },
        {
          "id": "[value] val_261",
          "label": "Initializer",
          "namespace": "main_graph/: transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/model.layers.0: transformers.models.llama.modeling_llama.LlamaDecoderLayer/model.layers.0.self_attn: transformers.models.llama.modeling_llama.LlamaAttention/model.layers.0.self_attn.k_proj: torch.nn.modules.linear.Linear/linear_1: aten.linear.default",
          "subgraphIds": [],
          "attrs": [],
          "incomingEdges": [],
          "outputsMetadata": [
            {
              "id": "0",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "val_261"
                },
                {
                  "key": "tensor_shape",
                  "value": "FLOAT[2048,2048]"
                },
                {
                  "key": "value",
                  "value": "ExternalTensor<FLOAT,[2048,2048]>(location='model_SmolLM17b_optimized.onnx.data', name='val_261', offset=16842752, length=16777216, base_dir='')"
                }
              ]
            }
          ],
          "inputsMetadata": [],
          "style": null,
          "config": null
        },
        {
          "id": "[value] val_268",
          "label": "Initializer",
          "namespace": "main_graph/: transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/model.layers.0: transformers.models.llama.modeling_llama.LlamaDecoderLayer/model.layers.0.self_attn: transformers.models.llama.modeling_llama.LlamaAttention/model.layers.0.self_attn.v_proj: torch.nn.modules.linear.Linear/linear_2: aten.linear.default",
          "subgraphIds": [],
          "attrs": [],
          "incomingEdges": [],
          "outputsMetadata": [
            {
              "id": "0",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "val_268"
                },
                {
                  "key": "tensor_shape",
                  "value": "FLOAT[2048,2048]"
                },
                {
                  "key": "value",
                  "value": "ExternalTensor<FLOAT,[2048,2048]>(location='model_SmolLM17b_optimized.onnx.data', name='val_268', offset=33619968, length=16777216, base_dir='')"
                }
              ]
            }
          ],
          "inputsMetadata": [],
          "style": null,
          "config": null
        },
        {
          "id": "[value] val_350",
          "label": "Initializer",
          "namespace": "main_graph/: transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/model.layers.0: transformers.models.llama.modeling_llama.LlamaDecoderLayer/model.layers.0.self_attn: transformers.models.llama.modeling_llama.LlamaAttention/model.layers.0.self_attn.o_proj: torch.nn.modules.linear.Linear/linear_3: aten.linear.default",
          "subgraphIds": [],
          "attrs": [],
          "incomingEdges": [],
          "outputsMetadata": [
            {
              "id": "0",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "val_350"
                },
                {
                  "key": "tensor_shape",
                  "value": "FLOAT[2048,2048]"
                },
                {
                  "key": "value",
                  "value": "ExternalTensor<FLOAT,[2048,2048]>(location='model_SmolLM17b_optimized.onnx.data', name='val_350', offset=50397184, length=16777216, base_dir='')"
                }
              ]
            }
          ],
          "inputsMetadata": [],
          "style": null,
          "config": null
        },
        {
          "id": "[value] val_355",
          "label": "Initializer",
          "namespace": "main_graph/: transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/model.layers.0: transformers.models.llama.modeling_llama.LlamaDecoderLayer/model.layers.0.mlp: transformers.models.llama.modeling_llama.LlamaMLP/model.layers.0.mlp.gate_proj: torch.nn.modules.linear.Linear/linear_4: aten.linear.default",
          "subgraphIds": [],
          "attrs": [],
          "incomingEdges": [],
          "outputsMetadata": [
            {
              "id": "0",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "val_355"
                },
                {
                  "key": "tensor_shape",
                  "value": "FLOAT[2048,8192]"
                },
                {
                  "key": "value",
                  "value": "ExternalTensor<FLOAT,[2048,8192]>(location='model_SmolLM17b_optimized.onnx.data', name='val_355', offset=134283264, length=67108864, base_dir='')"
                }
              ]
            }
          ],
          "inputsMetadata": [],
          "style": null,
          "config": null
        },
        {
          "id": "[value] val_357",
          "label": "Initializer",
          "namespace": "main_graph/: transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/model.layers.0: transformers.models.llama.modeling_llama.LlamaDecoderLayer/model.layers.0.mlp: transformers.models.llama.modeling_llama.LlamaMLP/model.layers.0.mlp.up_proj: torch.nn.modules.linear.Linear/linear_5: aten.linear.default",
          "subgraphIds": [],
          "attrs": [],
          "incomingEdges": [],
          "outputsMetadata": [
            {
              "id": "0",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "val_357"
                },
                {
                  "key": "tensor_shape",
                  "value": "FLOAT[2048,8192]"
                },
                {
                  "key": "value",
                  "value": "ExternalTensor<FLOAT,[2048,8192]>(location='model_SmolLM17b_optimized.onnx.data', name='val_357', offset=201392128, length=67108864, base_dir='')"
                }
              ]
            }
          ],
          "inputsMetadata": [],
          "style": null,
          "config": null
        },
        {
          "id": "[value] val_358",
          "label": "Initializer",
          "namespace": "main_graph/: transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/model.layers.0: transformers.models.llama.modeling_llama.LlamaDecoderLayer/model.layers.0.mlp: transformers.models.llama.modeling_llama.LlamaMLP/model.layers.0.mlp.down_proj: torch.nn.modules.linear.Linear/linear_6: aten.linear.default",
          "subgraphIds": [],
          "attrs": [],
          "incomingEdges": [],
          "outputsMetadata": [
            {
              "id": "0",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "val_358"
                },
                {
                  "key": "tensor_shape",
                  "value": "FLOAT[8192,2048]"
                },
                {
                  "key": "value",
                  "value": "ExternalTensor<FLOAT,[8192,2048]>(location='model_SmolLM17b_optimized.onnx.data', name='val_358', offset=268500992, length=67108864, base_dir='')"
                }
              ]
            }
          ],
          "inputsMetadata": [],
          "style": null,
          "config": null
        },
        {
          "id": "[value] val_363",
          "label": "Initializer",
          "namespace": "main_graph/: transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/model.layers.1: transformers.models.llama.modeling_llama.LlamaDecoderLayer/model.layers.1.self_attn: transformers.models.llama.modeling_llama.LlamaAttention/model.layers.1.self_attn.q_proj: torch.nn.modules.linear.Linear/linear_7: aten.linear.default",
          "subgraphIds": [],
          "attrs": [],
          "incomingEdges": [],
          "outputsMetadata": [
            {
              "id": "0",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "val_363"
                },
                {
                  "key": "tensor_shape",
                  "value": "FLOAT[2048,2048]"
                },
                {
                  "key": "value",
                  "value": "ExternalTensor<FLOAT,[2048,2048]>(location='model_SmolLM17b_optimized.onnx.data', name='val_363', offset=67174400, length=16777216, base_dir='')"
                }
              ]
            }
          ],
          "inputsMetadata": [],
          "style": null,
          "config": null
        },
        {
          "id": "[value] val_370",
          "label": "Initializer",
          "namespace": "main_graph/: transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/model.layers.1: transformers.models.llama.modeling_llama.LlamaDecoderLayer/model.layers.1.self_attn: transformers.models.llama.modeling_llama.LlamaAttention/model.layers.1.self_attn.k_proj: torch.nn.modules.linear.Linear/linear_8: aten.linear.default",
          "subgraphIds": [],
          "attrs": [],
          "incomingEdges": [],
          "outputsMetadata": [
            {
              "id": "0",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "val_370"
                },
                {
                  "key": "tensor_shape",
                  "value": "FLOAT[2048,2048]"
                },
                {
                  "key": "value",
                  "value": "ExternalTensor<FLOAT,[2048,2048]>(location='model_SmolLM17b_optimized.onnx.data', name='val_370', offset=83951616, length=16777216, base_dir='')"
                }
              ]
            }
          ],
          "inputsMetadata": [],
          "style": null,
          "config": null
        },
        {
          "id": "[value] val_377",
          "label": "Initializer",
          "namespace": "main_graph/: transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/model.layers.1: transformers.models.llama.modeling_llama.LlamaDecoderLayer/model.layers.1.self_attn: transformers.models.llama.modeling_llama.LlamaAttention/model.layers.1.self_attn.v_proj: torch.nn.modules.linear.Linear/linear_9: aten.linear.default",
          "subgraphIds": [],
          "attrs": [],
          "incomingEdges": [],
          "outputsMetadata": [
            {
              "id": "0",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "val_377"
                },
                {
                  "key": "tensor_shape",
                  "value": "FLOAT[2048,2048]"
                },
                {
                  "key": "value",
                  "value": "ExternalTensor<FLOAT,[2048,2048]>(location='model_SmolLM17b_optimized.onnx.data', name='val_377', offset=100728832, length=16777216, base_dir='')"
                }
              ]
            }
          ],
          "inputsMetadata": [],
          "style": null,
          "config": null
        },
        {
          "id": "[value] val_457",
          "label": "Initializer",
          "namespace": "main_graph/: transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/model.layers.1: transformers.models.llama.modeling_llama.LlamaDecoderLayer/model.layers.1.self_attn: transformers.models.llama.modeling_llama.LlamaAttention/model.layers.1.self_attn.o_proj: torch.nn.modules.linear.Linear/linear_10: aten.linear.default",
          "subgraphIds": [],
          "attrs": [],
          "incomingEdges": [],
          "outputsMetadata": [
            {
              "id": "0",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "val_457"
                },
                {
                  "key": "tensor_shape",
                  "value": "FLOAT[2048,2048]"
                },
                {
                  "key": "value",
                  "value": "ExternalTensor<FLOAT,[2048,2048]>(location='model_SmolLM17b_optimized.onnx.data', name='val_457', offset=117506048, length=16777216, base_dir='')"
                }
              ]
            }
          ],
          "inputsMetadata": [],
          "style": null,
          "config": null
        },
        {
          "id": "[value] val_462",
          "label": "Initializer",
          "namespace": "main_graph/: transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/model.layers.1: transformers.models.llama.modeling_llama.LlamaDecoderLayer/model.layers.1.mlp: transformers.models.llama.modeling_llama.LlamaMLP/model.layers.1.mlp.gate_proj: torch.nn.modules.linear.Linear/linear_11: aten.linear.default",
          "subgraphIds": [],
          "attrs": [],
          "incomingEdges": [],
          "outputsMetadata": [
            {
              "id": "0",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "val_462"
                },
                {
                  "key": "tensor_shape",
                  "value": "FLOAT[2048,8192]"
                },
                {
                  "key": "value",
                  "value": "ExternalTensor<FLOAT,[2048,8192]>(location='model_SmolLM17b_optimized.onnx.data', name='val_462', offset=335609856, length=67108864, base_dir='')"
                }
              ]
            }
          ],
          "inputsMetadata": [],
          "style": null,
          "config": null
        },
        {
          "id": "[value] val_464",
          "label": "Initializer",
          "namespace": "main_graph/: transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/model.layers.1: transformers.models.llama.modeling_llama.LlamaDecoderLayer/model.layers.1.mlp: transformers.models.llama.modeling_llama.LlamaMLP/model.layers.1.mlp.up_proj: torch.nn.modules.linear.Linear/linear_12: aten.linear.default",
          "subgraphIds": [],
          "attrs": [],
          "incomingEdges": [],
          "outputsMetadata": [
            {
              "id": "0",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "val_464"
                },
                {
                  "key": "tensor_shape",
                  "value": "FLOAT[2048,8192]"
                },
                {
                  "key": "value",
                  "value": "ExternalTensor<FLOAT,[2048,8192]>(location='model_SmolLM17b_optimized.onnx.data', name='val_464', offset=402718720, length=67108864, base_dir='')"
                }
              ]
            }
          ],
          "inputsMetadata": [],
          "style": null,
          "config": null
        },
        {
          "id": "[value] val_465",
          "label": "Initializer",
          "namespace": "main_graph/: transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/model.layers.1: transformers.models.llama.modeling_llama.LlamaDecoderLayer/model.layers.1.mlp: transformers.models.llama.modeling_llama.LlamaMLP/model.layers.1.mlp.down_proj: torch.nn.modules.linear.Linear/linear_13: aten.linear.default",
          "subgraphIds": [],
          "attrs": [],
          "incomingEdges": [],
          "outputsMetadata": [
            {
              "id": "0",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "val_465"
                },
                {
                  "key": "tensor_shape",
                  "value": "FLOAT[8192,2048]"
                },
                {
                  "key": "value",
                  "value": "ExternalTensor<FLOAT,[8192,2048]>(location='model_SmolLM17b_optimized.onnx.data', name='val_465', offset=469827584, length=67108864, base_dir='')"
                }
              ]
            }
          ],
          "inputsMetadata": [],
          "style": null,
          "config": null
        },
        {
          "id": "[value] val_16",
          "label": "Initializer",
          "namespace": "main_graph",
          "subgraphIds": [],
          "attrs": [
            {
              "key": "__value",
              "value": "[1.0,0.7498942017555237,0.5623413324356079,0.4216965138912201,0.3162277638912201,0.23713736236095428,0.17782793939113617,0.1333521455526352,0.10000000149011612,0.07498941570520401,0.05623412877321243,0.04216964915394783,0.03162277862429619,0.0237137358635664,0.017782794311642647,0.01333521492779255]"
            }
          ],
          "incomingEdges": [],
          "outputsMetadata": [
            {
              "id": "0",
              "attrs": [
                {
                  "key": "__tensor_tag",
                  "value": "val_16"
                },
                {
                  "key": "tensor_shape",
                  "value": "FLOAT[1,32]"
                },
                {
                  "key": "value",
                  "value": "TensorProtoTensor<FLOAT,[1,32]>(name='val_16')"
                }
              ]
            }
          ],
          "inputsMetadata": [],
          "style": null,
          "config": null
        },
        {
          "id": "[value] linear_14",
          "label": "Output",
          "namespace": "",
          "subgraphIds": [],
          "attrs": [
            {
              "key": "name",
              "value": "linear_14"
            },
            {
              "key": "index",
              "value": "0"
            }
          ],
          "incomingEdges": [
            {
              "sourceNodeId": "node_MatMul_702",
              "sourceNodeOutputId": "0",
              "targetNodeInputId": "0"
            }
          ],
          "outputsMetadata": [],
          "inputsMetadata": [],
          "style": null,
          "config": null
        },
        {
          "id": "[value] cat_3",
          "label": "Output",
          "namespace": "",
          "subgraphIds": [],
          "attrs": [
            {
              "key": "name",
              "value": "cat_3"
            },
            {
              "key": "index",
              "value": "1"
            }
          ],
          "incomingEdges": [
            {
              "sourceNodeId": "node_MultiHeadAttention_62",
              "sourceNodeOutputId": "1",
              "targetNodeInputId": "0"
            }
          ],
          "outputsMetadata": [],
          "inputsMetadata": [],
          "style": null,
          "config": null
        },
        {
          "id": "[value] cat_7",
          "label": "Output",
          "namespace": "",
          "subgraphIds": [],
          "attrs": [
            {
              "key": "name",
              "value": "cat_7"
            },
            {
              "key": "index",
              "value": "2"
            }
          ],
          "incomingEdges": [
            {
              "sourceNodeId": "node_MultiHeadAttention_67",
              "sourceNodeOutputId": "1",
              "targetNodeInputId": "0"
            }
          ],
          "outputsMetadata": [],
          "inputsMetadata": [],
          "style": null,
          "config": null
        },
        {
          "id": "[value] cat_4",
          "label": "Output",
          "namespace": "",
          "subgraphIds": [],
          "attrs": [
            {
              "key": "name",
              "value": "cat_4"
            },
            {
              "key": "index",
              "value": "3"
            }
          ],
          "incomingEdges": [
            {
              "sourceNodeId": "node_MultiHeadAttention_62",
              "sourceNodeOutputId": "2",
              "targetNodeInputId": "0"
            }
          ],
          "outputsMetadata": [],
          "inputsMetadata": [],
          "style": null,
          "config": null
        },
        {
          "id": "[value] cat_8",
          "label": "Output",
          "namespace": "",
          "subgraphIds": [],
          "attrs": [
            {
              "key": "name",
              "value": "cat_8"
            },
            {
              "key": "index",
              "value": "4"
            }
          ],
          "incomingEdges": [
            {
              "sourceNodeId": "node_MultiHeadAttention_67",
              "sourceNodeOutputId": "2",
              "targetNodeInputId": "0"
            }
          ],
          "outputsMetadata": [],
          "inputsMetadata": [],
          "style": null,
          "config": null
        }
      ],
      "groupNodeAttributes": {
        "": {
          "opset_imports": "{'': 18, 'com.microsoft': 1}",
          "producer_name": "pytorch",
          "producer_version": "2.8.0.dev20250530+cu126",
          "domain": "None",
          "model_version": "None",
          "doc_string": "None"
        },
        "main_graph": {
          "[metadata] pkg.torch.export.ExportedProgram.graph_signature": "\n# inputs\np_model_embed_tokens_weight: PARAMETER target='model.embed_tokens.weight'\np_model_layers_0_self_attn_q_proj_weight: PARAMETER target='model.layers.0.self_attn.q_proj.weight'\np_model_layers_0_self_attn_k_proj_weight: PARAMETER target='model.layers.0.self_attn.k_proj.weight'\np_model_layers_0_self_attn_v_proj_weight: PARAMETER target='model.layers.0.self_attn.v_proj.weight'\np_model_layers_0_self_attn_o_proj_weight: PARAMETER target='model.layers.0.self_attn.o_proj.weight'\np_model_layers_0_mlp_gate_proj_weight: PARAMETER target='model.layers.0.mlp.gate_proj.weight'\np_model_layers_0_mlp_up_proj_weight: PARAMETER target='model.layers.0.mlp.up_proj.weight'\np_model_layers_0_mlp_down_proj_weight: PARAMETER target='model.layers.0.mlp.down_proj.weight'\np_model_layers_0_input_layernorm_weight: PARAMETER target='model.layers.0.input_layernorm.weight'\np_model_layers_0_post_attention_layernorm_weight: PARAMETER target='model.layers.0.post_attention_layernorm.weight'\np_model_layers_1_self_attn_q_proj_weight: PARAMETER target='model.layers.1.self_attn.q_proj.weight'\np_model_layers_1_self_attn_k_proj_weight: PARAMETER target='model.layers.1.self_attn.k_proj.weight'\np_model_layers_1_self_attn_v_proj_weight: PARAMETER target='model.layers.1.self_attn.v_proj.weight'\np_model_layers_1_self_attn_o_proj_weight: PARAMETER target='model.layers.1.self_attn.o_proj.weight'\np_model_layers_1_mlp_gate_proj_weight: PARAMETER target='model.layers.1.mlp.gate_proj.weight'\np_model_layers_1_mlp_up_proj_weight: PARAMETER target='model.layers.1.mlp.up_proj.weight'\np_model_layers_1_mlp_down_proj_weight: PARAMETER target='model.layers.1.mlp.down_proj.weight'\np_model_layers_1_input_layernorm_weight: PARAMETER target='model.layers.1.input_layernorm.weight'\np_model_layers_1_post_attention_layernorm_weight: PARAMETER target='model.layers.1.post_attention_layernorm.weight'\np_model_norm_weight: PARAMETER target='model.norm.weight'\np_lm_head_weight: PARAMETER target='lm_head.weight'\nb_model_rotary_emb_inv_freq: BUFFER target='model.rotary_emb.inv_freq' persistent=False\ninput_ids: USER_INPUT\nattention_mask: USER_INPUT\nposition_ids: USER_INPUT\npast_key_values_key_cache_0: USER_INPUT\npast_key_values_key_cache_1: USER_INPUT\npast_key_values_value_cache_0: USER_INPUT\npast_key_values_value_cache_1: USER_INPUT\ninputs_embeds: USER_INPUT\nlabels: USER_INPUT\nuse_cache: USER_INPUT\noutput_attentions: USER_INPUT\noutput_hidden_states: USER_INPUT\ncache_position: USER_INPUT\nlogits_to_keep: USER_INPUT\n\n# outputs\nlinear_14: USER_OUTPUT\ncat_3: USER_OUTPUT\ncat_7: USER_OUTPUT\ncat_4: USER_OUTPUT\ncat_8: USER_OUTPUT\n",
          "[metadata] pkg.torch.export.ExportedProgram.range_constraints": "{s34: VR[1, 1024], s16: VR[8, 32768], s16 + s17: VR[10, 36864], s17: VR[1, 4096], s61: VR[2, int_oo], s75: VR[2, int_oo], s54: VR[2, int_oo]}"
        }
      },
      "collectionLabel": "model_SmolLM17b_optimized.onnx"
    }
  ],
  "graphsWithLevel": [
    {
      "graph": {
        "id": "main_graph (2)",
        "nodes": [
          {
            "id": "[value] input_ids",
            "label": "Input",
            "namespace": "",
            "subgraphIds": [],
            "attrs": [
              {
                "key": "name",
                "value": "input_ids"
              },
              {
                "key": "index",
                "value": "0"
              }
            ],
            "incomingEdges": [],
            "outputsMetadata": [
              {
                "id": "0",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "input_ids"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "INT64[s34,s16]"
                  },
                  {
                    "key": "[metadata] pkg.torch.export.graph_signature.InputSpec.kind",
                    "value": "USER_INPUT"
                  },
                  {
                    "key": "[metadata] pkg.torch.export.graph_signature.InputSpec.persistent",
                    "value": "None"
                  }
                ]
              }
            ],
            "inputsMetadata": [],
            "style": null,
            "config": null
          },
          {
            "id": "[value] attention_mask",
            "label": "Input",
            "namespace": "",
            "subgraphIds": [],
            "attrs": [
              {
                "key": "name",
                "value": "attention_mask"
              },
              {
                "key": "index",
                "value": "1"
              }
            ],
            "incomingEdges": [],
            "outputsMetadata": [
              {
                "id": "0",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "attention_mask"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "INT64[s34,s16 + s17]"
                  },
                  {
                    "key": "[metadata] pkg.torch.export.graph_signature.InputSpec.kind",
                    "value": "USER_INPUT"
                  },
                  {
                    "key": "[metadata] pkg.torch.export.graph_signature.InputSpec.persistent",
                    "value": "None"
                  }
                ]
              }
            ],
            "inputsMetadata": [],
            "style": null,
            "config": null
          },
          {
            "id": "[value] past_key_values_key_cache_0",
            "label": "Input",
            "namespace": "",
            "subgraphIds": [],
            "attrs": [
              {
                "key": "name",
                "value": "past_key_values_key_cache_0"
              },
              {
                "key": "index",
                "value": "2"
              }
            ],
            "incomingEdges": [],
            "outputsMetadata": [
              {
                "id": "0",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "past_key_values_key_cache_0"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "FLOAT[s34,32,s17,64]"
                  },
                  {
                    "key": "[metadata] pkg.torch.export.graph_signature.InputSpec.kind",
                    "value": "USER_INPUT"
                  },
                  {
                    "key": "[metadata] pkg.torch.export.graph_signature.InputSpec.persistent",
                    "value": "None"
                  }
                ]
              }
            ],
            "inputsMetadata": [],
            "style": null,
            "config": null
          },
          {
            "id": "[value] past_key_values_key_cache_1",
            "label": "Input",
            "namespace": "",
            "subgraphIds": [],
            "attrs": [
              {
                "key": "name",
                "value": "past_key_values_key_cache_1"
              },
              {
                "key": "index",
                "value": "3"
              }
            ],
            "incomingEdges": [],
            "outputsMetadata": [
              {
                "id": "0",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "past_key_values_key_cache_1"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "FLOAT[s34,32,s17,64]"
                  },
                  {
                    "key": "[metadata] pkg.torch.export.graph_signature.InputSpec.kind",
                    "value": "USER_INPUT"
                  },
                  {
                    "key": "[metadata] pkg.torch.export.graph_signature.InputSpec.persistent",
                    "value": "None"
                  }
                ]
              }
            ],
            "inputsMetadata": [],
            "style": null,
            "config": null
          },
          {
            "id": "[value] past_key_values_value_cache_0",
            "label": "Input",
            "namespace": "",
            "subgraphIds": [],
            "attrs": [
              {
                "key": "name",
                "value": "past_key_values_value_cache_0"
              },
              {
                "key": "index",
                "value": "4"
              }
            ],
            "incomingEdges": [],
            "outputsMetadata": [
              {
                "id": "0",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "past_key_values_value_cache_0"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "FLOAT[s34,32,s17,64]"
                  },
                  {
                    "key": "[metadata] pkg.torch.export.graph_signature.InputSpec.kind",
                    "value": "USER_INPUT"
                  },
                  {
                    "key": "[metadata] pkg.torch.export.graph_signature.InputSpec.persistent",
                    "value": "None"
                  }
                ]
              }
            ],
            "inputsMetadata": [],
            "style": null,
            "config": null
          },
          {
            "id": "[value] past_key_values_value_cache_1",
            "label": "Input",
            "namespace": "",
            "subgraphIds": [],
            "attrs": [
              {
                "key": "name",
                "value": "past_key_values_value_cache_1"
              },
              {
                "key": "index",
                "value": "5"
              }
            ],
            "incomingEdges": [],
            "outputsMetadata": [
              {
                "id": "0",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "past_key_values_value_cache_1"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "FLOAT[s34,32,s17,64]"
                  },
                  {
                    "key": "[metadata] pkg.torch.export.graph_signature.InputSpec.kind",
                    "value": "USER_INPUT"
                  },
                  {
                    "key": "[metadata] pkg.torch.export.graph_signature.InputSpec.persistent",
                    "value": "None"
                  }
                ]
              }
            ],
            "inputsMetadata": [],
            "style": null,
            "config": null
          },
          {
            "id": "node_Shape_2",
            "label": "Shape",
            "namespace": "main_graph/_empty_nn_module_stack_from_metadata_hook: _empty_nn_module_stack_from_metadata_hook/sym_size_int_61: aten.sym_size.int",
            "subgraphIds": [],
            "attrs": [
              {
                "key": "end",
                "value": "2"
              },
              {
                "key": "start",
                "value": "1"
              },
              {
                "key": "[metadata] namespace",
                "value": "_empty_nn_module_stack_from_metadata_hook: _empty_nn_module_stack_from_metadata_hook/sym_size_int_61: aten.sym_size.int"
              },
              {
                "key": "[metadata] pkg.torch.onnx.class_hierarchy",
                "value": "['_empty_nn_module_stack_from_metadata_hook', 'aten.sym_size.int']"
              },
              {
                "key": "[metadata] pkg.torch.onnx.fx_node",
                "value": "%sym_size_int_61 : [num_users=10] = call_function[target=torch.ops.aten.sym_size.int](args = (%input_ids, 1), kwargs = {})"
              },
              {
                "key": "[metadata] pkg.torch.onnx.name_scopes",
                "value": "['_empty_nn_module_stack_from_metadata_hook', 'sym_size_int_61']"
              },
              {
                "key": "[metadata] pkg.torch.onnx.stack_trace",
                "value": "File \"torch/fx/passes/runtime_assert.py\", line 24, in insert_deferred_runtime_asserts"
              }
            ],
            "incomingEdges": [
              {
                "sourceNodeId": "[value] input_ids",
                "sourceNodeOutputId": "0",
                "targetNodeInputId": "0"
              }
            ],
            "outputsMetadata": [
              {
                "id": "0",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "val_1"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "INT64[1]"
                  },
                  {
                    "key": "param_name",
                    "value": "shape"
                  }
                ]
              }
            ],
            "inputsMetadata": [
              {
                "id": "0",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "input_ids"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "INT64[s34,s16]"
                  },
                  {
                    "key": "[metadata] pkg.torch.export.graph_signature.InputSpec.kind",
                    "value": "USER_INPUT"
                  },
                  {
                    "key": "[metadata] pkg.torch.export.graph_signature.InputSpec.persistent",
                    "value": "None"
                  },
                  {
                    "key": "param_name",
                    "value": "data"
                  }
                ]
              }
            ],
            "style": null,
            "config": null
          },
          {
            "id": "node_Squeeze_3",
            "label": "Squeeze",
            "namespace": "main_graph/_empty_nn_module_stack_from_metadata_hook: _empty_nn_module_stack_from_metadata_hook/sym_size_int_61: aten.sym_size.int",
            "subgraphIds": [],
            "attrs": [
              {
                "key": "[metadata] namespace",
                "value": "_empty_nn_module_stack_from_metadata_hook: _empty_nn_module_stack_from_metadata_hook/sym_size_int_61: aten.sym_size.int"
              },
              {
                "key": "[metadata] pkg.torch.onnx.class_hierarchy",
                "value": "['_empty_nn_module_stack_from_metadata_hook', 'aten.sym_size.int']"
              },
              {
                "key": "[metadata] pkg.torch.onnx.fx_node",
                "value": "%sym_size_int_61 : [num_users=10] = call_function[target=torch.ops.aten.sym_size.int](args = (%input_ids, 1), kwargs = {})"
              },
              {
                "key": "[metadata] pkg.torch.onnx.name_scopes",
                "value": "['_empty_nn_module_stack_from_metadata_hook', 'sym_size_int_61']"
              },
              {
                "key": "[metadata] pkg.torch.onnx.stack_trace",
                "value": "File \"torch/fx/passes/runtime_assert.py\", line 24, in insert_deferred_runtime_asserts"
              }
            ],
            "incomingEdges": [
              {
                "sourceNodeId": "node_Shape_2",
                "sourceNodeOutputId": "0",
                "targetNodeInputId": "0"
              }
            ],
            "outputsMetadata": [
              {
                "id": "0",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "sym_size_int_61"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "INT64[]"
                  },
                  {
                    "key": "param_name",
                    "value": "squeezed"
                  }
                ]
              }
            ],
            "inputsMetadata": [
              {
                "id": "0",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "val_1"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "INT64[1]"
                  },
                  {
                    "key": "param_name",
                    "value": "data"
                  }
                ]
              }
            ],
            "style": null,
            "config": null
          },
          {
            "id": "node_Shape_10",
            "label": "Shape",
            "namespace": "main_graph/_empty_nn_module_stack_from_metadata_hook: _empty_nn_module_stack_from_metadata_hook/sym_size_int_67: aten.sym_size.int",
            "subgraphIds": [],
            "attrs": [
              {
                "key": "end",
                "value": "3"
              },
              {
                "key": "start",
                "value": "2"
              },
              {
                "key": "[metadata] namespace",
                "value": "_empty_nn_module_stack_from_metadata_hook: _empty_nn_module_stack_from_metadata_hook/sym_size_int_67: aten.sym_size.int"
              },
              {
                "key": "[metadata] pkg.torch.onnx.class_hierarchy",
                "value": "['_empty_nn_module_stack_from_metadata_hook', 'aten.sym_size.int']"
              },
              {
                "key": "[metadata] pkg.torch.onnx.fx_node",
                "value": "%sym_size_int_67 : [num_users=5] = call_function[target=torch.ops.aten.sym_size.int](args = (%past_key_values_key_cache_1, 2), kwargs = {})"
              },
              {
                "key": "[metadata] pkg.torch.onnx.name_scopes",
                "value": "['_empty_nn_module_stack_from_metadata_hook', 'sym_size_int_67']"
              },
              {
                "key": "[metadata] pkg.torch.onnx.stack_trace",
                "value": "File \"torch/fx/passes/runtime_assert.py\", line 24, in insert_deferred_runtime_asserts"
              }
            ],
            "incomingEdges": [
              {
                "sourceNodeId": "[value] past_key_values_key_cache_1",
                "sourceNodeOutputId": "0",
                "targetNodeInputId": "0"
              }
            ],
            "outputsMetadata": [
              {
                "id": "0",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "val_5"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "INT64[1]"
                  },
                  {
                    "key": "param_name",
                    "value": "shape"
                  }
                ]
              }
            ],
            "inputsMetadata": [
              {
                "id": "0",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "past_key_values_key_cache_1"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "FLOAT[s34,32,s17,64]"
                  },
                  {
                    "key": "[metadata] pkg.torch.export.graph_signature.InputSpec.kind",
                    "value": "USER_INPUT"
                  },
                  {
                    "key": "[metadata] pkg.torch.export.graph_signature.InputSpec.persistent",
                    "value": "None"
                  },
                  {
                    "key": "param_name",
                    "value": "data"
                  }
                ]
              }
            ],
            "style": null,
            "config": null
          },
          {
            "id": "node_Squeeze_11",
            "label": "Squeeze",
            "namespace": "main_graph/_empty_nn_module_stack_from_metadata_hook: _empty_nn_module_stack_from_metadata_hook/sym_size_int_67: aten.sym_size.int",
            "subgraphIds": [],
            "attrs": [
              {
                "key": "[metadata] namespace",
                "value": "_empty_nn_module_stack_from_metadata_hook: _empty_nn_module_stack_from_metadata_hook/sym_size_int_67: aten.sym_size.int"
              },
              {
                "key": "[metadata] pkg.torch.onnx.class_hierarchy",
                "value": "['_empty_nn_module_stack_from_metadata_hook', 'aten.sym_size.int']"
              },
              {
                "key": "[metadata] pkg.torch.onnx.fx_node",
                "value": "%sym_size_int_67 : [num_users=5] = call_function[target=torch.ops.aten.sym_size.int](args = (%past_key_values_key_cache_1, 2), kwargs = {})"
              },
              {
                "key": "[metadata] pkg.torch.onnx.name_scopes",
                "value": "['_empty_nn_module_stack_from_metadata_hook', 'sym_size_int_67']"
              },
              {
                "key": "[metadata] pkg.torch.onnx.stack_trace",
                "value": "File \"torch/fx/passes/runtime_assert.py\", line 24, in insert_deferred_runtime_asserts"
              }
            ],
            "incomingEdges": [
              {
                "sourceNodeId": "node_Shape_10",
                "sourceNodeOutputId": "0",
                "targetNodeInputId": "0"
              }
            ],
            "outputsMetadata": [
              {
                "id": "0",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "sym_size_int_67"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "INT64[]"
                  },
                  {
                    "key": "param_name",
                    "value": "squeezed"
                  }
                ]
              }
            ],
            "inputsMetadata": [
              {
                "id": "0",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "val_5"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "INT64[1]"
                  },
                  {
                    "key": "param_name",
                    "value": "data"
                  }
                ]
              }
            ],
            "style": null,
            "config": null
          },
          {
            "id": "node_Shape_12",
            "label": "Shape",
            "namespace": "main_graph/_empty_nn_module_stack_from_metadata_hook: _empty_nn_module_stack_from_metadata_hook/sym_size_int_68: aten.sym_size.int",
            "subgraphIds": [],
            "attrs": [
              {
                "key": "end",
                "value": "1"
              },
              {
                "key": "start",
                "value": "0"
              },
              {
                "key": "[metadata] namespace",
                "value": "_empty_nn_module_stack_from_metadata_hook: _empty_nn_module_stack_from_metadata_hook/sym_size_int_68: aten.sym_size.int"
              },
              {
                "key": "[metadata] pkg.torch.onnx.class_hierarchy",
                "value": "['_empty_nn_module_stack_from_metadata_hook', 'aten.sym_size.int']"
              },
              {
                "key": "[metadata] pkg.torch.onnx.fx_node",
                "value": "%sym_size_int_68 : [num_users=16] = call_function[target=torch.ops.aten.sym_size.int](args = (%past_key_values_value_cache_0, 0), kwargs = {})"
              },
              {
                "key": "[metadata] pkg.torch.onnx.name_scopes",
                "value": "['_empty_nn_module_stack_from_metadata_hook', 'sym_size_int_68']"
              },
              {
                "key": "[metadata] pkg.torch.onnx.stack_trace",
                "value": "File \"torch/fx/passes/runtime_assert.py\", line 24, in insert_deferred_runtime_asserts"
              }
            ],
            "incomingEdges": [
              {
                "sourceNodeId": "[value] past_key_values_value_cache_0",
                "sourceNodeOutputId": "0",
                "targetNodeInputId": "0"
              }
            ],
            "outputsMetadata": [
              {
                "id": "0",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "val_6"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "INT64[1]"
                  },
                  {
                    "key": "param_name",
                    "value": "shape"
                  }
                ]
              }
            ],
            "inputsMetadata": [
              {
                "id": "0",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "past_key_values_value_cache_0"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "FLOAT[s34,32,s17,64]"
                  },
                  {
                    "key": "[metadata] pkg.torch.export.graph_signature.InputSpec.kind",
                    "value": "USER_INPUT"
                  },
                  {
                    "key": "[metadata] pkg.torch.export.graph_signature.InputSpec.persistent",
                    "value": "None"
                  },
                  {
                    "key": "param_name",
                    "value": "data"
                  }
                ]
              }
            ],
            "style": null,
            "config": null
          },
          {
            "id": "node_Gather_20",
            "label": "Gather",
            "namespace": "main_graph/: transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/model.embed_tokens: torch.nn.modules.sparse.Embedding/embedding: aten.embedding.default",
            "subgraphIds": [],
            "attrs": [
              {
                "key": "axis",
                "value": "0"
              },
              {
                "key": "[metadata] namespace",
                "value": ": transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/model.embed_tokens: torch.nn.modules.sparse.Embedding/embedding: aten.embedding.default"
              },
              {
                "key": "[metadata] pkg.torch.onnx.class_hierarchy",
                "value": "['transformers.models.llama.modeling_llama.LlamaForCausalLM', 'transformers.models.llama.modeling_llama.LlamaModel', 'torch.nn.modules.sparse.Embedding', 'aten.embedding.default']"
              },
              {
                "key": "[metadata] pkg.torch.onnx.fx_node",
                "value": "%embedding : [num_users=3] = call_function[target=torch.ops.aten.embedding.default](args = (%p_lm_head_weight, %input_ids), kwargs = {})"
              },
              {
                "key": "[metadata] pkg.torch.onnx.name_scopes",
                "value": "['', 'model', 'model.embed_tokens', 'embedding']"
              },
              {
                "key": "[metadata] pkg.torch.onnx.stack_trace",
                "value": "File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 688, in forward\n    outputs: BaseModelOutputWithPast = self.model(\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 422, in forward\n    inputs_embeds = self.embed_tokens(input_ids)\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/torch/nn/modules/sparse.py\", line 190, in forward\n    return F.embedding("
              }
            ],
            "incomingEdges": [
              {
                "sourceNodeId": "[value] lm_head.weight",
                "sourceNodeOutputId": "0",
                "targetNodeInputId": "0"
              },
              {
                "sourceNodeId": "[value] input_ids",
                "sourceNodeOutputId": "0",
                "targetNodeInputId": "1"
              }
            ],
            "outputsMetadata": [
              {
                "id": "0",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "embedding"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "FLOAT[s34,s16,2048]"
                  },
                  {
                    "key": "param_name",
                    "value": "output"
                  }
                ]
              }
            ],
            "inputsMetadata": [
              {
                "id": "0",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "lm_head.weight"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "FLOAT[49152,2048]"
                  },
                  {
                    "key": "param_name",
                    "value": "data"
                  }
                ]
              },
              {
                "id": "1",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "input_ids"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "INT64[s34,s16]"
                  },
                  {
                    "key": "[metadata] pkg.torch.export.graph_signature.InputSpec.kind",
                    "value": "USER_INPUT"
                  },
                  {
                    "key": "[metadata] pkg.torch.export.graph_signature.InputSpec.persistent",
                    "value": "None"
                  },
                  {
                    "key": "param_name",
                    "value": "indices"
                  }
                ]
              }
            ],
            "style": null,
            "config": null
          },
          {
            "id": "node_Add_33",
            "label": "Add",
            "namespace": "main_graph/: transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/add_4: <built-in function add>",
            "subgraphIds": [],
            "attrs": [
              {
                "key": "[metadata] namespace",
                "value": ": transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/add_4: <built-in function add>"
              },
              {
                "key": "[metadata] pkg.torch.onnx.class_hierarchy",
                "value": "['transformers.models.llama.modeling_llama.LlamaForCausalLM', 'transformers.models.llama.modeling_llama.LlamaModel', '<built-in function add>']"
              },
              {
                "key": "[metadata] pkg.torch.onnx.fx_node",
                "value": "%add_4 : [num_users=7] = call_function[target=operator.add](args = (%sym_size_int_67, %sym_size_int_61), kwargs = {})"
              },
              {
                "key": "[metadata] pkg.torch.onnx.name_scopes",
                "value": "['', 'model', 'add_4']"
              },
              {
                "key": "[metadata] pkg.torch.onnx.stack_trace",
                "value": "File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 688, in forward\n    outputs: BaseModelOutputWithPast = self.model(\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 430, in forward\n    past_seen_tokens, past_seen_tokens + inputs_embeds.shape[1], device=inputs_embeds.device"
              }
            ],
            "incomingEdges": [
              {
                "sourceNodeId": "node_Squeeze_11",
                "sourceNodeOutputId": "0",
                "targetNodeInputId": "0"
              },
              {
                "sourceNodeId": "node_Squeeze_3",
                "sourceNodeOutputId": "0",
                "targetNodeInputId": "1"
              }
            ],
            "outputsMetadata": [
              {
                "id": "0",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "add_4"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "INT64[]"
                  },
                  {
                    "key": "param_name",
                    "value": "C"
                  }
                ]
              }
            ],
            "inputsMetadata": [
              {
                "id": "0",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "sym_size_int_67"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "INT64[]"
                  },
                  {
                    "key": "param_name",
                    "value": "A"
                  }
                ]
              },
              {
                "id": "1",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "sym_size_int_61"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "INT64[]"
                  },
                  {
                    "key": "param_name",
                    "value": "B"
                  }
                ]
              }
            ],
            "style": null,
            "config": null
          },
          {
            "id": "node_Constant_704",
            "label": "Constant",
            "namespace": "main_graph/: transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/arange: aten.arange.start",
            "subgraphIds": [],
            "attrs": [
              {
                "key": "__value",
                "value": "1"
              },
              {
                "key": "value",
                "value": "TensorProtoTensor<INT64,[]>(array(1), name='val_11')"
              }
            ],
            "incomingEdges": [],
            "outputsMetadata": [
              {
                "id": "0",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "val_11"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "INT64[]"
                  },
                  {
                    "key": "param_name",
                    "value": "output"
                  }
                ]
              }
            ],
            "inputsMetadata": [],
            "style": null,
            "config": null
          },
          {
            "id": "node_Range_36",
            "label": "Range",
            "namespace": "main_graph/: transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/arange: aten.arange.start",
            "subgraphIds": [],
            "attrs": [
              {
                "key": "[metadata] namespace",
                "value": ": transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/arange: aten.arange.start"
              },
              {
                "key": "[metadata] pkg.torch.onnx.class_hierarchy",
                "value": "['transformers.models.llama.modeling_llama.LlamaForCausalLM', 'transformers.models.llama.modeling_llama.LlamaModel', 'aten.arange.start']"
              },
              {
                "key": "[metadata] pkg.torch.onnx.fx_node",
                "value": "%arange : [num_users=2] = call_function[target=torch.ops.aten.arange.start](args = (%sym_size_int_67, %add_4), kwargs = {device: cuda:0, pin_memory: False})"
              },
              {
                "key": "[metadata] pkg.torch.onnx.name_scopes",
                "value": "['', 'model', 'arange']"
              },
              {
                "key": "[metadata] pkg.torch.onnx.stack_trace",
                "value": "File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 688, in forward\n    outputs: BaseModelOutputWithPast = self.model(\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 429, in forward\n    cache_position = torch.arange("
              }
            ],
            "incomingEdges": [
              {
                "sourceNodeId": "node_Squeeze_11",
                "sourceNodeOutputId": "0",
                "targetNodeInputId": "0"
              },
              {
                "sourceNodeId": "node_Add_33",
                "sourceNodeOutputId": "0",
                "targetNodeInputId": "1"
              },
              {
                "sourceNodeId": "node_Constant_704",
                "sourceNodeOutputId": "0",
                "targetNodeInputId": "2"
              }
            ],
            "outputsMetadata": [
              {
                "id": "0",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "arange"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "INT64[s16]"
                  },
                  {
                    "key": "param_name",
                    "value": "output"
                  }
                ]
              }
            ],
            "inputsMetadata": [
              {
                "id": "0",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "sym_size_int_67"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "INT64[]"
                  },
                  {
                    "key": "param_name",
                    "value": "start"
                  }
                ]
              },
              {
                "id": "1",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "add_4"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "INT64[]"
                  },
                  {
                    "key": "param_name",
                    "value": "limit"
                  }
                ]
              },
              {
                "id": "2",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "val_11"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "INT64[]"
                  },
                  {
                    "key": "param_name",
                    "value": "delta"
                  }
                ]
              }
            ],
            "style": null,
            "config": null
          },
          {
            "id": "node_Constant_706",
            "label": "Constant",
            "namespace": "main_graph/: transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/full: aten.full.default",
            "subgraphIds": [],
            "attrs": [
              {
                "key": "__value",
                "value": "-3.4028234663852886e+38"
              },
              {
                "key": "value",
                "value": "TensorProtoTensor<FLOAT,[]>(array(-3.4028235e+38, dtype=float32), name='val_14')"
              }
            ],
            "incomingEdges": [],
            "outputsMetadata": [
              {
                "id": "0",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "val_14"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "FLOAT[]"
                  },
                  {
                    "key": "param_name",
                    "value": "output"
                  }
                ]
              }
            ],
            "inputsMetadata": [],
            "style": null,
            "config": null
          },
          {
            "id": "node_Constant_43",
            "label": "Constant",
            "namespace": "main_graph/: transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/full: aten.full.default",
            "subgraphIds": [],
            "attrs": [
              {
                "key": "__value",
                "value": "[-1]"
              },
              {
                "key": "value",
                "value": "TensorProtoTensor<INT64,[1]>(array([-1]), name='')"
              },
              {
                "key": "[metadata] namespace",
                "value": ": transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/full: aten.full.default"
              },
              {
                "key": "[metadata] pkg.torch.onnx.class_hierarchy",
                "value": "['transformers.models.llama.modeling_llama.LlamaForCausalLM', 'transformers.models.llama.modeling_llama.LlamaModel', 'aten.full.default']"
              },
              {
                "key": "[metadata] pkg.torch.onnx.fx_node",
                "value": "%full : [num_users=1] = call_function[target=torch.ops.aten.full.default](args = ([%sym_size_int_61, %add_4], -3.4028234663852886e+38), kwargs = {dtype: torch.float32, device: cuda:0, pin_memory: False})"
              },
              {
                "key": "[metadata] pkg.torch.onnx.name_scopes",
                "value": "['', 'model', 'full']"
              },
              {
                "key": "[metadata] pkg.torch.onnx.stack_trace",
                "value": "File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 688, in forward\n    outputs: BaseModelOutputWithPast = self.model(\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 436, in forward\n    causal_mask = self._update_causal_mask("
              }
            ],
            "incomingEdges": [],
            "outputsMetadata": [
              {
                "id": "0",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "val_17"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "INT64[1]"
                  },
                  {
                    "key": "param_name",
                    "value": "output"
                  }
                ]
              }
            ],
            "inputsMetadata": [],
            "style": null,
            "config": null
          },
          {
            "id": "node_Reshape_44",
            "label": "Reshape",
            "namespace": "main_graph/: transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/full: aten.full.default",
            "subgraphIds": [],
            "attrs": [
              {
                "key": "allowzero",
                "value": "0"
              },
              {
                "key": "[metadata] namespace",
                "value": ": transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/full: aten.full.default"
              },
              {
                "key": "[metadata] pkg.torch.onnx.class_hierarchy",
                "value": "['transformers.models.llama.modeling_llama.LlamaForCausalLM', 'transformers.models.llama.modeling_llama.LlamaModel', 'aten.full.default']"
              },
              {
                "key": "[metadata] pkg.torch.onnx.fx_node",
                "value": "%full : [num_users=1] = call_function[target=torch.ops.aten.full.default](args = ([%sym_size_int_61, %add_4], -3.4028234663852886e+38), kwargs = {dtype: torch.float32, device: cuda:0, pin_memory: False})"
              },
              {
                "key": "[metadata] pkg.torch.onnx.name_scopes",
                "value": "['', 'model', 'full']"
              },
              {
                "key": "[metadata] pkg.torch.onnx.stack_trace",
                "value": "File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 688, in forward\n    outputs: BaseModelOutputWithPast = self.model(\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 436, in forward\n    causal_mask = self._update_causal_mask("
              }
            ],
            "incomingEdges": [
              {
                "sourceNodeId": "node_Add_33",
                "sourceNodeOutputId": "0",
                "targetNodeInputId": "0"
              },
              {
                "sourceNodeId": "node_Constant_43",
                "sourceNodeOutputId": "0",
                "targetNodeInputId": "1"
              }
            ],
            "outputsMetadata": [
              {
                "id": "0",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "val_18"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "INT64[1]"
                  },
                  {
                    "key": "param_name",
                    "value": "reshaped"
                  }
                ]
              }
            ],
            "inputsMetadata": [
              {
                "id": "0",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "add_4"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "INT64[]"
                  },
                  {
                    "key": "param_name",
                    "value": "data"
                  }
                ]
              },
              {
                "id": "1",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "val_17"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "INT64[1]"
                  },
                  {
                    "key": "param_name",
                    "value": "shape"
                  }
                ]
              }
            ],
            "style": null,
            "config": null
          },
          {
            "id": "node_Concat_45",
            "label": "Concat",
            "namespace": "main_graph/: transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/full: aten.full.default",
            "subgraphIds": [],
            "attrs": [
              {
                "key": "axis",
                "value": "0"
              },
              {
                "key": "[metadata] namespace",
                "value": ": transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/full: aten.full.default"
              },
              {
                "key": "[metadata] pkg.torch.onnx.class_hierarchy",
                "value": "['transformers.models.llama.modeling_llama.LlamaForCausalLM', 'transformers.models.llama.modeling_llama.LlamaModel', 'aten.full.default']"
              },
              {
                "key": "[metadata] pkg.torch.onnx.fx_node",
                "value": "%full : [num_users=1] = call_function[target=torch.ops.aten.full.default](args = ([%sym_size_int_61, %add_4], -3.4028234663852886e+38), kwargs = {dtype: torch.float32, device: cuda:0, pin_memory: False})"
              },
              {
                "key": "[metadata] pkg.torch.onnx.name_scopes",
                "value": "['', 'model', 'full']"
              },
              {
                "key": "[metadata] pkg.torch.onnx.stack_trace",
                "value": "File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 688, in forward\n    outputs: BaseModelOutputWithPast = self.model(\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 436, in forward\n    causal_mask = self._update_causal_mask("
              }
            ],
            "incomingEdges": [
              {
                "sourceNodeId": "node_Shape_2",
                "sourceNodeOutputId": "0",
                "targetNodeInputId": "0"
              },
              {
                "sourceNodeId": "node_Reshape_44",
                "sourceNodeOutputId": "0",
                "targetNodeInputId": "1"
              }
            ],
            "outputsMetadata": [
              {
                "id": "0",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "val_19"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "INT64[2]"
                  },
                  {
                    "key": "param_name",
                    "value": "concat_result"
                  }
                ]
              }
            ],
            "inputsMetadata": [
              {
                "id": "0",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "val_1"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "INT64[1]"
                  },
                  {
                    "key": "param_name",
                    "value": "inputs"
                  }
                ]
              },
              {
                "id": "1",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "val_18"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "INT64[1]"
                  },
                  {
                    "key": "param_name",
                    "value": "inputs"
                  }
                ]
              }
            ],
            "style": null,
            "config": null
          },
          {
            "id": "node_Expand_47",
            "label": "Expand",
            "namespace": "main_graph/: transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/full: aten.full.default",
            "subgraphIds": [],
            "attrs": [
              {
                "key": "[metadata] namespace",
                "value": ": transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/full: aten.full.default"
              },
              {
                "key": "[metadata] pkg.torch.onnx.class_hierarchy",
                "value": "['transformers.models.llama.modeling_llama.LlamaForCausalLM', 'transformers.models.llama.modeling_llama.LlamaModel', 'aten.full.default']"
              },
              {
                "key": "[metadata] pkg.torch.onnx.fx_node",
                "value": "%full : [num_users=1] = call_function[target=torch.ops.aten.full.default](args = ([%sym_size_int_61, %add_4], -3.4028234663852886e+38), kwargs = {dtype: torch.float32, device: cuda:0, pin_memory: False})"
              },
              {
                "key": "[metadata] pkg.torch.onnx.name_scopes",
                "value": "['', 'model', 'full']"
              },
              {
                "key": "[metadata] pkg.torch.onnx.stack_trace",
                "value": "File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 688, in forward\n    outputs: BaseModelOutputWithPast = self.model(\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 436, in forward\n    causal_mask = self._update_causal_mask("
              }
            ],
            "incomingEdges": [
              {
                "sourceNodeId": "node_Constant_706",
                "sourceNodeOutputId": "0",
                "targetNodeInputId": "0"
              },
              {
                "sourceNodeId": "node_Concat_45",
                "sourceNodeOutputId": "0",
                "targetNodeInputId": "1"
              }
            ],
            "outputsMetadata": [
              {
                "id": "0",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "full"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "FLOAT[s16,s16 + s17]"
                  },
                  {
                    "key": "param_name",
                    "value": "output"
                  }
                ]
              }
            ],
            "inputsMetadata": [
              {
                "id": "0",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "val_14"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "FLOAT[]"
                  },
                  {
                    "key": "param_name",
                    "value": "input"
                  }
                ]
              },
              {
                "id": "1",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "val_19"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "INT64[2]"
                  },
                  {
                    "key": "param_name",
                    "value": "shape"
                  }
                ]
              }
            ],
            "style": null,
            "config": null
          },
          {
            "id": "n0",
            "label": "Constant",
            "namespace": "main_graph",
            "subgraphIds": [],
            "attrs": [
              {
                "key": "__value",
                "value": "1"
              },
              {
                "key": "value_int",
                "value": "1"
              },
              {
                "key": "[metadata] namespace",
                "value": ": transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/triu: aten.triu.default"
              },
              {
                "key": "[metadata] pkg.torch.onnx.class_hierarchy",
                "value": "['transformers.models.llama.modeling_llama.LlamaForCausalLM', 'transformers.models.llama.modeling_llama.LlamaModel', 'aten.triu.default']"
              },
              {
                "key": "[metadata] pkg.torch.onnx.fx_node",
                "value": "%triu : [num_users=1] = call_function[target=torch.ops.aten.triu.default](args = (%full, 1), kwargs = {})"
              },
              {
                "key": "[metadata] pkg.torch.onnx.name_scopes",
                "value": "['', 'model', 'triu']"
              },
              {
                "key": "[metadata] pkg.torch.onnx.stack_trace",
                "value": "File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 688, in forward\n    outputs: BaseModelOutputWithPast = self.model(\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 436, in forward\n    causal_mask = self._update_causal_mask("
              }
            ],
            "incomingEdges": [],
            "outputsMetadata": [
              {
                "id": "0",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "diagonal"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "INT64[]"
                  },
                  {
                    "key": "param_name",
                    "value": "output"
                  }
                ]
              }
            ],
            "inputsMetadata": [],
            "style": null,
            "config": null
          },
          {
            "id": "n1",
            "label": "Trilu",
            "namespace": "main_graph/: transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/triu: aten.triu.default",
            "subgraphIds": [],
            "attrs": [
              {
                "key": "upper",
                "value": "1"
              },
              {
                "key": "[metadata] namespace",
                "value": ": transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/triu: aten.triu.default"
              },
              {
                "key": "[metadata] pkg.torch.onnx.class_hierarchy",
                "value": "['transformers.models.llama.modeling_llama.LlamaForCausalLM', 'transformers.models.llama.modeling_llama.LlamaModel', 'aten.triu.default']"
              },
              {
                "key": "[metadata] pkg.torch.onnx.fx_node",
                "value": "%triu : [num_users=1] = call_function[target=torch.ops.aten.triu.default](args = (%full, 1), kwargs = {})"
              },
              {
                "key": "[metadata] pkg.torch.onnx.name_scopes",
                "value": "['', 'model', 'triu']"
              },
              {
                "key": "[metadata] pkg.torch.onnx.stack_trace",
                "value": "File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 688, in forward\n    outputs: BaseModelOutputWithPast = self.model(\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 436, in forward\n    causal_mask = self._update_causal_mask("
              }
            ],
            "incomingEdges": [
              {
                "sourceNodeId": "node_Expand_47",
                "sourceNodeOutputId": "0",
                "targetNodeInputId": "0"
              },
              {
                "sourceNodeId": "n0",
                "sourceNodeOutputId": "0",
                "targetNodeInputId": "1"
              }
            ],
            "outputsMetadata": [
              {
                "id": "0",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "triu"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "FLOAT[s16,s16 + s17]"
                  },
                  {
                    "key": "param_name",
                    "value": "output"
                  }
                ]
              }
            ],
            "inputsMetadata": [
              {
                "id": "0",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "full"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "FLOAT[s16,s16 + s17]"
                  },
                  {
                    "key": "param_name",
                    "value": "input"
                  }
                ]
              },
              {
                "id": "1",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "diagonal"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "INT64[]"
                  },
                  {
                    "key": "param_name",
                    "value": "k"
                  }
                ]
              }
            ],
            "style": null,
            "config": null
          },
          {
            "id": "node_Constant_709",
            "label": "Constant",
            "namespace": "main_graph/: transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/arange_1: aten.arange.default",
            "subgraphIds": [],
            "attrs": [
              {
                "key": "__value",
                "value": "0"
              },
              {
                "key": "value",
                "value": "TensorProtoTensor<INT64,[]>(array(0), name='val_22')"
              }
            ],
            "incomingEdges": [],
            "outputsMetadata": [
              {
                "id": "0",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "val_22"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "INT64[]"
                  },
                  {
                    "key": "param_name",
                    "value": "output"
                  }
                ]
              }
            ],
            "inputsMetadata": [],
            "style": null,
            "config": null
          },
          {
            "id": "node_Constant_711",
            "label": "Constant",
            "namespace": "main_graph/: transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/arange_1: aten.arange.default",
            "subgraphIds": [],
            "attrs": [
              {
                "key": "__value",
                "value": "1"
              },
              {
                "key": "value",
                "value": "TensorProtoTensor<INT64,[]>(array(1), name='val_23')"
              }
            ],
            "incomingEdges": [],
            "outputsMetadata": [
              {
                "id": "0",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "val_23"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "INT64[]"
                  },
                  {
                    "key": "param_name",
                    "value": "output"
                  }
                ]
              }
            ],
            "inputsMetadata": [],
            "style": null,
            "config": null
          },
          {
            "id": "node_Range_52",
            "label": "Range",
            "namespace": "main_graph/: transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/arange_1: aten.arange.default",
            "subgraphIds": [],
            "attrs": [
              {
                "key": "[metadata] namespace",
                "value": ": transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/arange_1: aten.arange.default"
              },
              {
                "key": "[metadata] pkg.torch.onnx.class_hierarchy",
                "value": "['transformers.models.llama.modeling_llama.LlamaForCausalLM', 'transformers.models.llama.modeling_llama.LlamaModel', 'aten.arange.default']"
              },
              {
                "key": "[metadata] pkg.torch.onnx.fx_node",
                "value": "%arange_1 : [num_users=1] = call_function[target=torch.ops.aten.arange.default](args = (%add_4,), kwargs = {device: cuda:0, pin_memory: False})"
              },
              {
                "key": "[metadata] pkg.torch.onnx.name_scopes",
                "value": "['', 'model', 'arange_1']"
              },
              {
                "key": "[metadata] pkg.torch.onnx.stack_trace",
                "value": "File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 688, in forward\n    outputs: BaseModelOutputWithPast = self.model(\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 436, in forward\n    causal_mask = self._update_causal_mask("
              }
            ],
            "incomingEdges": [
              {
                "sourceNodeId": "node_Constant_709",
                "sourceNodeOutputId": "0",
                "targetNodeInputId": "0"
              },
              {
                "sourceNodeId": "node_Add_33",
                "sourceNodeOutputId": "0",
                "targetNodeInputId": "1"
              },
              {
                "sourceNodeId": "node_Constant_711",
                "sourceNodeOutputId": "0",
                "targetNodeInputId": "2"
              }
            ],
            "outputsMetadata": [
              {
                "id": "0",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "arange_1"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "INT64[s16 + s17]"
                  },
                  {
                    "key": "param_name",
                    "value": "output"
                  }
                ]
              }
            ],
            "inputsMetadata": [
              {
                "id": "0",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "val_22"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "INT64[]"
                  },
                  {
                    "key": "param_name",
                    "value": "start"
                  }
                ]
              },
              {
                "id": "1",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "add_4"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "INT64[]"
                  },
                  {
                    "key": "param_name",
                    "value": "limit"
                  }
                ]
              },
              {
                "id": "2",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "val_23"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "INT64[]"
                  },
                  {
                    "key": "param_name",
                    "value": "delta"
                  }
                ]
              }
            ],
            "style": null,
            "config": null
          },
          {
            "id": "node_Constant_713",
            "label": "Constant",
            "namespace": "main_graph/: transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/view: aten.view.default",
            "subgraphIds": [],
            "attrs": [
              {
                "key": "__value",
                "value": "[-1,1]"
              },
              {
                "key": "value",
                "value": "TensorProtoTensor<INT64,[2]>(array([-1,  1]), name='val_25')"
              }
            ],
            "incomingEdges": [],
            "outputsMetadata": [
              {
                "id": "0",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "val_25"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "INT64[2]"
                  },
                  {
                    "key": "param_name",
                    "value": "output"
                  }
                ]
              }
            ],
            "inputsMetadata": [],
            "style": null,
            "config": null
          },
          {
            "id": "node_Reshape_55",
            "label": "Reshape",
            "namespace": "main_graph/: transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/view: aten.view.default",
            "subgraphIds": [],
            "attrs": [
              {
                "key": "allowzero",
                "value": "1"
              },
              {
                "key": "[metadata] namespace",
                "value": ": transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/view: aten.view.default"
              },
              {
                "key": "[metadata] pkg.torch.onnx.class_hierarchy",
                "value": "['transformers.models.llama.modeling_llama.LlamaForCausalLM', 'transformers.models.llama.modeling_llama.LlamaModel', 'aten.view.default']"
              },
              {
                "key": "[metadata] pkg.torch.onnx.fx_node",
                "value": "%view : [num_users=1] = call_function[target=torch.ops.aten.view.default](args = (%arange, [-1, 1]), kwargs = {})"
              },
              {
                "key": "[metadata] pkg.torch.onnx.name_scopes",
                "value": "['', 'model', 'view']"
              },
              {
                "key": "[metadata] pkg.torch.onnx.stack_trace",
                "value": "File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 688, in forward\n    outputs: BaseModelOutputWithPast = self.model(\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 436, in forward\n    causal_mask = self._update_causal_mask("
              }
            ],
            "incomingEdges": [
              {
                "sourceNodeId": "node_Range_36",
                "sourceNodeOutputId": "0",
                "targetNodeInputId": "0"
              },
              {
                "sourceNodeId": "node_Constant_713",
                "sourceNodeOutputId": "0",
                "targetNodeInputId": "1"
              }
            ],
            "outputsMetadata": [
              {
                "id": "0",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "view"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "INT64[s16,1]"
                  },
                  {
                    "key": "param_name",
                    "value": "reshaped"
                  }
                ]
              }
            ],
            "inputsMetadata": [
              {
                "id": "0",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "arange"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "INT64[s16]"
                  },
                  {
                    "key": "param_name",
                    "value": "data"
                  }
                ]
              },
              {
                "id": "1",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "val_25"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "INT64[2]"
                  },
                  {
                    "key": "param_name",
                    "value": "shape"
                  }
                ]
              }
            ],
            "style": null,
            "config": null
          },
          {
            "id": "node_Greater_56",
            "label": "Greater",
            "namespace": "main_graph/: transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/gt: aten.gt.Tensor",
            "subgraphIds": [],
            "attrs": [
              {
                "key": "[metadata] namespace",
                "value": ": transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/gt: aten.gt.Tensor"
              },
              {
                "key": "[metadata] pkg.torch.onnx.class_hierarchy",
                "value": "['transformers.models.llama.modeling_llama.LlamaForCausalLM', 'transformers.models.llama.modeling_llama.LlamaModel', 'aten.gt.Tensor']"
              },
              {
                "key": "[metadata] pkg.torch.onnx.fx_node",
                "value": "%gt : [num_users=1] = call_function[target=torch.ops.aten.gt.Tensor](args = (%arange_1, %view), kwargs = {})"
              },
              {
                "key": "[metadata] pkg.torch.onnx.name_scopes",
                "value": "['', 'model', 'gt']"
              },
              {
                "key": "[metadata] pkg.torch.onnx.stack_trace",
                "value": "File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 688, in forward\n    outputs: BaseModelOutputWithPast = self.model(\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 436, in forward\n    causal_mask = self._update_causal_mask("
              }
            ],
            "incomingEdges": [
              {
                "sourceNodeId": "node_Range_52",
                "sourceNodeOutputId": "0",
                "targetNodeInputId": "0"
              },
              {
                "sourceNodeId": "node_Reshape_55",
                "sourceNodeOutputId": "0",
                "targetNodeInputId": "1"
              }
            ],
            "outputsMetadata": [
              {
                "id": "0",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "gt"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "BOOL[s16,s16 + s17]"
                  },
                  {
                    "key": "param_name",
                    "value": "C"
                  }
                ]
              }
            ],
            "inputsMetadata": [
              {
                "id": "0",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "arange_1"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "INT64[s16 + s17]"
                  },
                  {
                    "key": "param_name",
                    "value": "A"
                  }
                ]
              },
              {
                "id": "1",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "view"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "INT64[s16,1]"
                  },
                  {
                    "key": "param_name",
                    "value": "B"
                  }
                ]
              }
            ],
            "style": null,
            "config": null
          },
          {
            "id": "node_Cast_57",
            "label": "Cast",
            "namespace": "main_graph/: transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/convert_element_type_default: prims.convert_element_type.default",
            "subgraphIds": [],
            "attrs": [
              {
                "key": "to",
                "value": "FLOAT"
              },
              {
                "key": "[metadata] namespace",
                "value": ": transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/convert_element_type_default: prims.convert_element_type.default"
              },
              {
                "key": "[metadata] pkg.torch.onnx.class_hierarchy",
                "value": "['transformers.models.llama.modeling_llama.LlamaForCausalLM', 'transformers.models.llama.modeling_llama.LlamaModel', 'prims.convert_element_type.default']"
              },
              {
                "key": "[metadata] pkg.torch.onnx.fx_node",
                "value": "%convert_element_type_default : [num_users=1] = call_function[target=torch.ops.prims.convert_element_type.default](args = (%gt,), kwargs = {dtype: torch.float32})"
              },
              {
                "key": "[metadata] pkg.torch.onnx.name_scopes",
                "value": "['', 'model', 'convert_element_type_default']"
              },
              {
                "key": "[metadata] pkg.torch.onnx.stack_trace",
                "value": "File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 688, in forward\n    outputs: BaseModelOutputWithPast = self.model(\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 436, in forward\n    causal_mask = self._update_causal_mask("
              }
            ],
            "incomingEdges": [
              {
                "sourceNodeId": "node_Greater_56",
                "sourceNodeOutputId": "0",
                "targetNodeInputId": "0"
              }
            ],
            "outputsMetadata": [
              {
                "id": "0",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "convert_element_type_default"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "FLOAT[s16,s16 + s17]"
                  },
                  {
                    "key": "param_name",
                    "value": "output"
                  }
                ]
              }
            ],
            "inputsMetadata": [
              {
                "id": "0",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "gt"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "BOOL[s16,s16 + s17]"
                  },
                  {
                    "key": "param_name",
                    "value": "input"
                  }
                ]
              }
            ],
            "style": null,
            "config": null
          },
          {
            "id": "node_Mul_58",
            "label": "Mul",
            "namespace": "main_graph/: transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/mul_16: aten.mul.Tensor",
            "subgraphIds": [],
            "attrs": [
              {
                "key": "[metadata] namespace",
                "value": ": transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/mul_16: aten.mul.Tensor"
              },
              {
                "key": "[metadata] pkg.torch.onnx.class_hierarchy",
                "value": "['transformers.models.llama.modeling_llama.LlamaForCausalLM', 'transformers.models.llama.modeling_llama.LlamaModel', 'aten.mul.Tensor']"
              },
              {
                "key": "[metadata] pkg.torch.onnx.fx_node",
                "value": "%mul_16 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%triu, %convert_element_type_default), kwargs = {})"
              },
              {
                "key": "[metadata] pkg.torch.onnx.name_scopes",
                "value": "['', 'model', 'mul_16']"
              },
              {
                "key": "[metadata] pkg.torch.onnx.stack_trace",
                "value": "File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 688, in forward\n    outputs: BaseModelOutputWithPast = self.model(\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 436, in forward\n    causal_mask = self._update_causal_mask("
              }
            ],
            "incomingEdges": [
              {
                "sourceNodeId": "n1",
                "sourceNodeOutputId": "0",
                "targetNodeInputId": "0"
              },
              {
                "sourceNodeId": "node_Cast_57",
                "sourceNodeOutputId": "0",
                "targetNodeInputId": "1"
              }
            ],
            "outputsMetadata": [
              {
                "id": "0",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "mul_16"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "FLOAT[s16,s16 + s17]"
                  },
                  {
                    "key": "param_name",
                    "value": "C"
                  }
                ]
              }
            ],
            "inputsMetadata": [
              {
                "id": "0",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "triu"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "FLOAT[s16,s16 + s17]"
                  },
                  {
                    "key": "param_name",
                    "value": "A"
                  }
                ]
              },
              {
                "id": "1",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "convert_element_type_default"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "FLOAT[s16,s16 + s17]"
                  },
                  {
                    "key": "param_name",
                    "value": "B"
                  }
                ]
              }
            ],
            "style": null,
            "config": null
          },
          {
            "id": "node_Constant_60",
            "label": "Constant",
            "namespace": "main_graph/: transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/expand_1: aten.expand.default",
            "subgraphIds": [],
            "attrs": [
              {
                "key": "__value",
                "value": "[1]"
              },
              {
                "key": "value",
                "value": "TensorProtoTensor<INT64,[1]>(array([1]), name='')"
              },
              {
                "key": "[metadata] namespace",
                "value": ": transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/unsqueeze_4: aten.unsqueeze.default"
              },
              {
                "key": "[metadata] pkg.torch.onnx.class_hierarchy",
                "value": "['transformers.models.llama.modeling_llama.LlamaForCausalLM', 'transformers.models.llama.modeling_llama.LlamaModel', 'aten.unsqueeze.default']"
              },
              {
                "key": "[metadata] pkg.torch.onnx.fx_node",
                "value": "%unsqueeze_4 : [num_users=1] = call_function[target=torch.ops.aten.unsqueeze.default](args = (%unsqueeze_3, 1), kwargs = {})"
              },
              {
                "key": "[metadata] pkg.torch.onnx.name_scopes",
                "value": "['', 'model', 'unsqueeze_4']"
              },
              {
                "key": "[metadata] pkg.torch.onnx.stack_trace",
                "value": "File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 688, in forward\n    outputs: BaseModelOutputWithPast = self.model(\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 436, in forward\n    causal_mask = self._update_causal_mask("
              }
            ],
            "incomingEdges": [],
            "outputsMetadata": [
              {
                "id": "0",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "val_26"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "INT64[1]"
                  },
                  {
                    "key": "param_name",
                    "value": "output"
                  }
                ]
              }
            ],
            "inputsMetadata": [],
            "style": null,
            "config": null
          },
          {
            "id": "node_Constant_1026",
            "label": "Constant",
            "namespace": "main_graph",
            "subgraphIds": [],
            "attrs": [
              {
                "key": "__value",
                "value": "[0,1]"
              },
              {
                "key": "value",
                "value": "TensorProtoTensor<INT64,[2]>(array([0, 1]), name='val_491')"
              }
            ],
            "incomingEdges": [],
            "outputsMetadata": [
              {
                "id": "0",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "val_491"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "INT64[2]"
                  },
                  {
                    "key": "param_name",
                    "value": "output"
                  }
                ]
              }
            ],
            "inputsMetadata": [],
            "style": null,
            "config": null
          },
          {
            "id": "node_Unsqueeze_1027",
            "label": "Unsqueeze",
            "namespace": "main_graph",
            "subgraphIds": [],
            "attrs": [],
            "incomingEdges": [
              {
                "sourceNodeId": "node_Mul_58",
                "sourceNodeOutputId": "0",
                "targetNodeInputId": "0"
              },
              {
                "sourceNodeId": "node_Constant_1026",
                "sourceNodeOutputId": "0",
                "targetNodeInputId": "1"
              }
            ],
            "outputsMetadata": [
              {
                "id": "0",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "unsqueeze_4"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "FLOAT[1,1,s16,s16 + s17]"
                  },
                  {
                    "key": "param_name",
                    "value": "expanded"
                  }
                ]
              }
            ],
            "inputsMetadata": [
              {
                "id": "0",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "mul_16"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "FLOAT[s16,s16 + s17]"
                  },
                  {
                    "key": "param_name",
                    "value": "data"
                  }
                ]
              },
              {
                "id": "1",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "val_491"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "INT64[2]"
                  },
                  {
                    "key": "param_name",
                    "value": "axes"
                  }
                ]
              }
            ],
            "style": null,
            "config": null
          },
          {
            "id": "node_Constant_62",
            "label": "Constant",
            "namespace": "main_graph/: transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel",
            "subgraphIds": [],
            "attrs": [
              {
                "key": "__value",
                "value": "0"
              },
              {
                "key": "value",
                "value": "TensorProtoTensor<INT64,[]>(array(0), name='')"
              },
              {
                "key": "[metadata] namespace",
                "value": ": transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/slice_3: aten.slice.Tensor"
              },
              {
                "key": "[metadata] pkg.torch.onnx.class_hierarchy",
                "value": "['transformers.models.llama.modeling_llama.LlamaForCausalLM', 'transformers.models.llama.modeling_llama.LlamaModel', 'aten.slice.Tensor']"
              },
              {
                "key": "[metadata] pkg.torch.onnx.fx_node",
                "value": "%slice_3 : [num_users=1] = call_function[target=torch.ops.aten.slice.Tensor](args = (%unsqueeze_4, 2, 0, 9223372036854775807), kwargs = {})"
              },
              {
                "key": "[metadata] pkg.torch.onnx.name_scopes",
                "value": "['', 'model', 'slice_3']"
              },
              {
                "key": "[metadata] pkg.torch.onnx.stack_trace",
                "value": "File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 688, in forward\n    outputs: BaseModelOutputWithPast = self.model(\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 436, in forward\n    causal_mask = self._update_causal_mask("
              }
            ],
            "incomingEdges": [],
            "outputsMetadata": [
              {
                "id": "0",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "val_27"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "INT64[]"
                  },
                  {
                    "key": "param_name",
                    "value": "output"
                  }
                ]
              }
            ],
            "inputsMetadata": [],
            "style": null,
            "config": null
          },
          {
            "id": "node_Constant_70",
            "label": "Constant",
            "namespace": "main_graph/: transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/slice_scatter: aten.slice_scatter.default",
            "subgraphIds": [],
            "attrs": [
              {
                "key": "__value",
                "value": "2"
              },
              {
                "key": "value",
                "value": "TensorProtoTensor<INT64,[]>(array(2), name='')"
              },
              {
                "key": "[metadata] namespace",
                "value": ": transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/slice_3: aten.slice.Tensor"
              },
              {
                "key": "[metadata] pkg.torch.onnx.class_hierarchy",
                "value": "['transformers.models.llama.modeling_llama.LlamaForCausalLM', 'transformers.models.llama.modeling_llama.LlamaModel', 'aten.slice.Tensor']"
              },
              {
                "key": "[metadata] pkg.torch.onnx.fx_node",
                "value": "%slice_3 : [num_users=1] = call_function[target=torch.ops.aten.slice.Tensor](args = (%unsqueeze_4, 2, 0, 9223372036854775807), kwargs = {})"
              },
              {
                "key": "[metadata] pkg.torch.onnx.name_scopes",
                "value": "['', 'model', 'slice_3']"
              },
              {
                "key": "[metadata] pkg.torch.onnx.stack_trace",
                "value": "File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 688, in forward\n    outputs: BaseModelOutputWithPast = self.model(\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 436, in forward\n    causal_mask = self._update_causal_mask("
              }
            ],
            "incomingEdges": [],
            "outputsMetadata": [
              {
                "id": "0",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "val_35"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "INT64[]"
                  },
                  {
                    "key": "param_name",
                    "value": "output"
                  }
                ]
              }
            ],
            "inputsMetadata": [],
            "style": null,
            "config": null
          },
          {
            "id": "node_Constant_90",
            "label": "Constant",
            "namespace": "main_graph/: transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel",
            "subgraphIds": [],
            "attrs": [
              {
                "key": "__value",
                "value": "[-1]"
              },
              {
                "key": "value",
                "value": "TensorProtoTensor<INT64,[1]>(array([-1]), name='')"
              },
              {
                "key": "[metadata] namespace",
                "value": ": transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/expand_1: aten.expand.default"
              },
              {
                "key": "[metadata] pkg.torch.onnx.class_hierarchy",
                "value": "['transformers.models.llama.modeling_llama.LlamaForCausalLM', 'transformers.models.llama.modeling_llama.LlamaModel', 'aten.expand.default']"
              },
              {
                "key": "[metadata] pkg.torch.onnx.fx_node",
                "value": "%expand_1 : [num_users=1] = call_function[target=torch.ops.aten.expand.default](args = (%slice_4, [%sym_size_int_68, 1, -1, -1]), kwargs = {})"
              },
              {
                "key": "[metadata] pkg.torch.onnx.name_scopes",
                "value": "['', 'model', 'expand_1']"
              },
              {
                "key": "[metadata] pkg.torch.onnx.stack_trace",
                "value": "File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 688, in forward\n    outputs: BaseModelOutputWithPast = self.model(\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 436, in forward\n    causal_mask = self._update_causal_mask("
              }
            ],
            "incomingEdges": [],
            "outputsMetadata": [
              {
                "id": "0",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "val_53"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "INT64[1]"
                  },
                  {
                    "key": "param_name",
                    "value": "output"
                  }
                ]
              }
            ],
            "inputsMetadata": [],
            "style": null,
            "config": null
          },
          {
            "id": "node_Concat_91",
            "label": "Concat",
            "namespace": "main_graph/: transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/expand_1: aten.expand.default",
            "subgraphIds": [],
            "attrs": [
              {
                "key": "axis",
                "value": "0"
              },
              {
                "key": "[metadata] namespace",
                "value": ": transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/expand_1: aten.expand.default"
              },
              {
                "key": "[metadata] pkg.torch.onnx.class_hierarchy",
                "value": "['transformers.models.llama.modeling_llama.LlamaForCausalLM', 'transformers.models.llama.modeling_llama.LlamaModel', 'aten.expand.default']"
              },
              {
                "key": "[metadata] pkg.torch.onnx.fx_node",
                "value": "%expand_1 : [num_users=1] = call_function[target=torch.ops.aten.expand.default](args = (%slice_4, [%sym_size_int_68, 1, -1, -1]), kwargs = {})"
              },
              {
                "key": "[metadata] pkg.torch.onnx.name_scopes",
                "value": "['', 'model', 'expand_1']"
              },
              {
                "key": "[metadata] pkg.torch.onnx.stack_trace",
                "value": "File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 688, in forward\n    outputs: BaseModelOutputWithPast = self.model(\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 436, in forward\n    causal_mask = self._update_causal_mask("
              }
            ],
            "incomingEdges": [
              {
                "sourceNodeId": "node_Shape_12",
                "sourceNodeOutputId": "0",
                "targetNodeInputId": "0"
              },
              {
                "sourceNodeId": "node_Constant_60",
                "sourceNodeOutputId": "0",
                "targetNodeInputId": "1"
              },
              {
                "sourceNodeId": "node_Constant_90",
                "sourceNodeOutputId": "0",
                "targetNodeInputId": "2"
              },
              {
                "sourceNodeId": "node_Constant_90",
                "sourceNodeOutputId": "0",
                "targetNodeInputId": "3"
              }
            ],
            "outputsMetadata": [
              {
                "id": "0",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "val_54"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "INT64[4]"
                  },
                  {
                    "key": "param_name",
                    "value": "concat_result"
                  }
                ]
              }
            ],
            "inputsMetadata": [
              {
                "id": "0",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "val_6"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "INT64[1]"
                  },
                  {
                    "key": "param_name",
                    "value": "inputs"
                  }
                ]
              },
              {
                "id": "1",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "val_26"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "INT64[1]"
                  },
                  {
                    "key": "param_name",
                    "value": "inputs"
                  }
                ]
              },
              {
                "id": "2",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "val_53"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "INT64[1]"
                  },
                  {
                    "key": "param_name",
                    "value": "inputs"
                  }
                ]
              },
              {
                "id": "3",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "val_53"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "INT64[1]"
                  },
                  {
                    "key": "param_name",
                    "value": "inputs"
                  }
                ]
              }
            ],
            "style": null,
            "config": null
          },
          {
            "id": "node_Abs_93",
            "label": "Abs",
            "namespace": "main_graph/: transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/expand_1: aten.expand.default",
            "subgraphIds": [],
            "attrs": [
              {
                "key": "[metadata] namespace",
                "value": ": transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/expand_1: aten.expand.default"
              },
              {
                "key": "[metadata] pkg.torch.onnx.class_hierarchy",
                "value": "['transformers.models.llama.modeling_llama.LlamaForCausalLM', 'transformers.models.llama.modeling_llama.LlamaModel', 'aten.expand.default']"
              },
              {
                "key": "[metadata] pkg.torch.onnx.fx_node",
                "value": "%expand_1 : [num_users=1] = call_function[target=torch.ops.aten.expand.default](args = (%slice_4, [%sym_size_int_68, 1, -1, -1]), kwargs = {})"
              },
              {
                "key": "[metadata] pkg.torch.onnx.name_scopes",
                "value": "['', 'model', 'expand_1']"
              },
              {
                "key": "[metadata] pkg.torch.onnx.stack_trace",
                "value": "File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 688, in forward\n    outputs: BaseModelOutputWithPast = self.model(\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 436, in forward\n    causal_mask = self._update_causal_mask("
              }
            ],
            "incomingEdges": [
              {
                "sourceNodeId": "node_Concat_91",
                "sourceNodeOutputId": "0",
                "targetNodeInputId": "0"
              }
            ],
            "outputsMetadata": [
              {
                "id": "0",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "val_56"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "INT64[4]"
                  },
                  {
                    "key": "param_name",
                    "value": "Y"
                  }
                ]
              }
            ],
            "inputsMetadata": [
              {
                "id": "0",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "val_54"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "INT64[4]"
                  },
                  {
                    "key": "param_name",
                    "value": "X"
                  }
                ]
              }
            ],
            "style": null,
            "config": null
          },
          {
            "id": "node_Expand_94",
            "label": "Expand",
            "namespace": "main_graph/: transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/expand_1: aten.expand.default",
            "subgraphIds": [],
            "attrs": [
              {
                "key": "[metadata] namespace",
                "value": ": transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/expand_1: aten.expand.default"
              },
              {
                "key": "[metadata] pkg.torch.onnx.class_hierarchy",
                "value": "['transformers.models.llama.modeling_llama.LlamaForCausalLM', 'transformers.models.llama.modeling_llama.LlamaModel', 'aten.expand.default']"
              },
              {
                "key": "[metadata] pkg.torch.onnx.fx_node",
                "value": "%expand_1 : [num_users=1] = call_function[target=torch.ops.aten.expand.default](args = (%slice_4, [%sym_size_int_68, 1, -1, -1]), kwargs = {})"
              },
              {
                "key": "[metadata] pkg.torch.onnx.name_scopes",
                "value": "['', 'model', 'expand_1']"
              },
              {
                "key": "[metadata] pkg.torch.onnx.stack_trace",
                "value": "File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 688, in forward\n    outputs: BaseModelOutputWithPast = self.model(\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 436, in forward\n    causal_mask = self._update_causal_mask("
              }
            ],
            "incomingEdges": [
              {
                "sourceNodeId": "node_Unsqueeze_1027",
                "sourceNodeOutputId": "0",
                "targetNodeInputId": "0"
              },
              {
                "sourceNodeId": "node_Abs_93",
                "sourceNodeOutputId": "0",
                "targetNodeInputId": "1"
              }
            ],
            "outputsMetadata": [
              {
                "id": "0",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "expand_1"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "FLOAT[s34,1,s16,s16 + s17]"
                  },
                  {
                    "key": "param_name",
                    "value": "output"
                  }
                ]
              }
            ],
            "inputsMetadata": [
              {
                "id": "0",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "unsqueeze_4"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "FLOAT[1,1,s16,s16 + s17]"
                  },
                  {
                    "key": "param_name",
                    "value": "input"
                  }
                ]
              },
              {
                "id": "1",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "val_56"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "INT64[4]"
                  },
                  {
                    "key": "param_name",
                    "value": "shape"
                  }
                ]
              }
            ],
            "style": null,
            "config": null
          },
          {
            "id": "node_Constant_105",
            "label": "Constant",
            "namespace": "main_graph/: transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel",
            "subgraphIds": [],
            "attrs": [
              {
                "key": "__value",
                "value": "1"
              },
              {
                "key": "value",
                "value": "TensorProtoTensor<INT64,[]>(array(1), name='')"
              },
              {
                "key": "[metadata] namespace",
                "value": ": transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/slice_6: aten.slice.Tensor"
              },
              {
                "key": "[metadata] pkg.torch.onnx.class_hierarchy",
                "value": "['transformers.models.llama.modeling_llama.LlamaForCausalLM', 'transformers.models.llama.modeling_llama.LlamaModel', 'aten.slice.Tensor']"
              },
              {
                "key": "[metadata] pkg.torch.onnx.fx_node",
                "value": "%slice_6 : [num_users=1] = call_function[target=torch.ops.aten.slice.Tensor](args = (%slice_5, 1), kwargs = {})"
              },
              {
                "key": "[metadata] pkg.torch.onnx.name_scopes",
                "value": "['', 'model', 'slice_6']"
              },
              {
                "key": "[metadata] pkg.torch.onnx.stack_trace",
                "value": "File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 688, in forward\n    outputs: BaseModelOutputWithPast = self.model(\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 436, in forward\n    causal_mask = self._update_causal_mask("
              }
            ],
            "incomingEdges": [],
            "outputsMetadata": [
              {
                "id": "0",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "val_65"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "INT64[]"
                  },
                  {
                    "key": "param_name",
                    "value": "output"
                  }
                ]
              }
            ],
            "inputsMetadata": [],
            "style": null,
            "config": null
          },
          {
            "id": "node_Constant_118",
            "label": "Constant",
            "namespace": "main_graph",
            "subgraphIds": [],
            "attrs": [
              {
                "key": "__value",
                "value": "[0]"
              },
              {
                "key": "value_ints",
                "value": "[0]"
              },
              {
                "key": "[metadata] namespace",
                "value": ": transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/slice_8: aten.slice.Tensor"
              },
              {
                "key": "[metadata] pkg.torch.onnx.class_hierarchy",
                "value": "['transformers.models.llama.modeling_llama.LlamaForCausalLM', 'transformers.models.llama.modeling_llama.LlamaModel', 'aten.slice.Tensor']"
              },
              {
                "key": "[metadata] pkg.torch.onnx.fx_node",
                "value": "%slice_8 : [num_users=1] = call_function[target=torch.ops.aten.slice.Tensor](args = (%slice_7, 3, None, %add_4), kwargs = {})"
              },
              {
                "key": "[metadata] pkg.torch.onnx.name_scopes",
                "value": "['', 'model', 'slice_8']"
              },
              {
                "key": "[metadata] pkg.torch.onnx.stack_trace",
                "value": "File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 688, in forward\n    outputs: BaseModelOutputWithPast = self.model(\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 436, in forward\n    causal_mask = self._update_causal_mask("
              }
            ],
            "incomingEdges": [],
            "outputsMetadata": [
              {
                "id": "0",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "val_76"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "INT64[1]"
                  },
                  {
                    "key": "param_name",
                    "value": "output"
                  }
                ]
              }
            ],
            "inputsMetadata": [],
            "style": null,
            "config": null
          },
          {
            "id": "node_Constant_120",
            "label": "Constant",
            "namespace": "main_graph/: transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/slice_8: aten.slice.Tensor",
            "subgraphIds": [],
            "attrs": [
              {
                "key": "__value",
                "value": "[-1]"
              },
              {
                "key": "value_ints",
                "value": "[-1]"
              },
              {
                "key": "[metadata] namespace",
                "value": ": transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/slice_8: aten.slice.Tensor"
              },
              {
                "key": "[metadata] pkg.torch.onnx.class_hierarchy",
                "value": "['transformers.models.llama.modeling_llama.LlamaForCausalLM', 'transformers.models.llama.modeling_llama.LlamaModel', 'aten.slice.Tensor']"
              },
              {
                "key": "[metadata] pkg.torch.onnx.fx_node",
                "value": "%slice_8 : [num_users=1] = call_function[target=torch.ops.aten.slice.Tensor](args = (%slice_7, 3, None, %add_4), kwargs = {})"
              },
              {
                "key": "[metadata] pkg.torch.onnx.name_scopes",
                "value": "['', 'model', 'slice_8']"
              },
              {
                "key": "[metadata] pkg.torch.onnx.stack_trace",
                "value": "File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 688, in forward\n    outputs: BaseModelOutputWithPast = self.model(\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 436, in forward\n    causal_mask = self._update_causal_mask("
              }
            ],
            "incomingEdges": [],
            "outputsMetadata": [
              {
                "id": "0",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "val_78"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "INT64[1]"
                  },
                  {
                    "key": "param_name",
                    "value": "output"
                  }
                ]
              }
            ],
            "inputsMetadata": [],
            "style": null,
            "config": null
          },
          {
            "id": "node_Reshape_121",
            "label": "Reshape",
            "namespace": "main_graph/: transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/slice_8: aten.slice.Tensor",
            "subgraphIds": [],
            "attrs": [
              {
                "key": "allowzero",
                "value": "0"
              },
              {
                "key": "[metadata] namespace",
                "value": ": transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/slice_8: aten.slice.Tensor"
              },
              {
                "key": "[metadata] pkg.torch.onnx.class_hierarchy",
                "value": "['transformers.models.llama.modeling_llama.LlamaForCausalLM', 'transformers.models.llama.modeling_llama.LlamaModel', 'aten.slice.Tensor']"
              },
              {
                "key": "[metadata] pkg.torch.onnx.fx_node",
                "value": "%slice_8 : [num_users=1] = call_function[target=torch.ops.aten.slice.Tensor](args = (%slice_7, 3, None, %add_4), kwargs = {})"
              },
              {
                "key": "[metadata] pkg.torch.onnx.name_scopes",
                "value": "['', 'model', 'slice_8']"
              },
              {
                "key": "[metadata] pkg.torch.onnx.stack_trace",
                "value": "File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 688, in forward\n    outputs: BaseModelOutputWithPast = self.model(\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 436, in forward\n    causal_mask = self._update_causal_mask("
              }
            ],
            "incomingEdges": [
              {
                "sourceNodeId": "node_Add_33",
                "sourceNodeOutputId": "0",
                "targetNodeInputId": "0"
              },
              {
                "sourceNodeId": "node_Constant_120",
                "sourceNodeOutputId": "0",
                "targetNodeInputId": "1"
              }
            ],
            "outputsMetadata": [
              {
                "id": "0",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "val_79"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "INT64[1]"
                  },
                  {
                    "key": "param_name",
                    "value": "reshaped"
                  }
                ]
              }
            ],
            "inputsMetadata": [
              {
                "id": "0",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "add_4"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "INT64[]"
                  },
                  {
                    "key": "param_name",
                    "value": "data"
                  }
                ]
              },
              {
                "id": "1",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "val_78"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "INT64[1]"
                  },
                  {
                    "key": "param_name",
                    "value": "shape"
                  }
                ]
              }
            ],
            "style": null,
            "config": null
          },
          {
            "id": "node_Constant_745",
            "label": "Constant",
            "namespace": "main_graph/: transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/slice_8: aten.slice.Tensor",
            "subgraphIds": [],
            "attrs": [
              {
                "key": "__value",
                "value": "[3]"
              },
              {
                "key": "value",
                "value": "TensorProtoTensor<INT64,[1]>(array([3]), name='val_82')"
              }
            ],
            "incomingEdges": [],
            "outputsMetadata": [
              {
                "id": "0",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "val_82"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "INT64[1]"
                  },
                  {
                    "key": "param_name",
                    "value": "output"
                  }
                ]
              }
            ],
            "inputsMetadata": [],
            "style": null,
            "config": null
          },
          {
            "id": "node_Constant_125",
            "label": "Constant",
            "namespace": "main_graph/: transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel",
            "subgraphIds": [],
            "attrs": [
              {
                "key": "__value",
                "value": "[1]"
              },
              {
                "key": "value_ints",
                "value": "[1]"
              },
              {
                "key": "[metadata] namespace",
                "value": ": transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/slice_8: aten.slice.Tensor"
              },
              {
                "key": "[metadata] pkg.torch.onnx.class_hierarchy",
                "value": "['transformers.models.llama.modeling_llama.LlamaForCausalLM', 'transformers.models.llama.modeling_llama.LlamaModel', 'aten.slice.Tensor']"
              },
              {
                "key": "[metadata] pkg.torch.onnx.fx_node",
                "value": "%slice_8 : [num_users=1] = call_function[target=torch.ops.aten.slice.Tensor](args = (%slice_7, 3, None, %add_4), kwargs = {})"
              },
              {
                "key": "[metadata] pkg.torch.onnx.name_scopes",
                "value": "['', 'model', 'slice_8']"
              },
              {
                "key": "[metadata] pkg.torch.onnx.stack_trace",
                "value": "File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 688, in forward\n    outputs: BaseModelOutputWithPast = self.model(\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 436, in forward\n    causal_mask = self._update_causal_mask("
              }
            ],
            "incomingEdges": [],
            "outputsMetadata": [
              {
                "id": "0",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "val_83"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "INT64[1]"
                  },
                  {
                    "key": "param_name",
                    "value": "output"
                  }
                ]
              }
            ],
            "inputsMetadata": [],
            "style": null,
            "config": null
          },
          {
            "id": "node_Slice_126",
            "label": "Slice",
            "namespace": "main_graph/: transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/slice_8: aten.slice.Tensor",
            "subgraphIds": [],
            "attrs": [
              {
                "key": "[metadata] namespace",
                "value": ": transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/slice_8: aten.slice.Tensor"
              },
              {
                "key": "[metadata] pkg.torch.onnx.class_hierarchy",
                "value": "['transformers.models.llama.modeling_llama.LlamaForCausalLM', 'transformers.models.llama.modeling_llama.LlamaModel', 'aten.slice.Tensor']"
              },
              {
                "key": "[metadata] pkg.torch.onnx.fx_node",
                "value": "%slice_8 : [num_users=1] = call_function[target=torch.ops.aten.slice.Tensor](args = (%slice_7, 3, None, %add_4), kwargs = {})"
              },
              {
                "key": "[metadata] pkg.torch.onnx.name_scopes",
                "value": "['', 'model', 'slice_8']"
              },
              {
                "key": "[metadata] pkg.torch.onnx.stack_trace",
                "value": "File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 688, in forward\n    outputs: BaseModelOutputWithPast = self.model(\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 436, in forward\n    causal_mask = self._update_causal_mask("
              }
            ],
            "incomingEdges": [
              {
                "sourceNodeId": "node_Expand_94",
                "sourceNodeOutputId": "0",
                "targetNodeInputId": "0"
              },
              {
                "sourceNodeId": "node_Constant_118",
                "sourceNodeOutputId": "0",
                "targetNodeInputId": "1"
              },
              {
                "sourceNodeId": "node_Reshape_121",
                "sourceNodeOutputId": "0",
                "targetNodeInputId": "2"
              },
              {
                "sourceNodeId": "node_Constant_745",
                "sourceNodeOutputId": "0",
                "targetNodeInputId": "3"
              },
              {
                "sourceNodeId": "node_Constant_125",
                "sourceNodeOutputId": "0",
                "targetNodeInputId": "4"
              }
            ],
            "outputsMetadata": [
              {
                "id": "0",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "slice_8"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "FLOAT[s34,1,s16,s16 + s17]"
                  },
                  {
                    "key": "param_name",
                    "value": "output"
                  }
                ]
              }
            ],
            "inputsMetadata": [
              {
                "id": "0",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "expand_1"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "FLOAT[s34,1,s16,s16 + s17]"
                  },
                  {
                    "key": "param_name",
                    "value": "data"
                  }
                ]
              },
              {
                "id": "1",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "val_76"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "INT64[1]"
                  },
                  {
                    "key": "param_name",
                    "value": "starts"
                  }
                ]
              },
              {
                "id": "2",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "val_79"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "INT64[1]"
                  },
                  {
                    "key": "param_name",
                    "value": "ends"
                  }
                ]
              },
              {
                "id": "3",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "val_82"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "INT64[1]"
                  },
                  {
                    "key": "param_name",
                    "value": "axes"
                  }
                ]
              },
              {
                "id": "4",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "val_83"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "INT64[1]"
                  },
                  {
                    "key": "param_name",
                    "value": "steps"
                  }
                ]
              }
            ],
            "style": null,
            "config": null
          },
          {
            "id": "node_Constant_1028",
            "label": "Constant",
            "namespace": "main_graph",
            "subgraphIds": [],
            "attrs": [
              {
                "key": "__value",
                "value": "[1,2]"
              },
              {
                "key": "value",
                "value": "TensorProtoTensor<INT64,[2]>(array([1, 2]), name='val_492')"
              }
            ],
            "incomingEdges": [],
            "outputsMetadata": [
              {
                "id": "0",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "val_492"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "INT64[2]"
                  },
                  {
                    "key": "param_name",
                    "value": "output"
                  }
                ]
              }
            ],
            "inputsMetadata": [],
            "style": null,
            "config": null
          },
          {
            "id": "node_Unsqueeze_1029",
            "label": "Unsqueeze",
            "namespace": "main_graph",
            "subgraphIds": [],
            "attrs": [],
            "incomingEdges": [
              {
                "sourceNodeId": "[value] attention_mask",
                "sourceNodeOutputId": "0",
                "targetNodeInputId": "0"
              },
              {
                "sourceNodeId": "node_Constant_1028",
                "sourceNodeOutputId": "0",
                "targetNodeInputId": "1"
              }
            ],
            "outputsMetadata": [
              {
                "id": "0",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "unsqueeze_6"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "INT64[s34,1,1,s16 + s17]"
                  },
                  {
                    "key": "param_name",
                    "value": "expanded"
                  }
                ]
              }
            ],
            "inputsMetadata": [
              {
                "id": "0",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "attention_mask"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "INT64[s34,s16 + s17]"
                  },
                  {
                    "key": "[metadata] pkg.torch.export.graph_signature.InputSpec.kind",
                    "value": "USER_INPUT"
                  },
                  {
                    "key": "[metadata] pkg.torch.export.graph_signature.InputSpec.persistent",
                    "value": "None"
                  },
                  {
                    "key": "param_name",
                    "value": "data"
                  }
                ]
              },
              {
                "id": "1",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "val_492"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "INT64[2]"
                  },
                  {
                    "key": "param_name",
                    "value": "axes"
                  }
                ]
              }
            ],
            "style": null,
            "config": null
          },
          {
            "id": "node_Cast_152",
            "label": "Cast",
            "namespace": "main_graph/: transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/convert_element_type_default_1: prims.convert_element_type.default",
            "subgraphIds": [],
            "attrs": [
              {
                "key": "to",
                "value": "FLOAT"
              },
              {
                "key": "[metadata] namespace",
                "value": ": transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/convert_element_type_default_1: prims.convert_element_type.default"
              },
              {
                "key": "[metadata] pkg.torch.onnx.class_hierarchy",
                "value": "['transformers.models.llama.modeling_llama.LlamaForCausalLM', 'transformers.models.llama.modeling_llama.LlamaModel', 'prims.convert_element_type.default']"
              },
              {
                "key": "[metadata] pkg.torch.onnx.fx_node",
                "value": "%convert_element_type_default_1 : [num_users=1] = call_function[target=torch.ops.prims.convert_element_type.default](args = (%slice_10,), kwargs = {dtype: torch.float32})"
              },
              {
                "key": "[metadata] pkg.torch.onnx.name_scopes",
                "value": "['', 'model', 'convert_element_type_default_1']"
              },
              {
                "key": "[metadata] pkg.torch.onnx.stack_trace",
                "value": "File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 688, in forward\n    outputs: BaseModelOutputWithPast = self.model(\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 436, in forward\n    causal_mask = self._update_causal_mask("
              }
            ],
            "incomingEdges": [
              {
                "sourceNodeId": "node_Unsqueeze_1029",
                "sourceNodeOutputId": "0",
                "targetNodeInputId": "0"
              }
            ],
            "outputsMetadata": [
              {
                "id": "0",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "convert_element_type_default_1"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "FLOAT[s34,1,1,s16 + s17]"
                  },
                  {
                    "key": "param_name",
                    "value": "output"
                  }
                ]
              }
            ],
            "inputsMetadata": [
              {
                "id": "0",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "unsqueeze_6"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "INT64[s34,1,1,s16 + s17]"
                  },
                  {
                    "key": "param_name",
                    "value": "input"
                  }
                ]
              }
            ],
            "style": null,
            "config": null
          },
          {
            "id": "node_Add_153",
            "label": "Add",
            "namespace": "main_graph/: transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/add_89: aten.add.Tensor",
            "subgraphIds": [],
            "attrs": [
              {
                "key": "[metadata] namespace",
                "value": ": transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/add_89: aten.add.Tensor"
              },
              {
                "key": "[metadata] pkg.torch.onnx.class_hierarchy",
                "value": "['transformers.models.llama.modeling_llama.LlamaForCausalLM', 'transformers.models.llama.modeling_llama.LlamaModel', 'aten.add.Tensor']"
              },
              {
                "key": "[metadata] pkg.torch.onnx.fx_node",
                "value": "%add_89 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%slice_8, %convert_element_type_default_1), kwargs = {})"
              },
              {
                "key": "[metadata] pkg.torch.onnx.name_scopes",
                "value": "['', 'model', 'add_89']"
              },
              {
                "key": "[metadata] pkg.torch.onnx.stack_trace",
                "value": "File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 688, in forward\n    outputs: BaseModelOutputWithPast = self.model(\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 436, in forward\n    causal_mask = self._update_causal_mask("
              }
            ],
            "incomingEdges": [
              {
                "sourceNodeId": "node_Slice_126",
                "sourceNodeOutputId": "0",
                "targetNodeInputId": "0"
              },
              {
                "sourceNodeId": "node_Cast_152",
                "sourceNodeOutputId": "0",
                "targetNodeInputId": "1"
              }
            ],
            "outputsMetadata": [
              {
                "id": "0",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "add_89"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "FLOAT[s34,1,s16,s16 + s17]"
                  },
                  {
                    "key": "param_name",
                    "value": "C"
                  }
                ]
              }
            ],
            "inputsMetadata": [
              {
                "id": "0",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "slice_8"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "FLOAT[s34,1,s16,s16 + s17]"
                  },
                  {
                    "key": "param_name",
                    "value": "A"
                  }
                ]
              },
              {
                "id": "1",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "convert_element_type_default_1"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "FLOAT[s34,1,1,s16 + s17]"
                  },
                  {
                    "key": "param_name",
                    "value": "B"
                  }
                ]
              }
            ],
            "style": null,
            "config": null
          },
          {
            "id": "node_Constant_764",
            "label": "Constant",
            "namespace": "main_graph/: transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/eq_67: aten.eq.Tensor",
            "subgraphIds": [],
            "attrs": [
              {
                "key": "__value",
                "value": "0.0"
              },
              {
                "key": "value",
                "value": "TensorProtoTensor<FLOAT,[]>(array(0., dtype=float32), name='scalar_tensor_default')"
              }
            ],
            "incomingEdges": [],
            "outputsMetadata": [
              {
                "id": "0",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "scalar_tensor_default"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "FLOAT[]"
                  },
                  {
                    "key": "param_name",
                    "value": "output"
                  }
                ]
              }
            ],
            "inputsMetadata": [],
            "style": null,
            "config": null
          },
          {
            "id": "node_Equal_155",
            "label": "Equal",
            "namespace": "main_graph/: transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/eq_67: aten.eq.Tensor",
            "subgraphIds": [],
            "attrs": [
              {
                "key": "[metadata] namespace",
                "value": ": transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/eq_67: aten.eq.Tensor"
              },
              {
                "key": "[metadata] pkg.torch.onnx.class_hierarchy",
                "value": "['transformers.models.llama.modeling_llama.LlamaForCausalLM', 'transformers.models.llama.modeling_llama.LlamaModel', 'aten.eq.Tensor']"
              },
              {
                "key": "[metadata] pkg.torch.onnx.fx_node",
                "value": "%eq_67 : [num_users=1] = call_function[target=torch.ops.aten.eq.Tensor](args = (%add_89, %scalar_tensor_default), kwargs = {})"
              },
              {
                "key": "[metadata] pkg.torch.onnx.name_scopes",
                "value": "['', 'model', 'eq_67']"
              },
              {
                "key": "[metadata] pkg.torch.onnx.stack_trace",
                "value": "File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 688, in forward\n    outputs: BaseModelOutputWithPast = self.model(\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 436, in forward\n    causal_mask = self._update_causal_mask("
              }
            ],
            "incomingEdges": [
              {
                "sourceNodeId": "node_Add_153",
                "sourceNodeOutputId": "0",
                "targetNodeInputId": "0"
              },
              {
                "sourceNodeId": "node_Constant_764",
                "sourceNodeOutputId": "0",
                "targetNodeInputId": "1"
              }
            ],
            "outputsMetadata": [
              {
                "id": "0",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "eq_67"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "BOOL[s34,1,s16,s16 + s17]"
                  },
                  {
                    "key": "param_name",
                    "value": "C"
                  }
                ]
              }
            ],
            "inputsMetadata": [
              {
                "id": "0",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "add_89"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "FLOAT[s34,1,s16,s16 + s17]"
                  },
                  {
                    "key": "param_name",
                    "value": "A"
                  }
                ]
              },
              {
                "id": "1",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "scalar_tensor_default"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "FLOAT[]"
                  },
                  {
                    "key": "param_name",
                    "value": "B"
                  }
                ]
              }
            ],
            "style": null,
            "config": null
          },
          {
            "id": "node_Constant_777",
            "label": "Constant",
            "namespace": "main_graph/: transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/slice_14: aten.slice.Tensor",
            "subgraphIds": [],
            "attrs": [
              {
                "key": "__value",
                "value": "[3]"
              },
              {
                "key": "value",
                "value": "TensorProtoTensor<INT64,[1]>(array([3]), name='val_129')"
              }
            ],
            "incomingEdges": [],
            "outputsMetadata": [
              {
                "id": "0",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "val_129"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "INT64[1]"
                  },
                  {
                    "key": "param_name",
                    "value": "output"
                  }
                ]
              }
            ],
            "inputsMetadata": [],
            "style": null,
            "config": null
          },
          {
            "id": "node_Slice_185",
            "label": "Slice",
            "namespace": "main_graph/: transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/slice_14: aten.slice.Tensor",
            "subgraphIds": [],
            "attrs": [
              {
                "key": "[metadata] namespace",
                "value": ": transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/slice_14: aten.slice.Tensor"
              },
              {
                "key": "[metadata] pkg.torch.onnx.class_hierarchy",
                "value": "['transformers.models.llama.modeling_llama.LlamaForCausalLM', 'transformers.models.llama.modeling_llama.LlamaModel', 'aten.slice.Tensor']"
              },
              {
                "key": "[metadata] pkg.torch.onnx.fx_node",
                "value": "%slice_14 : [num_users=1] = call_function[target=torch.ops.aten.slice.Tensor](args = (%slice_13, 3, None, %add_4), kwargs = {})"
              },
              {
                "key": "[metadata] pkg.torch.onnx.name_scopes",
                "value": "['', 'model', 'slice_14']"
              },
              {
                "key": "[metadata] pkg.torch.onnx.stack_trace",
                "value": "File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 688, in forward\n    outputs: BaseModelOutputWithPast = self.model(\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 436, in forward\n    causal_mask = self._update_causal_mask("
              }
            ],
            "incomingEdges": [
              {
                "sourceNodeId": "node_Expand_94",
                "sourceNodeOutputId": "0",
                "targetNodeInputId": "0"
              },
              {
                "sourceNodeId": "node_Constant_118",
                "sourceNodeOutputId": "0",
                "targetNodeInputId": "1"
              },
              {
                "sourceNodeId": "node_Reshape_121",
                "sourceNodeOutputId": "0",
                "targetNodeInputId": "2"
              },
              {
                "sourceNodeId": "node_Constant_777",
                "sourceNodeOutputId": "0",
                "targetNodeInputId": "3"
              },
              {
                "sourceNodeId": "node_Constant_125",
                "sourceNodeOutputId": "0",
                "targetNodeInputId": "4"
              }
            ],
            "outputsMetadata": [
              {
                "id": "0",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "slice_14"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "FLOAT[s34,1,s16,s16 + s17]"
                  },
                  {
                    "key": "param_name",
                    "value": "output"
                  }
                ]
              }
            ],
            "inputsMetadata": [
              {
                "id": "0",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "expand_1"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "FLOAT[s34,1,s16,s16 + s17]"
                  },
                  {
                    "key": "param_name",
                    "value": "data"
                  }
                ]
              },
              {
                "id": "1",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "val_76"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "INT64[1]"
                  },
                  {
                    "key": "param_name",
                    "value": "starts"
                  }
                ]
              },
              {
                "id": "2",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "val_79"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "INT64[1]"
                  },
                  {
                    "key": "param_name",
                    "value": "ends"
                  }
                ]
              },
              {
                "id": "3",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "val_129"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "INT64[1]"
                  },
                  {
                    "key": "param_name",
                    "value": "axes"
                  }
                ]
              },
              {
                "id": "4",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "val_83"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "INT64[1]"
                  },
                  {
                    "key": "param_name",
                    "value": "steps"
                  }
                ]
              }
            ],
            "style": null,
            "config": null
          },
          {
            "id": "node_Constant_779",
            "label": "Constant",
            "namespace": "main_graph/: transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/masked_fill: aten.masked_fill.Scalar",
            "subgraphIds": [],
            "attrs": [
              {
                "key": "__value",
                "value": "-3.4028234663852886e+38"
              },
              {
                "key": "value",
                "value": "TensorProtoTensor<FLOAT,[]>(array(-3.4028235e+38, dtype=float32), name='val_131')"
              }
            ],
            "incomingEdges": [],
            "outputsMetadata": [
              {
                "id": "0",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "val_131"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "FLOAT[]"
                  },
                  {
                    "key": "param_name",
                    "value": "output"
                  }
                ]
              }
            ],
            "inputsMetadata": [],
            "style": null,
            "config": null
          },
          {
            "id": "node_Where_187",
            "label": "Where",
            "namespace": "main_graph/: transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/masked_fill: aten.masked_fill.Scalar",
            "subgraphIds": [],
            "attrs": [
              {
                "key": "[metadata] namespace",
                "value": ": transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/masked_fill: aten.masked_fill.Scalar"
              },
              {
                "key": "[metadata] pkg.torch.onnx.class_hierarchy",
                "value": "['transformers.models.llama.modeling_llama.LlamaForCausalLM', 'transformers.models.llama.modeling_llama.LlamaModel', 'aten.masked_fill.Scalar']"
              },
              {
                "key": "[metadata] pkg.torch.onnx.fx_node",
                "value": "%masked_fill : [num_users=1] = call_function[target=torch.ops.aten.masked_fill.Scalar](args = (%slice_14, %eq_67, -3.4028234663852886e+38), kwargs = {})"
              },
              {
                "key": "[metadata] pkg.torch.onnx.name_scopes",
                "value": "['', 'model', 'masked_fill']"
              },
              {
                "key": "[metadata] pkg.torch.onnx.stack_trace",
                "value": "File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 688, in forward\n    outputs: BaseModelOutputWithPast = self.model(\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 436, in forward\n    causal_mask = self._update_causal_mask("
              }
            ],
            "incomingEdges": [
              {
                "sourceNodeId": "node_Equal_155",
                "sourceNodeOutputId": "0",
                "targetNodeInputId": "0"
              },
              {
                "sourceNodeId": "node_Constant_779",
                "sourceNodeOutputId": "0",
                "targetNodeInputId": "1"
              },
              {
                "sourceNodeId": "node_Slice_185",
                "sourceNodeOutputId": "0",
                "targetNodeInputId": "2"
              }
            ],
            "outputsMetadata": [
              {
                "id": "0",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "masked_fill"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "FLOAT[s34,1,s16,s16 + s17]"
                  },
                  {
                    "key": "param_name",
                    "value": "output"
                  }
                ]
              }
            ],
            "inputsMetadata": [
              {
                "id": "0",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "eq_67"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "BOOL[s34,1,s16,s16 + s17]"
                  },
                  {
                    "key": "param_name",
                    "value": "condition"
                  }
                ]
              },
              {
                "id": "1",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "val_131"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "FLOAT[]"
                  },
                  {
                    "key": "param_name",
                    "value": "X"
                  }
                ]
              },
              {
                "id": "2",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "slice_14"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "FLOAT[s34,1,s16,s16 + s17]"
                  },
                  {
                    "key": "param_name",
                    "value": "Y"
                  }
                ]
              }
            ],
            "style": null,
            "config": null
          },
          {
            "id": "node_Shape_245",
            "label": "Shape",
            "namespace": "main_graph/: transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/slice_scatter: aten.slice_scatter.default",
            "subgraphIds": [],
            "attrs": [
              {
                "key": "start",
                "value": "0"
              },
              {
                "key": "[metadata] namespace",
                "value": ": transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/slice_scatter: aten.slice_scatter.default"
              },
              {
                "key": "[metadata] pkg.torch.onnx.class_hierarchy",
                "value": "['transformers.models.llama.modeling_llama.LlamaForCausalLM', 'transformers.models.llama.modeling_llama.LlamaModel', 'aten.slice_scatter.default']"
              },
              {
                "key": "[metadata] pkg.torch.onnx.fx_node",
                "value": "%slice_scatter : [num_users=1] = call_function[target=torch.ops.aten.slice_scatter.default](args = (%slice_19, %copy, 2, 0, 9223372036854775807), kwargs = {})"
              },
              {
                "key": "[metadata] pkg.torch.onnx.name_scopes",
                "value": "['', 'model', 'slice_scatter']"
              },
              {
                "key": "[metadata] pkg.torch.onnx.stack_trace",
                "value": "File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 688, in forward\n    outputs: BaseModelOutputWithPast = self.model(\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 436, in forward\n    causal_mask = self._update_causal_mask("
              }
            ],
            "incomingEdges": [
              {
                "sourceNodeId": "node_Expand_94",
                "sourceNodeOutputId": "0",
                "targetNodeInputId": "0"
              }
            ],
            "outputsMetadata": [
              {
                "id": "0",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "val_183"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "INT64[4]"
                  },
                  {
                    "key": "param_name",
                    "value": "shape"
                  }
                ]
              }
            ],
            "inputsMetadata": [
              {
                "id": "0",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "expand_1"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "FLOAT[s34,1,s16,s16 + s17]"
                  },
                  {
                    "key": "param_name",
                    "value": "data"
                  }
                ]
              }
            ],
            "style": null,
            "config": null
          },
          {
            "id": "node_Gather_246",
            "label": "Gather",
            "namespace": "main_graph/: transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/slice_scatter: aten.slice_scatter.default",
            "subgraphIds": [],
            "attrs": [
              {
                "key": "axis",
                "value": "0"
              },
              {
                "key": "[metadata] namespace",
                "value": ": transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/slice_scatter: aten.slice_scatter.default"
              },
              {
                "key": "[metadata] pkg.torch.onnx.class_hierarchy",
                "value": "['transformers.models.llama.modeling_llama.LlamaForCausalLM', 'transformers.models.llama.modeling_llama.LlamaModel', 'aten.slice_scatter.default']"
              },
              {
                "key": "[metadata] pkg.torch.onnx.fx_node",
                "value": "%slice_scatter : [num_users=1] = call_function[target=torch.ops.aten.slice_scatter.default](args = (%slice_19, %copy, 2, 0, 9223372036854775807), kwargs = {})"
              },
              {
                "key": "[metadata] pkg.torch.onnx.name_scopes",
                "value": "['', 'model', 'slice_scatter']"
              },
              {
                "key": "[metadata] pkg.torch.onnx.stack_trace",
                "value": "File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 688, in forward\n    outputs: BaseModelOutputWithPast = self.model(\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 436, in forward\n    causal_mask = self._update_causal_mask("
              }
            ],
            "incomingEdges": [
              {
                "sourceNodeId": "node_Shape_245",
                "sourceNodeOutputId": "0",
                "targetNodeInputId": "0"
              },
              {
                "sourceNodeId": "node_Constant_70",
                "sourceNodeOutputId": "0",
                "targetNodeInputId": "1"
              }
            ],
            "outputsMetadata": [
              {
                "id": "0",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "val_184"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "INT64[]"
                  },
                  {
                    "key": "param_name",
                    "value": "output"
                  }
                ]
              }
            ],
            "inputsMetadata": [
              {
                "id": "0",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "val_183"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "INT64[4]"
                  },
                  {
                    "key": "param_name",
                    "value": "data"
                  }
                ]
              },
              {
                "id": "1",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "val_35"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "INT64[]"
                  },
                  {
                    "key": "param_name",
                    "value": "indices"
                  }
                ]
              }
            ],
            "style": null,
            "config": null
          },
          {
            "id": "node_Range_247",
            "label": "Range",
            "namespace": "main_graph/: transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/slice_scatter: aten.slice_scatter.default",
            "subgraphIds": [],
            "attrs": [
              {
                "key": "[metadata] namespace",
                "value": ": transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/slice_scatter: aten.slice_scatter.default"
              },
              {
                "key": "[metadata] pkg.torch.onnx.class_hierarchy",
                "value": "['transformers.models.llama.modeling_llama.LlamaForCausalLM', 'transformers.models.llama.modeling_llama.LlamaModel', 'aten.slice_scatter.default']"
              },
              {
                "key": "[metadata] pkg.torch.onnx.fx_node",
                "value": "%slice_scatter : [num_users=1] = call_function[target=torch.ops.aten.slice_scatter.default](args = (%slice_19, %copy, 2, 0, 9223372036854775807), kwargs = {})"
              },
              {
                "key": "[metadata] pkg.torch.onnx.name_scopes",
                "value": "['', 'model', 'slice_scatter']"
              },
              {
                "key": "[metadata] pkg.torch.onnx.stack_trace",
                "value": "File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 688, in forward\n    outputs: BaseModelOutputWithPast = self.model(\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 436, in forward\n    causal_mask = self._update_causal_mask("
              }
            ],
            "incomingEdges": [
              {
                "sourceNodeId": "node_Constant_62",
                "sourceNodeOutputId": "0",
                "targetNodeInputId": "0"
              },
              {
                "sourceNodeId": "node_Gather_246",
                "sourceNodeOutputId": "0",
                "targetNodeInputId": "1"
              },
              {
                "sourceNodeId": "node_Constant_105",
                "sourceNodeOutputId": "0",
                "targetNodeInputId": "2"
              }
            ],
            "outputsMetadata": [
              {
                "id": "0",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "val_185"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "INT64[unk__16]"
                  },
                  {
                    "key": "param_name",
                    "value": "output"
                  }
                ]
              }
            ],
            "inputsMetadata": [
              {
                "id": "0",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "val_27"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "INT64[]"
                  },
                  {
                    "key": "param_name",
                    "value": "start"
                  }
                ]
              },
              {
                "id": "1",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "val_184"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "INT64[]"
                  },
                  {
                    "key": "param_name",
                    "value": "limit"
                  }
                ]
              },
              {
                "id": "2",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "val_65"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "INT64[]"
                  },
                  {
                    "key": "param_name",
                    "value": "delta"
                  }
                ]
              }
            ],
            "style": null,
            "config": null
          },
          {
            "id": "node_Unsqueeze_252",
            "label": "Unsqueeze",
            "namespace": "main_graph/: transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/slice_scatter: aten.slice_scatter.default",
            "subgraphIds": [],
            "attrs": [
              {
                "key": "[metadata] namespace",
                "value": ": transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/slice_scatter: aten.slice_scatter.default"
              },
              {
                "key": "[metadata] pkg.torch.onnx.class_hierarchy",
                "value": "['transformers.models.llama.modeling_llama.LlamaForCausalLM', 'transformers.models.llama.modeling_llama.LlamaModel', 'aten.slice_scatter.default']"
              },
              {
                "key": "[metadata] pkg.torch.onnx.fx_node",
                "value": "%slice_scatter : [num_users=1] = call_function[target=torch.ops.aten.slice_scatter.default](args = (%slice_19, %copy, 2, 0, 9223372036854775807), kwargs = {})"
              },
              {
                "key": "[metadata] pkg.torch.onnx.name_scopes",
                "value": "['', 'model', 'slice_scatter']"
              },
              {
                "key": "[metadata] pkg.torch.onnx.stack_trace",
                "value": "File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 688, in forward\n    outputs: BaseModelOutputWithPast = self.model(\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 436, in forward\n    causal_mask = self._update_causal_mask("
              }
            ],
            "incomingEdges": [
              {
                "sourceNodeId": "node_Range_247",
                "sourceNodeOutputId": "0",
                "targetNodeInputId": "0"
              },
              {
                "sourceNodeId": "node_Constant_90",
                "sourceNodeOutputId": "0",
                "targetNodeInputId": "1"
              }
            ],
            "outputsMetadata": [
              {
                "id": "0",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "val_190"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "INT64[unk__16,1]"
                  },
                  {
                    "key": "param_name",
                    "value": "expanded"
                  }
                ]
              }
            ],
            "inputsMetadata": [
              {
                "id": "0",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "val_185"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "INT64[unk__16]"
                  },
                  {
                    "key": "param_name",
                    "value": "data"
                  }
                ]
              },
              {
                "id": "1",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "val_53"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "INT64[1]"
                  },
                  {
                    "key": "param_name",
                    "value": "axes"
                  }
                ]
              }
            ],
            "style": null,
            "config": null
          },
          {
            "id": "node_Transpose_253",
            "label": "Transpose",
            "namespace": "main_graph/: transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/slice_scatter: aten.slice_scatter.default",
            "subgraphIds": [],
            "attrs": [
              {
                "key": "perm",
                "value": "[2, 1, 0, 3]"
              },
              {
                "key": "[metadata] namespace",
                "value": ": transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/slice_scatter: aten.slice_scatter.default"
              },
              {
                "key": "[metadata] pkg.torch.onnx.class_hierarchy",
                "value": "['transformers.models.llama.modeling_llama.LlamaForCausalLM', 'transformers.models.llama.modeling_llama.LlamaModel', 'aten.slice_scatter.default']"
              },
              {
                "key": "[metadata] pkg.torch.onnx.fx_node",
                "value": "%slice_scatter : [num_users=1] = call_function[target=torch.ops.aten.slice_scatter.default](args = (%slice_19, %copy, 2, 0, 9223372036854775807), kwargs = {})"
              },
              {
                "key": "[metadata] pkg.torch.onnx.name_scopes",
                "value": "['', 'model', 'slice_scatter']"
              },
              {
                "key": "[metadata] pkg.torch.onnx.stack_trace",
                "value": "File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 688, in forward\n    outputs: BaseModelOutputWithPast = self.model(\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 436, in forward\n    causal_mask = self._update_causal_mask("
              }
            ],
            "incomingEdges": [
              {
                "sourceNodeId": "node_Where_187",
                "sourceNodeOutputId": "0",
                "targetNodeInputId": "0"
              }
            ],
            "outputsMetadata": [
              {
                "id": "0",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "val_191"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "FLOAT[s16,1,s34,s16 + s17]"
                  },
                  {
                    "key": "param_name",
                    "value": "transposed"
                  }
                ]
              }
            ],
            "inputsMetadata": [
              {
                "id": "0",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "masked_fill"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "FLOAT[s34,1,s16,s16 + s17]"
                  },
                  {
                    "key": "param_name",
                    "value": "data"
                  }
                ]
              }
            ],
            "style": null,
            "config": null
          },
          {
            "id": "node_Transpose_254",
            "label": "Transpose",
            "namespace": "main_graph/: transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/slice_scatter: aten.slice_scatter.default",
            "subgraphIds": [],
            "attrs": [
              {
                "key": "perm",
                "value": "[2, 1, 0, 3]"
              },
              {
                "key": "[metadata] namespace",
                "value": ": transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/slice_scatter: aten.slice_scatter.default"
              },
              {
                "key": "[metadata] pkg.torch.onnx.class_hierarchy",
                "value": "['transformers.models.llama.modeling_llama.LlamaForCausalLM', 'transformers.models.llama.modeling_llama.LlamaModel', 'aten.slice_scatter.default']"
              },
              {
                "key": "[metadata] pkg.torch.onnx.fx_node",
                "value": "%slice_scatter : [num_users=1] = call_function[target=torch.ops.aten.slice_scatter.default](args = (%slice_19, %copy, 2, 0, 9223372036854775807), kwargs = {})"
              },
              {
                "key": "[metadata] pkg.torch.onnx.name_scopes",
                "value": "['', 'model', 'slice_scatter']"
              },
              {
                "key": "[metadata] pkg.torch.onnx.stack_trace",
                "value": "File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 688, in forward\n    outputs: BaseModelOutputWithPast = self.model(\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 436, in forward\n    causal_mask = self._update_causal_mask("
              }
            ],
            "incomingEdges": [
              {
                "sourceNodeId": "node_Expand_94",
                "sourceNodeOutputId": "0",
                "targetNodeInputId": "0"
              }
            ],
            "outputsMetadata": [
              {
                "id": "0",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "val_192"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "FLOAT[s16,1,s34,s16 + s17]"
                  },
                  {
                    "key": "param_name",
                    "value": "transposed"
                  }
                ]
              }
            ],
            "inputsMetadata": [
              {
                "id": "0",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "expand_1"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "FLOAT[s34,1,s16,s16 + s17]"
                  },
                  {
                    "key": "param_name",
                    "value": "data"
                  }
                ]
              }
            ],
            "style": null,
            "config": null
          },
          {
            "id": "node_ScatterND_255",
            "label": "ScatterND",
            "namespace": "main_graph/: transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/slice_scatter: aten.slice_scatter.default",
            "subgraphIds": [],
            "attrs": [
              {
                "key": "reduction",
                "value": "none"
              },
              {
                "key": "[metadata] namespace",
                "value": ": transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/slice_scatter: aten.slice_scatter.default"
              },
              {
                "key": "[metadata] pkg.torch.onnx.class_hierarchy",
                "value": "['transformers.models.llama.modeling_llama.LlamaForCausalLM', 'transformers.models.llama.modeling_llama.LlamaModel', 'aten.slice_scatter.default']"
              },
              {
                "key": "[metadata] pkg.torch.onnx.fx_node",
                "value": "%slice_scatter : [num_users=1] = call_function[target=torch.ops.aten.slice_scatter.default](args = (%slice_19, %copy, 2, 0, 9223372036854775807), kwargs = {})"
              },
              {
                "key": "[metadata] pkg.torch.onnx.name_scopes",
                "value": "['', 'model', 'slice_scatter']"
              },
              {
                "key": "[metadata] pkg.torch.onnx.stack_trace",
                "value": "File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 688, in forward\n    outputs: BaseModelOutputWithPast = self.model(\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 436, in forward\n    causal_mask = self._update_causal_mask("
              }
            ],
            "incomingEdges": [
              {
                "sourceNodeId": "node_Transpose_254",
                "sourceNodeOutputId": "0",
                "targetNodeInputId": "0"
              },
              {
                "sourceNodeId": "node_Unsqueeze_252",
                "sourceNodeOutputId": "0",
                "targetNodeInputId": "1"
              },
              {
                "sourceNodeId": "node_Transpose_253",
                "sourceNodeOutputId": "0",
                "targetNodeInputId": "2"
              }
            ],
            "outputsMetadata": [
              {
                "id": "0",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "val_193"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "FLOAT[s16,1,s34,s16 + s17]"
                  },
                  {
                    "key": "param_name",
                    "value": "output"
                  }
                ]
              }
            ],
            "inputsMetadata": [
              {
                "id": "0",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "val_192"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "FLOAT[s16,1,s34,s16 + s17]"
                  },
                  {
                    "key": "param_name",
                    "value": "data"
                  }
                ]
              },
              {
                "id": "1",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "val_190"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "INT64[unk__16,1]"
                  },
                  {
                    "key": "param_name",
                    "value": "indices"
                  }
                ]
              },
              {
                "id": "2",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "val_191"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "FLOAT[s16,1,s34,s16 + s17]"
                  },
                  {
                    "key": "param_name",
                    "value": "updates"
                  }
                ]
              }
            ],
            "style": null,
            "config": null
          },
          {
            "id": "node_Gather_259",
            "label": "Gather",
            "namespace": "main_graph/: transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/slice_scatter_1: aten.slice_scatter.default",
            "subgraphIds": [],
            "attrs": [
              {
                "key": "axis",
                "value": "0"
              },
              {
                "key": "[metadata] namespace",
                "value": ": transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/slice_scatter_1: aten.slice_scatter.default"
              },
              {
                "key": "[metadata] pkg.torch.onnx.class_hierarchy",
                "value": "['transformers.models.llama.modeling_llama.LlamaForCausalLM', 'transformers.models.llama.modeling_llama.LlamaModel', 'aten.slice_scatter.default']"
              },
              {
                "key": "[metadata] pkg.torch.onnx.fx_node",
                "value": "%slice_scatter_1 : [num_users=1] = call_function[target=torch.ops.aten.slice_scatter.default](args = (%slice_18, %slice_scatter, 1, 0, 9223372036854775807), kwargs = {})"
              },
              {
                "key": "[metadata] pkg.torch.onnx.name_scopes",
                "value": "['', 'model', 'slice_scatter_1']"
              },
              {
                "key": "[metadata] pkg.torch.onnx.stack_trace",
                "value": "File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 688, in forward\n    outputs: BaseModelOutputWithPast = self.model(\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 436, in forward\n    causal_mask = self._update_causal_mask("
              }
            ],
            "incomingEdges": [
              {
                "sourceNodeId": "node_Shape_245",
                "sourceNodeOutputId": "0",
                "targetNodeInputId": "0"
              },
              {
                "sourceNodeId": "node_Constant_105",
                "sourceNodeOutputId": "0",
                "targetNodeInputId": "1"
              }
            ],
            "outputsMetadata": [
              {
                "id": "0",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "val_196"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "INT64[]"
                  },
                  {
                    "key": "param_name",
                    "value": "output"
                  }
                ]
              }
            ],
            "inputsMetadata": [
              {
                "id": "0",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "val_183"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "INT64[4]"
                  },
                  {
                    "key": "param_name",
                    "value": "data"
                  }
                ]
              },
              {
                "id": "1",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "val_65"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "INT64[]"
                  },
                  {
                    "key": "param_name",
                    "value": "indices"
                  }
                ]
              }
            ],
            "style": null,
            "config": null
          },
          {
            "id": "node_Range_260",
            "label": "Range",
            "namespace": "main_graph/: transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/slice_scatter_1: aten.slice_scatter.default",
            "subgraphIds": [],
            "attrs": [
              {
                "key": "[metadata] namespace",
                "value": ": transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/slice_scatter_1: aten.slice_scatter.default"
              },
              {
                "key": "[metadata] pkg.torch.onnx.class_hierarchy",
                "value": "['transformers.models.llama.modeling_llama.LlamaForCausalLM', 'transformers.models.llama.modeling_llama.LlamaModel', 'aten.slice_scatter.default']"
              },
              {
                "key": "[metadata] pkg.torch.onnx.fx_node",
                "value": "%slice_scatter_1 : [num_users=1] = call_function[target=torch.ops.aten.slice_scatter.default](args = (%slice_18, %slice_scatter, 1, 0, 9223372036854775807), kwargs = {})"
              },
              {
                "key": "[metadata] pkg.torch.onnx.name_scopes",
                "value": "['', 'model', 'slice_scatter_1']"
              },
              {
                "key": "[metadata] pkg.torch.onnx.stack_trace",
                "value": "File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 688, in forward\n    outputs: BaseModelOutputWithPast = self.model(\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 436, in forward\n    causal_mask = self._update_causal_mask("
              }
            ],
            "incomingEdges": [
              {
                "sourceNodeId": "node_Constant_62",
                "sourceNodeOutputId": "0",
                "targetNodeInputId": "0"
              },
              {
                "sourceNodeId": "node_Gather_259",
                "sourceNodeOutputId": "0",
                "targetNodeInputId": "1"
              },
              {
                "sourceNodeId": "node_Constant_105",
                "sourceNodeOutputId": "0",
                "targetNodeInputId": "2"
              }
            ],
            "outputsMetadata": [
              {
                "id": "0",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "val_197"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "INT64[unk__17]"
                  },
                  {
                    "key": "param_name",
                    "value": "output"
                  }
                ]
              }
            ],
            "inputsMetadata": [
              {
                "id": "0",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "val_27"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "INT64[]"
                  },
                  {
                    "key": "param_name",
                    "value": "start"
                  }
                ]
              },
              {
                "id": "1",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "val_196"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "INT64[]"
                  },
                  {
                    "key": "param_name",
                    "value": "limit"
                  }
                ]
              },
              {
                "id": "2",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "val_65"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "INT64[]"
                  },
                  {
                    "key": "param_name",
                    "value": "delta"
                  }
                ]
              }
            ],
            "style": null,
            "config": null
          },
          {
            "id": "node_Unsqueeze_265",
            "label": "Unsqueeze",
            "namespace": "main_graph/: transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/slice_scatter_1: aten.slice_scatter.default",
            "subgraphIds": [],
            "attrs": [
              {
                "key": "[metadata] namespace",
                "value": ": transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/slice_scatter_1: aten.slice_scatter.default"
              },
              {
                "key": "[metadata] pkg.torch.onnx.class_hierarchy",
                "value": "['transformers.models.llama.modeling_llama.LlamaForCausalLM', 'transformers.models.llama.modeling_llama.LlamaModel', 'aten.slice_scatter.default']"
              },
              {
                "key": "[metadata] pkg.torch.onnx.fx_node",
                "value": "%slice_scatter_1 : [num_users=1] = call_function[target=torch.ops.aten.slice_scatter.default](args = (%slice_18, %slice_scatter, 1, 0, 9223372036854775807), kwargs = {})"
              },
              {
                "key": "[metadata] pkg.torch.onnx.name_scopes",
                "value": "['', 'model', 'slice_scatter_1']"
              },
              {
                "key": "[metadata] pkg.torch.onnx.stack_trace",
                "value": "File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 688, in forward\n    outputs: BaseModelOutputWithPast = self.model(\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 436, in forward\n    causal_mask = self._update_causal_mask("
              }
            ],
            "incomingEdges": [
              {
                "sourceNodeId": "node_Range_260",
                "sourceNodeOutputId": "0",
                "targetNodeInputId": "0"
              },
              {
                "sourceNodeId": "node_Constant_90",
                "sourceNodeOutputId": "0",
                "targetNodeInputId": "1"
              }
            ],
            "outputsMetadata": [
              {
                "id": "0",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "val_202"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "INT64[unk__17,1]"
                  },
                  {
                    "key": "param_name",
                    "value": "expanded"
                  }
                ]
              }
            ],
            "inputsMetadata": [
              {
                "id": "0",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "val_197"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "INT64[unk__17]"
                  },
                  {
                    "key": "param_name",
                    "value": "data"
                  }
                ]
              },
              {
                "id": "1",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "val_53"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "INT64[1]"
                  },
                  {
                    "key": "param_name",
                    "value": "axes"
                  }
                ]
              }
            ],
            "style": null,
            "config": null
          },
          {
            "id": "node_Transpose_1025",
            "label": "Transpose",
            "namespace": "main_graph",
            "subgraphIds": [],
            "attrs": [
              {
                "key": "perm",
                "value": "[1, 2, 0, 3]"
              }
            ],
            "incomingEdges": [
              {
                "sourceNodeId": "node_ScatterND_255",
                "sourceNodeOutputId": "0",
                "targetNodeInputId": "0"
              }
            ],
            "outputsMetadata": [
              {
                "id": "0",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "val_203"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "FLOAT[1,s34,s16,s16 + s17]"
                  },
                  {
                    "key": "param_name",
                    "value": "transposed"
                  }
                ]
              }
            ],
            "inputsMetadata": [
              {
                "id": "0",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "val_193"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "FLOAT[s16,1,s34,s16 + s17]"
                  },
                  {
                    "key": "param_name",
                    "value": "data"
                  }
                ]
              }
            ],
            "style": null,
            "config": null
          },
          {
            "id": "node_Transpose_267",
            "label": "Transpose",
            "namespace": "main_graph/: transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/slice_scatter_1: aten.slice_scatter.default",
            "subgraphIds": [],
            "attrs": [
              {
                "key": "perm",
                "value": "[1, 0, 2, 3]"
              },
              {
                "key": "[metadata] namespace",
                "value": ": transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/slice_scatter_1: aten.slice_scatter.default"
              },
              {
                "key": "[metadata] pkg.torch.onnx.class_hierarchy",
                "value": "['transformers.models.llama.modeling_llama.LlamaForCausalLM', 'transformers.models.llama.modeling_llama.LlamaModel', 'aten.slice_scatter.default']"
              },
              {
                "key": "[metadata] pkg.torch.onnx.fx_node",
                "value": "%slice_scatter_1 : [num_users=1] = call_function[target=torch.ops.aten.slice_scatter.default](args = (%slice_18, %slice_scatter, 1, 0, 9223372036854775807), kwargs = {})"
              },
              {
                "key": "[metadata] pkg.torch.onnx.name_scopes",
                "value": "['', 'model', 'slice_scatter_1']"
              },
              {
                "key": "[metadata] pkg.torch.onnx.stack_trace",
                "value": "File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 688, in forward\n    outputs: BaseModelOutputWithPast = self.model(\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 436, in forward\n    causal_mask = self._update_causal_mask("
              }
            ],
            "incomingEdges": [
              {
                "sourceNodeId": "node_Expand_94",
                "sourceNodeOutputId": "0",
                "targetNodeInputId": "0"
              }
            ],
            "outputsMetadata": [
              {
                "id": "0",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "val_204"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "FLOAT[1,s34,s16,s16 + s17]"
                  },
                  {
                    "key": "param_name",
                    "value": "transposed"
                  }
                ]
              }
            ],
            "inputsMetadata": [
              {
                "id": "0",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "expand_1"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "FLOAT[s34,1,s16,s16 + s17]"
                  },
                  {
                    "key": "param_name",
                    "value": "data"
                  }
                ]
              }
            ],
            "style": null,
            "config": null
          },
          {
            "id": "node_ScatterND_268",
            "label": "ScatterND",
            "namespace": "main_graph/: transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/slice_scatter_1: aten.slice_scatter.default",
            "subgraphIds": [],
            "attrs": [
              {
                "key": "reduction",
                "value": "none"
              },
              {
                "key": "[metadata] namespace",
                "value": ": transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/slice_scatter_1: aten.slice_scatter.default"
              },
              {
                "key": "[metadata] pkg.torch.onnx.class_hierarchy",
                "value": "['transformers.models.llama.modeling_llama.LlamaForCausalLM', 'transformers.models.llama.modeling_llama.LlamaModel', 'aten.slice_scatter.default']"
              },
              {
                "key": "[metadata] pkg.torch.onnx.fx_node",
                "value": "%slice_scatter_1 : [num_users=1] = call_function[target=torch.ops.aten.slice_scatter.default](args = (%slice_18, %slice_scatter, 1, 0, 9223372036854775807), kwargs = {})"
              },
              {
                "key": "[metadata] pkg.torch.onnx.name_scopes",
                "value": "['', 'model', 'slice_scatter_1']"
              },
              {
                "key": "[metadata] pkg.torch.onnx.stack_trace",
                "value": "File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 688, in forward\n    outputs: BaseModelOutputWithPast = self.model(\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 436, in forward\n    causal_mask = self._update_causal_mask("
              }
            ],
            "incomingEdges": [
              {
                "sourceNodeId": "node_Transpose_267",
                "sourceNodeOutputId": "0",
                "targetNodeInputId": "0"
              },
              {
                "sourceNodeId": "node_Unsqueeze_265",
                "sourceNodeOutputId": "0",
                "targetNodeInputId": "1"
              },
              {
                "sourceNodeId": "node_Transpose_1025",
                "sourceNodeOutputId": "0",
                "targetNodeInputId": "2"
              }
            ],
            "outputsMetadata": [
              {
                "id": "0",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "val_205"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "FLOAT[1,s34,s16,s16 + s17]"
                  },
                  {
                    "key": "param_name",
                    "value": "output"
                  }
                ]
              }
            ],
            "inputsMetadata": [
              {
                "id": "0",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "val_204"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "FLOAT[1,s34,s16,s16 + s17]"
                  },
                  {
                    "key": "param_name",
                    "value": "data"
                  }
                ]
              },
              {
                "id": "1",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "val_202"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "INT64[unk__17,1]"
                  },
                  {
                    "key": "param_name",
                    "value": "indices"
                  }
                ]
              },
              {
                "id": "2",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "val_203"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "FLOAT[1,s34,s16,s16 + s17]"
                  },
                  {
                    "key": "param_name",
                    "value": "updates"
                  }
                ]
              }
            ],
            "style": null,
            "config": null
          },
          {
            "id": "node_Transpose_269",
            "label": "Transpose",
            "namespace": "main_graph/: transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/slice_scatter_1: aten.slice_scatter.default",
            "subgraphIds": [],
            "attrs": [
              {
                "key": "perm",
                "value": "[1, 0, 2, 3]"
              },
              {
                "key": "[metadata] namespace",
                "value": ": transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/slice_scatter_1: aten.slice_scatter.default"
              },
              {
                "key": "[metadata] pkg.torch.onnx.class_hierarchy",
                "value": "['transformers.models.llama.modeling_llama.LlamaForCausalLM', 'transformers.models.llama.modeling_llama.LlamaModel', 'aten.slice_scatter.default']"
              },
              {
                "key": "[metadata] pkg.torch.onnx.fx_node",
                "value": "%slice_scatter_1 : [num_users=1] = call_function[target=torch.ops.aten.slice_scatter.default](args = (%slice_18, %slice_scatter, 1, 0, 9223372036854775807), kwargs = {})"
              },
              {
                "key": "[metadata] pkg.torch.onnx.name_scopes",
                "value": "['', 'model', 'slice_scatter_1']"
              },
              {
                "key": "[metadata] pkg.torch.onnx.stack_trace",
                "value": "File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 688, in forward\n    outputs: BaseModelOutputWithPast = self.model(\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 436, in forward\n    causal_mask = self._update_causal_mask("
              }
            ],
            "incomingEdges": [
              {
                "sourceNodeId": "node_ScatterND_268",
                "sourceNodeOutputId": "0",
                "targetNodeInputId": "0"
              }
            ],
            "outputsMetadata": [
              {
                "id": "0",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "slice_scatter_1"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "FLOAT[s34,1,s16,s16 + s17]"
                  },
                  {
                    "key": "param_name",
                    "value": "transposed"
                  }
                ]
              }
            ],
            "inputsMetadata": [
              {
                "id": "0",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "val_205"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "FLOAT[1,s34,s16,s16 + s17]"
                  },
                  {
                    "key": "param_name",
                    "value": "data"
                  }
                ]
              }
            ],
            "style": null,
            "config": null
          },
          {
            "id": "node_Gather_272",
            "label": "Gather",
            "namespace": "main_graph/: transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/slice_scatter_2: aten.slice_scatter.default",
            "subgraphIds": [],
            "attrs": [
              {
                "key": "axis",
                "value": "0"
              },
              {
                "key": "[metadata] namespace",
                "value": ": transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/slice_scatter_2: aten.slice_scatter.default"
              },
              {
                "key": "[metadata] pkg.torch.onnx.class_hierarchy",
                "value": "['transformers.models.llama.modeling_llama.LlamaForCausalLM', 'transformers.models.llama.modeling_llama.LlamaModel', 'aten.slice_scatter.default']"
              },
              {
                "key": "[metadata] pkg.torch.onnx.fx_node",
                "value": "%slice_scatter_2 : [num_users=2] = call_function[target=torch.ops.aten.slice_scatter.default](args = (%clone, %slice_scatter_1, 0, 0, 9223372036854775807), kwargs = {})"
              },
              {
                "key": "[metadata] pkg.torch.onnx.name_scopes",
                "value": "['', 'model', 'slice_scatter_2']"
              },
              {
                "key": "[metadata] pkg.torch.onnx.stack_trace",
                "value": "File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 688, in forward\n    outputs: BaseModelOutputWithPast = self.model(\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 436, in forward\n    causal_mask = self._update_causal_mask("
              }
            ],
            "incomingEdges": [
              {
                "sourceNodeId": "node_Shape_245",
                "sourceNodeOutputId": "0",
                "targetNodeInputId": "0"
              },
              {
                "sourceNodeId": "node_Constant_62",
                "sourceNodeOutputId": "0",
                "targetNodeInputId": "1"
              }
            ],
            "outputsMetadata": [
              {
                "id": "0",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "val_208"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "INT64[]"
                  },
                  {
                    "key": "param_name",
                    "value": "output"
                  }
                ]
              }
            ],
            "inputsMetadata": [
              {
                "id": "0",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "val_183"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "INT64[4]"
                  },
                  {
                    "key": "param_name",
                    "value": "data"
                  }
                ]
              },
              {
                "id": "1",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "val_27"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "INT64[]"
                  },
                  {
                    "key": "param_name",
                    "value": "indices"
                  }
                ]
              }
            ],
            "style": null,
            "config": null
          },
          {
            "id": "node_Range_273",
            "label": "Range",
            "namespace": "main_graph/: transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/slice_scatter_2: aten.slice_scatter.default",
            "subgraphIds": [],
            "attrs": [
              {
                "key": "[metadata] namespace",
                "value": ": transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/slice_scatter_2: aten.slice_scatter.default"
              },
              {
                "key": "[metadata] pkg.torch.onnx.class_hierarchy",
                "value": "['transformers.models.llama.modeling_llama.LlamaForCausalLM', 'transformers.models.llama.modeling_llama.LlamaModel', 'aten.slice_scatter.default']"
              },
              {
                "key": "[metadata] pkg.torch.onnx.fx_node",
                "value": "%slice_scatter_2 : [num_users=2] = call_function[target=torch.ops.aten.slice_scatter.default](args = (%clone, %slice_scatter_1, 0, 0, 9223372036854775807), kwargs = {})"
              },
              {
                "key": "[metadata] pkg.torch.onnx.name_scopes",
                "value": "['', 'model', 'slice_scatter_2']"
              },
              {
                "key": "[metadata] pkg.torch.onnx.stack_trace",
                "value": "File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 688, in forward\n    outputs: BaseModelOutputWithPast = self.model(\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 436, in forward\n    causal_mask = self._update_causal_mask("
              }
            ],
            "incomingEdges": [
              {
                "sourceNodeId": "node_Constant_62",
                "sourceNodeOutputId": "0",
                "targetNodeInputId": "0"
              },
              {
                "sourceNodeId": "node_Gather_272",
                "sourceNodeOutputId": "0",
                "targetNodeInputId": "1"
              },
              {
                "sourceNodeId": "node_Constant_105",
                "sourceNodeOutputId": "0",
                "targetNodeInputId": "2"
              }
            ],
            "outputsMetadata": [
              {
                "id": "0",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "val_209"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "INT64[unk__18]"
                  },
                  {
                    "key": "param_name",
                    "value": "output"
                  }
                ]
              }
            ],
            "inputsMetadata": [
              {
                "id": "0",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "val_27"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "INT64[]"
                  },
                  {
                    "key": "param_name",
                    "value": "start"
                  }
                ]
              },
              {
                "id": "1",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "val_208"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "INT64[]"
                  },
                  {
                    "key": "param_name",
                    "value": "limit"
                  }
                ]
              },
              {
                "id": "2",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "val_65"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "INT64[]"
                  },
                  {
                    "key": "param_name",
                    "value": "delta"
                  }
                ]
              }
            ],
            "style": null,
            "config": null
          },
          {
            "id": "node_Unsqueeze_278",
            "label": "Unsqueeze",
            "namespace": "main_graph/: transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/slice_scatter_2: aten.slice_scatter.default",
            "subgraphIds": [],
            "attrs": [
              {
                "key": "[metadata] namespace",
                "value": ": transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/slice_scatter_2: aten.slice_scatter.default"
              },
              {
                "key": "[metadata] pkg.torch.onnx.class_hierarchy",
                "value": "['transformers.models.llama.modeling_llama.LlamaForCausalLM', 'transformers.models.llama.modeling_llama.LlamaModel', 'aten.slice_scatter.default']"
              },
              {
                "key": "[metadata] pkg.torch.onnx.fx_node",
                "value": "%slice_scatter_2 : [num_users=2] = call_function[target=torch.ops.aten.slice_scatter.default](args = (%clone, %slice_scatter_1, 0, 0, 9223372036854775807), kwargs = {})"
              },
              {
                "key": "[metadata] pkg.torch.onnx.name_scopes",
                "value": "['', 'model', 'slice_scatter_2']"
              },
              {
                "key": "[metadata] pkg.torch.onnx.stack_trace",
                "value": "File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 688, in forward\n    outputs: BaseModelOutputWithPast = self.model(\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 436, in forward\n    causal_mask = self._update_causal_mask("
              }
            ],
            "incomingEdges": [
              {
                "sourceNodeId": "node_Range_273",
                "sourceNodeOutputId": "0",
                "targetNodeInputId": "0"
              },
              {
                "sourceNodeId": "node_Constant_90",
                "sourceNodeOutputId": "0",
                "targetNodeInputId": "1"
              }
            ],
            "outputsMetadata": [
              {
                "id": "0",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "val_214"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "INT64[unk__18,1]"
                  },
                  {
                    "key": "param_name",
                    "value": "expanded"
                  }
                ]
              }
            ],
            "inputsMetadata": [
              {
                "id": "0",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "val_209"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "INT64[unk__18]"
                  },
                  {
                    "key": "param_name",
                    "value": "data"
                  }
                ]
              },
              {
                "id": "1",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "val_53"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "INT64[1]"
                  },
                  {
                    "key": "param_name",
                    "value": "axes"
                  }
                ]
              }
            ],
            "style": null,
            "config": null
          },
          {
            "id": "node_ScatterND_279",
            "label": "ScatterND",
            "namespace": "main_graph/: transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/slice_scatter_2: aten.slice_scatter.default",
            "subgraphIds": [],
            "attrs": [
              {
                "key": "reduction",
                "value": "none"
              },
              {
                "key": "[metadata] namespace",
                "value": ": transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/slice_scatter_2: aten.slice_scatter.default"
              },
              {
                "key": "[metadata] pkg.torch.onnx.class_hierarchy",
                "value": "['transformers.models.llama.modeling_llama.LlamaForCausalLM', 'transformers.models.llama.modeling_llama.LlamaModel', 'aten.slice_scatter.default']"
              },
              {
                "key": "[metadata] pkg.torch.onnx.fx_node",
                "value": "%slice_scatter_2 : [num_users=2] = call_function[target=torch.ops.aten.slice_scatter.default](args = (%clone, %slice_scatter_1, 0, 0, 9223372036854775807), kwargs = {})"
              },
              {
                "key": "[metadata] pkg.torch.onnx.name_scopes",
                "value": "['', 'model', 'slice_scatter_2']"
              },
              {
                "key": "[metadata] pkg.torch.onnx.stack_trace",
                "value": "File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 688, in forward\n    outputs: BaseModelOutputWithPast = self.model(\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 436, in forward\n    causal_mask = self._update_causal_mask("
              }
            ],
            "incomingEdges": [
              {
                "sourceNodeId": "node_Expand_94",
                "sourceNodeOutputId": "0",
                "targetNodeInputId": "0"
              },
              {
                "sourceNodeId": "node_Unsqueeze_278",
                "sourceNodeOutputId": "0",
                "targetNodeInputId": "1"
              },
              {
                "sourceNodeId": "node_Transpose_269",
                "sourceNodeOutputId": "0",
                "targetNodeInputId": "2"
              }
            ],
            "outputsMetadata": [
              {
                "id": "0",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "slice_scatter_2"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "FLOAT[s34,1,s16,s16 + s17]"
                  },
                  {
                    "key": "param_name",
                    "value": "output"
                  }
                ]
              }
            ],
            "inputsMetadata": [
              {
                "id": "0",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "expand_1"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "FLOAT[s34,1,s16,s16 + s17]"
                  },
                  {
                    "key": "param_name",
                    "value": "data"
                  }
                ]
              },
              {
                "id": "1",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "val_214"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "INT64[unk__18,1]"
                  },
                  {
                    "key": "param_name",
                    "value": "indices"
                  }
                ]
              },
              {
                "id": "2",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "slice_scatter_1"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "FLOAT[s34,1,s16,s16 + s17]"
                  },
                  {
                    "key": "param_name",
                    "value": "updates"
                  }
                ]
              }
            ],
            "style": null,
            "config": null
          },
          {
            "id": "node_SimplifiedLayerNormalization_16",
            "label": "SimplifiedLayerNormalization",
            "namespace": "main_graph",
            "subgraphIds": [],
            "attrs": [
              {
                "key": "axis",
                "value": "-1"
              },
              {
                "key": "epsilon",
                "value": "9.999999747378752e-06"
              },
              {
                "key": "stash_type",
                "value": "1"
              }
            ],
            "incomingEdges": [
              {
                "sourceNodeId": "node_Gather_20",
                "sourceNodeOutputId": "0",
                "targetNodeInputId": "0"
              },
              {
                "sourceNodeId": "[value] model.layers.0.input_layernorm.weight",
                "sourceNodeOutputId": "0",
                "targetNodeInputId": "1"
              }
            ],
            "outputsMetadata": [
              {
                "id": "0",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "mul_173"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "FLOAT[s34,s16,2048]"
                  }
                ]
              }
            ],
            "inputsMetadata": [
              {
                "id": "0",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "embedding"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "FLOAT[s34,s16,2048]"
                  }
                ]
              },
              {
                "id": "1",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "model.layers.0.input_layernorm.weight"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "FLOAT[2048]"
                  }
                ]
              }
            ],
            "style": null,
            "config": null
          },
          {
            "id": "node_MatMul_340",
            "label": "MatMul",
            "namespace": "main_graph/: transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/model.layers.0: transformers.models.llama.modeling_llama.LlamaDecoderLayer/model.layers.0.self_attn: transformers.models.llama.modeling_llama.LlamaAttention/model.layers.0.self_attn.q_proj: torch.nn.modules.linear.Linear/linear: aten.linear.default",
            "subgraphIds": [],
            "attrs": [
              {
                "key": "[metadata] namespace",
                "value": ": transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/model.layers.0: transformers.models.llama.modeling_llama.LlamaDecoderLayer/model.layers.0.self_attn: transformers.models.llama.modeling_llama.LlamaAttention/model.layers.0.self_attn.q_proj: torch.nn.modules.linear.Linear/linear: aten.linear.default"
              },
              {
                "key": "[metadata] pkg.torch.onnx.class_hierarchy",
                "value": "['transformers.models.llama.modeling_llama.LlamaForCausalLM', 'transformers.models.llama.modeling_llama.LlamaModel', 'transformers.models.llama.modeling_llama.LlamaDecoderLayer', 'transformers.models.llama.modeling_llama.LlamaAttention', 'torch.nn.modules.linear.Linear', 'aten.linear.default']"
              },
              {
                "key": "[metadata] pkg.torch.onnx.fx_node",
                "value": "%linear : [num_users=1] = call_function[target=torch.ops.aten.linear.default](args = (%mul_173, %p_model_layers_0_self_attn_q_proj_weight), kwargs = {})"
              },
              {
                "key": "[metadata] pkg.torch.onnx.name_scopes",
                "value": "['', 'model', 'model.layers.0', 'model.layers.0.self_attn', 'model.layers.0.self_attn.q_proj', 'linear']"
              },
              {
                "key": "[metadata] pkg.torch.onnx.stack_trace",
                "value": "File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 688, in forward\n    outputs: BaseModelOutputWithPast = self.model(\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 453, in forward\n    layer_outputs = decoder_layer(\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 308, in forward\n    hidden_states, self_attn_weights = self.self_attn(\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 242, in forward\n    query_states = self.q_proj(hidden_states).view(hidden_shape).transpose(1, 2)\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/torch/nn/modules/linear.py\", line 125, in forward\n    return F.linear(input, self.weight, self.bias)"
              }
            ],
            "incomingEdges": [
              {
                "sourceNodeId": "node_SimplifiedLayerNormalization_16",
                "sourceNodeOutputId": "0",
                "targetNodeInputId": "0"
              },
              {
                "sourceNodeId": "[value] val_253",
                "sourceNodeOutputId": "0",
                "targetNodeInputId": "1"
              }
            ],
            "outputsMetadata": [
              {
                "id": "0",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "linear"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "FLOAT[s34,s16,2048]"
                  },
                  {
                    "key": "param_name",
                    "value": "Y"
                  }
                ]
              }
            ],
            "inputsMetadata": [
              {
                "id": "0",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "mul_173"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "FLOAT[s34,s16,2048]"
                  },
                  {
                    "key": "param_name",
                    "value": "A"
                  }
                ]
              },
              {
                "id": "1",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "val_253"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "FLOAT[2048,2048]"
                  },
                  {
                    "key": "param_name",
                    "value": "B"
                  }
                ]
              }
            ],
            "style": null,
            "config": null
          },
          {
            "id": "node_MatMul_351",
            "label": "MatMul",
            "namespace": "main_graph/: transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/model.layers.0: transformers.models.llama.modeling_llama.LlamaDecoderLayer/model.layers.0.self_attn: transformers.models.llama.modeling_llama.LlamaAttention/model.layers.0.self_attn.k_proj: torch.nn.modules.linear.Linear/linear_1: aten.linear.default",
            "subgraphIds": [],
            "attrs": [
              {
                "key": "[metadata] namespace",
                "value": ": transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/model.layers.0: transformers.models.llama.modeling_llama.LlamaDecoderLayer/model.layers.0.self_attn: transformers.models.llama.modeling_llama.LlamaAttention/model.layers.0.self_attn.k_proj: torch.nn.modules.linear.Linear/linear_1: aten.linear.default"
              },
              {
                "key": "[metadata] pkg.torch.onnx.class_hierarchy",
                "value": "['transformers.models.llama.modeling_llama.LlamaForCausalLM', 'transformers.models.llama.modeling_llama.LlamaModel', 'transformers.models.llama.modeling_llama.LlamaDecoderLayer', 'transformers.models.llama.modeling_llama.LlamaAttention', 'torch.nn.modules.linear.Linear', 'aten.linear.default']"
              },
              {
                "key": "[metadata] pkg.torch.onnx.fx_node",
                "value": "%linear_1 : [num_users=1] = call_function[target=torch.ops.aten.linear.default](args = (%mul_173, %p_model_layers_0_self_attn_k_proj_weight), kwargs = {})"
              },
              {
                "key": "[metadata] pkg.torch.onnx.name_scopes",
                "value": "['', 'model', 'model.layers.0', 'model.layers.0.self_attn', 'model.layers.0.self_attn.k_proj', 'linear_1']"
              },
              {
                "key": "[metadata] pkg.torch.onnx.stack_trace",
                "value": "File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 688, in forward\n    outputs: BaseModelOutputWithPast = self.model(\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 453, in forward\n    layer_outputs = decoder_layer(\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 308, in forward\n    hidden_states, self_attn_weights = self.self_attn(\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 243, in forward\n    key_states = self.k_proj(hidden_states).view(hidden_shape).transpose(1, 2)\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/torch/nn/modules/linear.py\", line 125, in forward\n    return F.linear(input, self.weight, self.bias)"
              }
            ],
            "incomingEdges": [
              {
                "sourceNodeId": "node_SimplifiedLayerNormalization_16",
                "sourceNodeOutputId": "0",
                "targetNodeInputId": "0"
              },
              {
                "sourceNodeId": "[value] val_261",
                "sourceNodeOutputId": "0",
                "targetNodeInputId": "1"
              }
            ],
            "outputsMetadata": [
              {
                "id": "0",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "linear_1"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "FLOAT[s34,s16,2048]"
                  },
                  {
                    "key": "param_name",
                    "value": "Y"
                  }
                ]
              }
            ],
            "inputsMetadata": [
              {
                "id": "0",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "mul_173"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "FLOAT[s34,s16,2048]"
                  },
                  {
                    "key": "param_name",
                    "value": "A"
                  }
                ]
              },
              {
                "id": "1",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "val_261"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "FLOAT[2048,2048]"
                  },
                  {
                    "key": "param_name",
                    "value": "B"
                  }
                ]
              }
            ],
            "style": null,
            "config": null
          },
          {
            "id": "node_MatMul_361",
            "label": "MatMul",
            "namespace": "main_graph/: transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/model.layers.0: transformers.models.llama.modeling_llama.LlamaDecoderLayer/model.layers.0.self_attn: transformers.models.llama.modeling_llama.LlamaAttention/model.layers.0.self_attn.v_proj: torch.nn.modules.linear.Linear/linear_2: aten.linear.default",
            "subgraphIds": [],
            "attrs": [
              {
                "key": "[metadata] namespace",
                "value": ": transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/model.layers.0: transformers.models.llama.modeling_llama.LlamaDecoderLayer/model.layers.0.self_attn: transformers.models.llama.modeling_llama.LlamaAttention/model.layers.0.self_attn.v_proj: torch.nn.modules.linear.Linear/linear_2: aten.linear.default"
              },
              {
                "key": "[metadata] pkg.torch.onnx.class_hierarchy",
                "value": "['transformers.models.llama.modeling_llama.LlamaForCausalLM', 'transformers.models.llama.modeling_llama.LlamaModel', 'transformers.models.llama.modeling_llama.LlamaDecoderLayer', 'transformers.models.llama.modeling_llama.LlamaAttention', 'torch.nn.modules.linear.Linear', 'aten.linear.default']"
              },
              {
                "key": "[metadata] pkg.torch.onnx.fx_node",
                "value": "%linear_2 : [num_users=1] = call_function[target=torch.ops.aten.linear.default](args = (%mul_173, %p_model_layers_0_self_attn_v_proj_weight), kwargs = {})"
              },
              {
                "key": "[metadata] pkg.torch.onnx.name_scopes",
                "value": "['', 'model', 'model.layers.0', 'model.layers.0.self_attn', 'model.layers.0.self_attn.v_proj', 'linear_2']"
              },
              {
                "key": "[metadata] pkg.torch.onnx.stack_trace",
                "value": "File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 688, in forward\n    outputs: BaseModelOutputWithPast = self.model(\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 453, in forward\n    layer_outputs = decoder_layer(\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 308, in forward\n    hidden_states, self_attn_weights = self.self_attn(\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 244, in forward\n    value_states = self.v_proj(hidden_states).view(hidden_shape).transpose(1, 2)\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/torch/nn/modules/linear.py\", line 125, in forward\n    return F.linear(input, self.weight, self.bias)"
              }
            ],
            "incomingEdges": [
              {
                "sourceNodeId": "node_SimplifiedLayerNormalization_16",
                "sourceNodeOutputId": "0",
                "targetNodeInputId": "0"
              },
              {
                "sourceNodeId": "[value] val_268",
                "sourceNodeOutputId": "0",
                "targetNodeInputId": "1"
              }
            ],
            "outputsMetadata": [
              {
                "id": "0",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "linear_2"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "FLOAT[s34,s16,2048]"
                  },
                  {
                    "key": "param_name",
                    "value": "Y"
                  }
                ]
              }
            ],
            "inputsMetadata": [
              {
                "id": "0",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "mul_173"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "FLOAT[s34,s16,2048]"
                  },
                  {
                    "key": "param_name",
                    "value": "A"
                  }
                ]
              },
              {
                "id": "1",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "val_268"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "FLOAT[2048,2048]"
                  },
                  {
                    "key": "param_name",
                    "value": "B"
                  }
                ]
              }
            ],
            "style": null,
            "config": null
          },
          {
            "id": "node_ReduceMax_31",
            "label": "ReduceMax",
            "namespace": "main_graph",
            "subgraphIds": [],
            "attrs": [
              {
                "key": "keepdims",
                "value": "0"
              }
            ],
            "incomingEdges": [
              {
                "sourceNodeId": "node_Range_36",
                "sourceNodeOutputId": "0",
                "targetNodeInputId": "0"
              }
            ],
            "outputsMetadata": [
              {
                "id": "0",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "val_20"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "INT64[]"
                  },
                  {
                    "key": "param_name",
                    "value": "reduced"
                  }
                ]
              }
            ],
            "inputsMetadata": [
              {
                "id": "0",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "arange"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "INT64[s16]"
                  },
                  {
                    "key": "param_name",
                    "value": "data"
                  }
                ]
              }
            ],
            "style": null,
            "config": null
          },
          {
            "id": "node_Add_34",
            "label": "Add",
            "namespace": "main_graph",
            "subgraphIds": [],
            "attrs": [],
            "incomingEdges": [
              {
                "sourceNodeId": "node_ReduceMax_31",
                "sourceNodeOutputId": "0",
                "targetNodeInputId": "0"
              },
              {
                "sourceNodeId": "n0",
                "sourceNodeOutputId": "0",
                "targetNodeInputId": "1"
              }
            ],
            "outputsMetadata": [
              {
                "id": "0",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "val_24"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "INT64[]"
                  },
                  {
                    "key": "param_name",
                    "value": "C"
                  }
                ]
              }
            ],
            "inputsMetadata": [
              {
                "id": "0",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "val_20"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "INT64[]"
                  },
                  {
                    "key": "param_name",
                    "value": "A"
                  }
                ]
              },
              {
                "id": "1",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "diagonal"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "INT64[]"
                  },
                  {
                    "key": "param_name",
                    "value": "B"
                  }
                ]
              }
            ],
            "style": null,
            "config": null
          },
          {
            "id": "node_Constant_35",
            "label": "Constant",
            "namespace": "main_graph",
            "subgraphIds": [],
            "attrs": [
              {
                "key": "__value",
                "value": "0"
              },
              {
                "key": "value_int",
                "value": "0"
              }
            ],
            "incomingEdges": [],
            "outputsMetadata": [
              {
                "id": "0",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "val_28"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "INT64[]"
                  },
                  {
                    "key": "param_name",
                    "value": "output"
                  }
                ]
              }
            ],
            "inputsMetadata": [],
            "style": null,
            "config": null
          },
          {
            "id": "node_Range_37",
            "label": "Range",
            "namespace": "main_graph",
            "subgraphIds": [],
            "attrs": [],
            "incomingEdges": [
              {
                "sourceNodeId": "node_Constant_35",
                "sourceNodeOutputId": "0",
                "targetNodeInputId": "0"
              },
              {
                "sourceNodeId": "node_Add_34",
                "sourceNodeOutputId": "0",
                "targetNodeInputId": "1"
              },
              {
                "sourceNodeId": "n0",
                "sourceNodeOutputId": "0",
                "targetNodeInputId": "2"
              }
            ],
            "outputsMetadata": [
              {
                "id": "0",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "val_30"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "INT64[unk__25]"
                  },
                  {
                    "key": "param_name",
                    "value": "output"
                  }
                ]
              }
            ],
            "inputsMetadata": [
              {
                "id": "0",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "val_28"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "INT64[]"
                  },
                  {
                    "key": "param_name",
                    "value": "start"
                  }
                ]
              },
              {
                "id": "1",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "val_24"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "INT64[]"
                  },
                  {
                    "key": "param_name",
                    "value": "limit"
                  }
                ]
              },
              {
                "id": "2",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "diagonal"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "INT64[]"
                  },
                  {
                    "key": "param_name",
                    "value": "delta"
                  }
                ]
              }
            ],
            "style": null,
            "config": null
          },
          {
            "id": "node_Constant_38",
            "label": "Constant",
            "namespace": "main_graph",
            "subgraphIds": [],
            "attrs": [
              {
                "key": "__value",
                "value": "[-1,1]"
              },
              {
                "key": "value_ints",
                "value": "[-1, 1]"
              }
            ],
            "incomingEdges": [],
            "outputsMetadata": [
              {
                "id": "0",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "val_31"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "INT64[2]"
                  },
                  {
                    "key": "param_name",
                    "value": "output"
                  }
                ]
              }
            ],
            "inputsMetadata": [],
            "style": null,
            "config": null
          },
          {
            "id": "node_Reshape_39",
            "label": "Reshape",
            "namespace": "main_graph",
            "subgraphIds": [],
            "attrs": [],
            "incomingEdges": [
              {
                "sourceNodeId": "node_Range_37",
                "sourceNodeOutputId": "0",
                "targetNodeInputId": "0"
              },
              {
                "sourceNodeId": "node_Constant_38",
                "sourceNodeOutputId": "0",
                "targetNodeInputId": "1"
              }
            ],
            "outputsMetadata": [
              {
                "id": "0",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "val_32"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "INT64[unk__26,1]"
                  },
                  {
                    "key": "param_name",
                    "value": "reshaped"
                  }
                ]
              }
            ],
            "inputsMetadata": [
              {
                "id": "0",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "val_30"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "INT64[unk__25]"
                  },
                  {
                    "key": "param_name",
                    "value": "data"
                  }
                ]
              },
              {
                "id": "1",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "val_31"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "INT64[2]"
                  },
                  {
                    "key": "param_name",
                    "value": "shape"
                  }
                ]
              }
            ],
            "style": null,
            "config": null
          },
          {
            "id": "node_Cast_40",
            "label": "Cast",
            "namespace": "main_graph",
            "subgraphIds": [],
            "attrs": [
              {
                "key": "to",
                "value": "FLOAT"
              }
            ],
            "incomingEdges": [
              {
                "sourceNodeId": "node_Reshape_39",
                "sourceNodeOutputId": "0",
                "targetNodeInputId": "0"
              }
            ],
            "outputsMetadata": [
              {
                "id": "0",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "val_33"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "FLOAT[unk__26,1]"
                  },
                  {
                    "key": "param_name",
                    "value": "output"
                  }
                ]
              }
            ],
            "inputsMetadata": [
              {
                "id": "0",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "val_32"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "INT64[unk__26,1]"
                  },
                  {
                    "key": "param_name",
                    "value": "input"
                  }
                ]
              }
            ],
            "style": null,
            "config": null
          },
          {
            "id": "node_MatMul_41",
            "label": "MatMul",
            "namespace": "main_graph",
            "subgraphIds": [],
            "attrs": [],
            "incomingEdges": [
              {
                "sourceNodeId": "node_Cast_40",
                "sourceNodeOutputId": "0",
                "targetNodeInputId": "0"
              },
              {
                "sourceNodeId": "[value] val_16",
                "sourceNodeOutputId": "0",
                "targetNodeInputId": "1"
              }
            ],
            "outputsMetadata": [
              {
                "id": "0",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "val_34"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "FLOAT[unk__26,32]"
                  },
                  {
                    "key": "param_name",
                    "value": "Y"
                  }
                ]
              }
            ],
            "inputsMetadata": [
              {
                "id": "0",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "val_33"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "FLOAT[unk__26,1]"
                  },
                  {
                    "key": "param_name",
                    "value": "A"
                  }
                ]
              },
              {
                "id": "1",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "val_16"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "FLOAT[1,32]"
                  },
                  {
                    "key": "param_name",
                    "value": "B"
                  }
                ]
              }
            ],
            "style": null,
            "config": null
          },
          {
            "id": "node_Cos_42",
            "label": "Cos",
            "namespace": "main_graph",
            "subgraphIds": [],
            "attrs": [],
            "incomingEdges": [
              {
                "sourceNodeId": "node_MatMul_41",
                "sourceNodeOutputId": "0",
                "targetNodeInputId": "0"
              }
            ],
            "outputsMetadata": [
              {
                "id": "0",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "val_36"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "FLOAT[unk__26,32]"
                  },
                  {
                    "key": "param_name",
                    "value": "output"
                  }
                ]
              }
            ],
            "inputsMetadata": [
              {
                "id": "0",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "val_34"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "FLOAT[unk__26,32]"
                  },
                  {
                    "key": "param_name",
                    "value": "input"
                  }
                ]
              }
            ],
            "style": null,
            "config": null
          },
          {
            "id": "node_Sin_43",
            "label": "Sin",
            "namespace": "main_graph",
            "subgraphIds": [],
            "attrs": [],
            "incomingEdges": [
              {
                "sourceNodeId": "node_MatMul_41",
                "sourceNodeOutputId": "0",
                "targetNodeInputId": "0"
              }
            ],
            "outputsMetadata": [
              {
                "id": "0",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "val_37"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "FLOAT[unk__26,32]"
                  },
                  {
                    "key": "param_name",
                    "value": "output"
                  }
                ]
              }
            ],
            "inputsMetadata": [
              {
                "id": "0",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "val_34"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "FLOAT[unk__26,32]"
                  },
                  {
                    "key": "param_name",
                    "value": "input"
                  }
                ]
              }
            ],
            "style": null,
            "config": null
          },
          {
            "id": "node_Constant_921",
            "label": "Constant",
            "namespace": "main_graph/: transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/model.layers.0: transformers.models.llama.modeling_llama.LlamaDecoderLayer/model.layers.0.self_attn: transformers.models.llama.modeling_llama.LlamaAttention/slice_37: aten.slice.Tensor",
            "subgraphIds": [],
            "attrs": [
              {
                "key": "__value",
                "value": "[3]"
              },
              {
                "key": "value",
                "value": "TensorProtoTensor<INT64,[1]>(array([3]), name='val_341')"
              }
            ],
            "incomingEdges": [],
            "outputsMetadata": [
              {
                "id": "0",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "val_341"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "INT64[1]"
                  },
                  {
                    "key": "param_name",
                    "value": "output"
                  }
                ]
              }
            ],
            "inputsMetadata": [],
            "style": null,
            "config": null
          },
          {
            "id": "node_Slice_462",
            "label": "Slice",
            "namespace": "main_graph/: transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/model.layers.0: transformers.models.llama.modeling_llama.LlamaDecoderLayer/model.layers.0.self_attn: transformers.models.llama.modeling_llama.LlamaAttention/slice_37: aten.slice.Tensor",
            "subgraphIds": [],
            "attrs": [
              {
                "key": "[metadata] namespace",
                "value": ": transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/model.layers.0: transformers.models.llama.modeling_llama.LlamaDecoderLayer/model.layers.0.self_attn: transformers.models.llama.modeling_llama.LlamaAttention/slice_37: aten.slice.Tensor"
              },
              {
                "key": "[metadata] pkg.torch.onnx.class_hierarchy",
                "value": "['transformers.models.llama.modeling_llama.LlamaForCausalLM', 'transformers.models.llama.modeling_llama.LlamaModel', 'transformers.models.llama.modeling_llama.LlamaDecoderLayer', 'transformers.models.llama.modeling_llama.LlamaAttention', 'aten.slice.Tensor']"
              },
              {
                "key": "[metadata] pkg.torch.onnx.fx_node",
                "value": "%slice_37 : [num_users=1] = call_function[target=torch.ops.aten.slice.Tensor](args = (%slice_36, 3, None, %add_4), kwargs = {})"
              },
              {
                "key": "[metadata] pkg.torch.onnx.name_scopes",
                "value": "['', 'model', 'model.layers.0', 'model.layers.0.self_attn', 'slice_37']"
              },
              {
                "key": "[metadata] pkg.torch.onnx.stack_trace",
                "value": "File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 688, in forward\n    outputs: BaseModelOutputWithPast = self.model(\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 453, in forward\n    layer_outputs = decoder_layer(\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 308, in forward\n    hidden_states, self_attn_weights = self.self_attn(\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 265, in forward\n    attn_output, attn_weights = attention_interface("
              }
            ],
            "incomingEdges": [
              {
                "sourceNodeId": "node_ScatterND_279",
                "sourceNodeOutputId": "0",
                "targetNodeInputId": "0"
              },
              {
                "sourceNodeId": "node_Constant_118",
                "sourceNodeOutputId": "0",
                "targetNodeInputId": "1"
              },
              {
                "sourceNodeId": "node_Reshape_121",
                "sourceNodeOutputId": "0",
                "targetNodeInputId": "2"
              },
              {
                "sourceNodeId": "node_Constant_921",
                "sourceNodeOutputId": "0",
                "targetNodeInputId": "3"
              },
              {
                "sourceNodeId": "node_Constant_125",
                "sourceNodeOutputId": "0",
                "targetNodeInputId": "4"
              }
            ],
            "outputsMetadata": [
              {
                "id": "0",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "slice_37"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "FLOAT[s34,1,s16,s16 + s17]"
                  },
                  {
                    "key": "param_name",
                    "value": "output"
                  }
                ]
              }
            ],
            "inputsMetadata": [
              {
                "id": "0",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "slice_scatter_2"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "FLOAT[s34,1,s16,s16 + s17]"
                  },
                  {
                    "key": "param_name",
                    "value": "data"
                  }
                ]
              },
              {
                "id": "1",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "val_76"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "INT64[1]"
                  },
                  {
                    "key": "param_name",
                    "value": "starts"
                  }
                ]
              },
              {
                "id": "2",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "val_79"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "INT64[1]"
                  },
                  {
                    "key": "param_name",
                    "value": "ends"
                  }
                ]
              },
              {
                "id": "3",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "val_341"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "INT64[1]"
                  },
                  {
                    "key": "param_name",
                    "value": "axes"
                  }
                ]
              },
              {
                "id": "4",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "val_83"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "INT64[1]"
                  },
                  {
                    "key": "param_name",
                    "value": "steps"
                  }
                ]
              }
            ],
            "style": null,
            "config": null
          },
          {
            "id": "node_Unsqueeze_59",
            "label": "Unsqueeze",
            "namespace": "main_graph",
            "subgraphIds": [],
            "attrs": [],
            "incomingEdges": [
              {
                "sourceNodeId": "node_Range_36",
                "sourceNodeOutputId": "0",
                "targetNodeInputId": "0"
              },
              {
                "sourceNodeId": "node_Constant_118",
                "sourceNodeOutputId": "0",
                "targetNodeInputId": "1"
              }
            ],
            "outputsMetadata": [
              {
                "id": "0",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "val_47"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "INT64[1,s16]"
                  },
                  {
                    "key": "param_name",
                    "value": "expanded"
                  }
                ]
              }
            ],
            "inputsMetadata": [
              {
                "id": "0",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "arange"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "INT64[s16]"
                  },
                  {
                    "key": "param_name",
                    "value": "data"
                  }
                ]
              },
              {
                "id": "1",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "val_76"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "INT64[1]"
                  },
                  {
                    "key": "param_name",
                    "value": "axes"
                  }
                ]
              }
            ],
            "style": null,
            "config": null
          },
          {
            "id": "node_RotaryEmbedding_60",
            "label": "com.microsoft::RotaryEmbedding",
            "namespace": "main_graph",
            "subgraphIds": [],
            "attrs": [],
            "incomingEdges": [
              {
                "sourceNodeId": "node_MatMul_340",
                "sourceNodeOutputId": "0",
                "targetNodeInputId": "0"
              },
              {
                "sourceNodeId": "node_Unsqueeze_59",
                "sourceNodeOutputId": "0",
                "targetNodeInputId": "1"
              },
              {
                "sourceNodeId": "node_Cos_42",
                "sourceNodeOutputId": "0",
                "targetNodeInputId": "2"
              },
              {
                "sourceNodeId": "node_Sin_43",
                "sourceNodeOutputId": "0",
                "targetNodeInputId": "3"
              }
            ],
            "outputsMetadata": [
              {
                "id": "0",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "val_48"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "?[?]"
                  }
                ]
              }
            ],
            "inputsMetadata": [
              {
                "id": "0",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "linear"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "FLOAT[s34,s16,2048]"
                  }
                ]
              },
              {
                "id": "1",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "val_47"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "INT64[1,s16]"
                  }
                ]
              },
              {
                "id": "2",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "val_36"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "FLOAT[unk__26,32]"
                  }
                ]
              },
              {
                "id": "3",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "val_37"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "FLOAT[unk__26,32]"
                  }
                ]
              }
            ],
            "style": null,
            "config": null
          },
          {
            "id": "node_RotaryEmbedding_61",
            "label": "com.microsoft::RotaryEmbedding",
            "namespace": "main_graph",
            "subgraphIds": [],
            "attrs": [],
            "incomingEdges": [
              {
                "sourceNodeId": "node_MatMul_351",
                "sourceNodeOutputId": "0",
                "targetNodeInputId": "0"
              },
              {
                "sourceNodeId": "node_Unsqueeze_59",
                "sourceNodeOutputId": "0",
                "targetNodeInputId": "1"
              },
              {
                "sourceNodeId": "node_Cos_42",
                "sourceNodeOutputId": "0",
                "targetNodeInputId": "2"
              },
              {
                "sourceNodeId": "node_Sin_43",
                "sourceNodeOutputId": "0",
                "targetNodeInputId": "3"
              }
            ],
            "outputsMetadata": [
              {
                "id": "0",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "val_49"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "?[?]"
                  }
                ]
              }
            ],
            "inputsMetadata": [
              {
                "id": "0",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "linear_1"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "FLOAT[s34,s16,2048]"
                  }
                ]
              },
              {
                "id": "1",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "val_47"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "INT64[1,s16]"
                  }
                ]
              },
              {
                "id": "2",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "val_36"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "FLOAT[unk__26,32]"
                  }
                ]
              },
              {
                "id": "3",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "val_37"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "FLOAT[unk__26,32]"
                  }
                ]
              }
            ],
            "style": null,
            "config": null
          },
          {
            "id": "node_MultiHeadAttention_62",
            "label": "com.microsoft::MultiHeadAttention",
            "namespace": "main_graph",
            "subgraphIds": [],
            "attrs": [
              {
                "key": "num_heads",
                "value": "32"
              }
            ],
            "incomingEdges": [
              {
                "sourceNodeId": "node_RotaryEmbedding_60",
                "sourceNodeOutputId": "0",
                "targetNodeInputId": "0"
              },
              {
                "sourceNodeId": "node_RotaryEmbedding_61",
                "sourceNodeOutputId": "0",
                "targetNodeInputId": "1"
              },
              {
                "sourceNodeId": "node_MatMul_361",
                "sourceNodeOutputId": "0",
                "targetNodeInputId": "2"
              },
              {
                "sourceNodeId": "node_Slice_462",
                "sourceNodeOutputId": "0",
                "targetNodeInputId": "5"
              },
              {
                "sourceNodeId": "[value] past_key_values_key_cache_0",
                "sourceNodeOutputId": "0",
                "targetNodeInputId": "6"
              },
              {
                "sourceNodeId": "[value] past_key_values_value_cache_0",
                "sourceNodeOutputId": "0",
                "targetNodeInputId": "7"
              }
            ],
            "outputsMetadata": [
              {
                "id": "0",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "view_4"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "FLOAT[s34,s16,2048]"
                  }
                ]
              },
              {
                "id": "1",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "cat_3"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "FLOAT[s34,32,s16 + s17,64]"
                  }
                ]
              },
              {
                "id": "2",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "cat_4"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "FLOAT[s34,32,s16 + s17,64]"
                  }
                ]
              }
            ],
            "inputsMetadata": [
              {
                "id": "0",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "val_48"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "?[?]"
                  }
                ]
              },
              {
                "id": "1",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "val_49"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "?[?]"
                  }
                ]
              },
              {
                "id": "2",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "linear_2"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "FLOAT[s34,s16,2048]"
                  }
                ]
              },
              {
                "id": "3",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "None"
                  }
                ]
              },
              {
                "id": "4",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "None"
                  }
                ]
              },
              {
                "id": "5",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "slice_37"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "FLOAT[s34,1,s16,s16 + s17]"
                  }
                ]
              },
              {
                "id": "6",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "past_key_values_key_cache_0"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "FLOAT[s34,32,s17,64]"
                  },
                  {
                    "key": "[metadata] pkg.torch.export.graph_signature.InputSpec.kind",
                    "value": "USER_INPUT"
                  },
                  {
                    "key": "[metadata] pkg.torch.export.graph_signature.InputSpec.persistent",
                    "value": "None"
                  }
                ]
              },
              {
                "id": "7",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "past_key_values_value_cache_0"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "FLOAT[s34,32,s17,64]"
                  },
                  {
                    "key": "[metadata] pkg.torch.export.graph_signature.InputSpec.kind",
                    "value": "USER_INPUT"
                  },
                  {
                    "key": "[metadata] pkg.torch.export.graph_signature.InputSpec.persistent",
                    "value": "None"
                  }
                ]
              }
            ],
            "style": null,
            "config": null
          },
          {
            "id": "node_MatMul_478",
            "label": "MatMul",
            "namespace": "main_graph/: transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/model.layers.0: transformers.models.llama.modeling_llama.LlamaDecoderLayer/model.layers.0.self_attn: transformers.models.llama.modeling_llama.LlamaAttention/model.layers.0.self_attn.o_proj: torch.nn.modules.linear.Linear/linear_3: aten.linear.default",
            "subgraphIds": [],
            "attrs": [
              {
                "key": "[metadata] namespace",
                "value": ": transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/model.layers.0: transformers.models.llama.modeling_llama.LlamaDecoderLayer/model.layers.0.self_attn: transformers.models.llama.modeling_llama.LlamaAttention/model.layers.0.self_attn.o_proj: torch.nn.modules.linear.Linear/linear_3: aten.linear.default"
              },
              {
                "key": "[metadata] pkg.torch.onnx.class_hierarchy",
                "value": "['transformers.models.llama.modeling_llama.LlamaForCausalLM', 'transformers.models.llama.modeling_llama.LlamaModel', 'transformers.models.llama.modeling_llama.LlamaDecoderLayer', 'transformers.models.llama.modeling_llama.LlamaAttention', 'torch.nn.modules.linear.Linear', 'aten.linear.default']"
              },
              {
                "key": "[metadata] pkg.torch.onnx.fx_node",
                "value": "%linear_3 : [num_users=1] = call_function[target=torch.ops.aten.linear.default](args = (%view_4, %p_model_layers_0_self_attn_o_proj_weight), kwargs = {})"
              },
              {
                "key": "[metadata] pkg.torch.onnx.name_scopes",
                "value": "['', 'model', 'model.layers.0', 'model.layers.0.self_attn', 'model.layers.0.self_attn.o_proj', 'linear_3']"
              },
              {
                "key": "[metadata] pkg.torch.onnx.stack_trace",
                "value": "File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 688, in forward\n    outputs: BaseModelOutputWithPast = self.model(\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 453, in forward\n    layer_outputs = decoder_layer(\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 308, in forward\n    hidden_states, self_attn_weights = self.self_attn(\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 277, in forward\n    attn_output = self.o_proj(attn_output)\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/torch/nn/modules/linear.py\", line 125, in forward\n    return F.linear(input, self.weight, self.bias)"
              }
            ],
            "incomingEdges": [
              {
                "sourceNodeId": "node_MultiHeadAttention_62",
                "sourceNodeOutputId": "0",
                "targetNodeInputId": "0"
              },
              {
                "sourceNodeId": "[value] val_350",
                "sourceNodeOutputId": "0",
                "targetNodeInputId": "1"
              }
            ],
            "outputsMetadata": [
              {
                "id": "0",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "linear_3"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "FLOAT[s34,s16,2048]"
                  },
                  {
                    "key": "param_name",
                    "value": "Y"
                  }
                ]
              }
            ],
            "inputsMetadata": [
              {
                "id": "0",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "view_4"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "FLOAT[s34,s16,2048]"
                  },
                  {
                    "key": "param_name",
                    "value": "A"
                  }
                ]
              },
              {
                "id": "1",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "val_350"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "FLOAT[2048,2048]"
                  },
                  {
                    "key": "param_name",
                    "value": "B"
                  }
                ]
              }
            ],
            "style": null,
            "config": null
          },
          {
            "id": "node_SkipSimplifiedLayerNormalization_21",
            "label": "com.microsoft::SkipSimplifiedLayerNormalization",
            "namespace": "main_graph",
            "subgraphIds": [],
            "attrs": [
              {
                "key": "epsilon",
                "value": "9.999999747378752e-06"
              }
            ],
            "incomingEdges": [
              {
                "sourceNodeId": "node_MatMul_478",
                "sourceNodeOutputId": "0",
                "targetNodeInputId": "0"
              },
              {
                "sourceNodeId": "node_Gather_20",
                "sourceNodeOutputId": "0",
                "targetNodeInputId": "1"
              },
              {
                "sourceNodeId": "[value] model.layers.0.post_attention_layernorm.weight",
                "sourceNodeOutputId": "0",
                "targetNodeInputId": "2"
              }
            ],
            "outputsMetadata": [
              {
                "id": "0",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "mul_352"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "FLOAT[s34,s16,2048]"
                  }
                ]
              },
              {
                "id": "1",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "val_2"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "?[?]"
                  },
                  {
                    "key": "unused",
                    "value": "True"
                  }
                ]
              },
              {
                "id": "2",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "val_3"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "?[?]"
                  },
                  {
                    "key": "unused",
                    "value": "True"
                  }
                ]
              },
              {
                "id": "3",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "add_413"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "FLOAT[s34,s16,2048]"
                  }
                ]
              }
            ],
            "inputsMetadata": [
              {
                "id": "0",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "linear_3"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "FLOAT[s34,s16,2048]"
                  }
                ]
              },
              {
                "id": "1",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "embedding"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "FLOAT[s34,s16,2048]"
                  }
                ]
              },
              {
                "id": "2",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "model.layers.0.post_attention_layernorm.weight"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "FLOAT[2048]"
                  }
                ]
              }
            ],
            "style": null,
            "config": null
          },
          {
            "id": "node_MatMul_491",
            "label": "MatMul",
            "namespace": "main_graph/: transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/model.layers.0: transformers.models.llama.modeling_llama.LlamaDecoderLayer/model.layers.0.mlp: transformers.models.llama.modeling_llama.LlamaMLP/model.layers.0.mlp.gate_proj: torch.nn.modules.linear.Linear/linear_4: aten.linear.default",
            "subgraphIds": [],
            "attrs": [
              {
                "key": "[metadata] namespace",
                "value": ": transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/model.layers.0: transformers.models.llama.modeling_llama.LlamaDecoderLayer/model.layers.0.mlp: transformers.models.llama.modeling_llama.LlamaMLP/model.layers.0.mlp.gate_proj: torch.nn.modules.linear.Linear/linear_4: aten.linear.default"
              },
              {
                "key": "[metadata] pkg.torch.onnx.class_hierarchy",
                "value": "['transformers.models.llama.modeling_llama.LlamaForCausalLM', 'transformers.models.llama.modeling_llama.LlamaModel', 'transformers.models.llama.modeling_llama.LlamaDecoderLayer', 'transformers.models.llama.modeling_llama.LlamaMLP', 'torch.nn.modules.linear.Linear', 'aten.linear.default']"
              },
              {
                "key": "[metadata] pkg.torch.onnx.fx_node",
                "value": "%linear_4 : [num_users=1] = call_function[target=torch.ops.aten.linear.default](args = (%mul_352, %p_model_layers_0_mlp_gate_proj_weight), kwargs = {})"
              },
              {
                "key": "[metadata] pkg.torch.onnx.name_scopes",
                "value": "['', 'model', 'model.layers.0', 'model.layers.0.mlp', 'model.layers.0.mlp.gate_proj', 'linear_4']"
              },
              {
                "key": "[metadata] pkg.torch.onnx.stack_trace",
                "value": "File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 688, in forward\n    outputs: BaseModelOutputWithPast = self.model(\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 453, in forward\n    layer_outputs = decoder_layer(\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 324, in forward\n    hidden_states = self.mlp(hidden_states)\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 162, in forward\n    down_proj = self.down_proj(self.act_fn(self.gate_proj(x)) * self.up_proj(x))\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/torch/nn/modules/linear.py\", line 125, in forward\n    return F.linear(input, self.weight, self.bias)"
              }
            ],
            "incomingEdges": [
              {
                "sourceNodeId": "node_SkipSimplifiedLayerNormalization_21",
                "sourceNodeOutputId": "0",
                "targetNodeInputId": "0"
              },
              {
                "sourceNodeId": "[value] val_355",
                "sourceNodeOutputId": "0",
                "targetNodeInputId": "1"
              }
            ],
            "outputsMetadata": [
              {
                "id": "0",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "linear_4"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "FLOAT[s34,s16,8192]"
                  },
                  {
                    "key": "param_name",
                    "value": "Y"
                  }
                ]
              }
            ],
            "inputsMetadata": [
              {
                "id": "0",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "mul_352"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "FLOAT[s34,s16,2048]"
                  },
                  {
                    "key": "param_name",
                    "value": "A"
                  }
                ]
              },
              {
                "id": "1",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "val_355"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "FLOAT[2048,8192]"
                  },
                  {
                    "key": "param_name",
                    "value": "B"
                  }
                ]
              }
            ],
            "style": null,
            "config": null
          },
          {
            "id": "node_Sigmoid_492",
            "label": "Sigmoid",
            "namespace": "main_graph/: transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/model.layers.0: transformers.models.llama.modeling_llama.LlamaDecoderLayer/model.layers.0.mlp: transformers.models.llama.modeling_llama.LlamaMLP/model.layers.0.mlp.act_fn: torch.nn.modules.activation.SiLU/silu: aten.silu.default",
            "subgraphIds": [],
            "attrs": [
              {
                "key": "[metadata] namespace",
                "value": ": transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/model.layers.0: transformers.models.llama.modeling_llama.LlamaDecoderLayer/model.layers.0.mlp: transformers.models.llama.modeling_llama.LlamaMLP/model.layers.0.mlp.act_fn: torch.nn.modules.activation.SiLU/silu: aten.silu.default"
              },
              {
                "key": "[metadata] pkg.torch.onnx.class_hierarchy",
                "value": "['transformers.models.llama.modeling_llama.LlamaForCausalLM', 'transformers.models.llama.modeling_llama.LlamaModel', 'transformers.models.llama.modeling_llama.LlamaDecoderLayer', 'transformers.models.llama.modeling_llama.LlamaMLP', 'torch.nn.modules.activation.SiLU', 'aten.silu.default']"
              },
              {
                "key": "[metadata] pkg.torch.onnx.fx_node",
                "value": "%silu : [num_users=1] = call_function[target=torch.ops.aten.silu.default](args = (%linear_4,), kwargs = {})"
              },
              {
                "key": "[metadata] pkg.torch.onnx.name_scopes",
                "value": "['', 'model', 'model.layers.0', 'model.layers.0.mlp', 'model.layers.0.mlp.act_fn', 'silu']"
              },
              {
                "key": "[metadata] pkg.torch.onnx.stack_trace",
                "value": "File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 688, in forward\n    outputs: BaseModelOutputWithPast = self.model(\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 453, in forward\n    layer_outputs = decoder_layer(\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 324, in forward\n    hidden_states = self.mlp(hidden_states)\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 162, in forward\n    down_proj = self.down_proj(self.act_fn(self.gate_proj(x)) * self.up_proj(x))\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/torch/nn/modules/activation.py\", line 434, in forward\n    return F.silu(input, inplace=self.inplace)"
              }
            ],
            "incomingEdges": [
              {
                "sourceNodeId": "node_MatMul_491",
                "sourceNodeOutputId": "0",
                "targetNodeInputId": "0"
              }
            ],
            "outputsMetadata": [
              {
                "id": "0",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "val_356"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "FLOAT[s34,s16,8192]"
                  },
                  {
                    "key": "param_name",
                    "value": "Y"
                  }
                ]
              }
            ],
            "inputsMetadata": [
              {
                "id": "0",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "linear_4"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "FLOAT[s34,s16,8192]"
                  },
                  {
                    "key": "param_name",
                    "value": "X"
                  }
                ]
              }
            ],
            "style": null,
            "config": null
          },
          {
            "id": "node_Mul_493",
            "label": "Mul",
            "namespace": "main_graph/: transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/model.layers.0: transformers.models.llama.modeling_llama.LlamaDecoderLayer/model.layers.0.mlp: transformers.models.llama.modeling_llama.LlamaMLP/model.layers.0.mlp.act_fn: torch.nn.modules.activation.SiLU/silu: aten.silu.default",
            "subgraphIds": [],
            "attrs": [
              {
                "key": "[metadata] namespace",
                "value": ": transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/model.layers.0: transformers.models.llama.modeling_llama.LlamaDecoderLayer/model.layers.0.mlp: transformers.models.llama.modeling_llama.LlamaMLP/model.layers.0.mlp.act_fn: torch.nn.modules.activation.SiLU/silu: aten.silu.default"
              },
              {
                "key": "[metadata] pkg.torch.onnx.class_hierarchy",
                "value": "['transformers.models.llama.modeling_llama.LlamaForCausalLM', 'transformers.models.llama.modeling_llama.LlamaModel', 'transformers.models.llama.modeling_llama.LlamaDecoderLayer', 'transformers.models.llama.modeling_llama.LlamaMLP', 'torch.nn.modules.activation.SiLU', 'aten.silu.default']"
              },
              {
                "key": "[metadata] pkg.torch.onnx.fx_node",
                "value": "%silu : [num_users=1] = call_function[target=torch.ops.aten.silu.default](args = (%linear_4,), kwargs = {})"
              },
              {
                "key": "[metadata] pkg.torch.onnx.name_scopes",
                "value": "['', 'model', 'model.layers.0', 'model.layers.0.mlp', 'model.layers.0.mlp.act_fn', 'silu']"
              },
              {
                "key": "[metadata] pkg.torch.onnx.stack_trace",
                "value": "File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 688, in forward\n    outputs: BaseModelOutputWithPast = self.model(\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 453, in forward\n    layer_outputs = decoder_layer(\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 324, in forward\n    hidden_states = self.mlp(hidden_states)\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 162, in forward\n    down_proj = self.down_proj(self.act_fn(self.gate_proj(x)) * self.up_proj(x))\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/torch/nn/modules/activation.py\", line 434, in forward\n    return F.silu(input, inplace=self.inplace)"
              }
            ],
            "incomingEdges": [
              {
                "sourceNodeId": "node_MatMul_491",
                "sourceNodeOutputId": "0",
                "targetNodeInputId": "0"
              },
              {
                "sourceNodeId": "node_Sigmoid_492",
                "sourceNodeOutputId": "0",
                "targetNodeInputId": "1"
              }
            ],
            "outputsMetadata": [
              {
                "id": "0",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "silu"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "FLOAT[s34,s16,8192]"
                  },
                  {
                    "key": "param_name",
                    "value": "C"
                  }
                ]
              }
            ],
            "inputsMetadata": [
              {
                "id": "0",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "linear_4"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "FLOAT[s34,s16,8192]"
                  },
                  {
                    "key": "param_name",
                    "value": "A"
                  }
                ]
              },
              {
                "id": "1",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "val_356"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "FLOAT[s34,s16,8192]"
                  },
                  {
                    "key": "param_name",
                    "value": "B"
                  }
                ]
              }
            ],
            "style": null,
            "config": null
          },
          {
            "id": "node_MatMul_495",
            "label": "MatMul",
            "namespace": "main_graph/: transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/model.layers.0: transformers.models.llama.modeling_llama.LlamaDecoderLayer/model.layers.0.mlp: transformers.models.llama.modeling_llama.LlamaMLP/model.layers.0.mlp.up_proj: torch.nn.modules.linear.Linear/linear_5: aten.linear.default",
            "subgraphIds": [],
            "attrs": [
              {
                "key": "[metadata] namespace",
                "value": ": transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/model.layers.0: transformers.models.llama.modeling_llama.LlamaDecoderLayer/model.layers.0.mlp: transformers.models.llama.modeling_llama.LlamaMLP/model.layers.0.mlp.up_proj: torch.nn.modules.linear.Linear/linear_5: aten.linear.default"
              },
              {
                "key": "[metadata] pkg.torch.onnx.class_hierarchy",
                "value": "['transformers.models.llama.modeling_llama.LlamaForCausalLM', 'transformers.models.llama.modeling_llama.LlamaModel', 'transformers.models.llama.modeling_llama.LlamaDecoderLayer', 'transformers.models.llama.modeling_llama.LlamaMLP', 'torch.nn.modules.linear.Linear', 'aten.linear.default']"
              },
              {
                "key": "[metadata] pkg.torch.onnx.fx_node",
                "value": "%linear_5 : [num_users=1] = call_function[target=torch.ops.aten.linear.default](args = (%mul_352, %p_model_layers_0_mlp_up_proj_weight), kwargs = {})"
              },
              {
                "key": "[metadata] pkg.torch.onnx.name_scopes",
                "value": "['', 'model', 'model.layers.0', 'model.layers.0.mlp', 'model.layers.0.mlp.up_proj', 'linear_5']"
              },
              {
                "key": "[metadata] pkg.torch.onnx.stack_trace",
                "value": "File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 688, in forward\n    outputs: BaseModelOutputWithPast = self.model(\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 453, in forward\n    layer_outputs = decoder_layer(\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 324, in forward\n    hidden_states = self.mlp(hidden_states)\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 162, in forward\n    down_proj = self.down_proj(self.act_fn(self.gate_proj(x)) * self.up_proj(x))\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/torch/nn/modules/linear.py\", line 125, in forward\n    return F.linear(input, self.weight, self.bias)"
              }
            ],
            "incomingEdges": [
              {
                "sourceNodeId": "node_SkipSimplifiedLayerNormalization_21",
                "sourceNodeOutputId": "0",
                "targetNodeInputId": "0"
              },
              {
                "sourceNodeId": "[value] val_357",
                "sourceNodeOutputId": "0",
                "targetNodeInputId": "1"
              }
            ],
            "outputsMetadata": [
              {
                "id": "0",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "linear_5"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "FLOAT[s34,s16,8192]"
                  },
                  {
                    "key": "param_name",
                    "value": "Y"
                  }
                ]
              }
            ],
            "inputsMetadata": [
              {
                "id": "0",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "mul_352"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "FLOAT[s34,s16,2048]"
                  },
                  {
                    "key": "param_name",
                    "value": "A"
                  }
                ]
              },
              {
                "id": "1",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "val_357"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "FLOAT[2048,8192]"
                  },
                  {
                    "key": "param_name",
                    "value": "B"
                  }
                ]
              }
            ],
            "style": null,
            "config": null
          },
          {
            "id": "node_Mul_496",
            "label": "Mul",
            "namespace": "main_graph/: transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/model.layers.0: transformers.models.llama.modeling_llama.LlamaDecoderLayer/model.layers.0.mlp: transformers.models.llama.modeling_llama.LlamaMLP/mul_365: aten.mul.Tensor",
            "subgraphIds": [],
            "attrs": [
              {
                "key": "[metadata] namespace",
                "value": ": transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/model.layers.0: transformers.models.llama.modeling_llama.LlamaDecoderLayer/model.layers.0.mlp: transformers.models.llama.modeling_llama.LlamaMLP/mul_365: aten.mul.Tensor"
              },
              {
                "key": "[metadata] pkg.torch.onnx.class_hierarchy",
                "value": "['transformers.models.llama.modeling_llama.LlamaForCausalLM', 'transformers.models.llama.modeling_llama.LlamaModel', 'transformers.models.llama.modeling_llama.LlamaDecoderLayer', 'transformers.models.llama.modeling_llama.LlamaMLP', 'aten.mul.Tensor']"
              },
              {
                "key": "[metadata] pkg.torch.onnx.fx_node",
                "value": "%mul_365 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%silu, %linear_5), kwargs = {})"
              },
              {
                "key": "[metadata] pkg.torch.onnx.name_scopes",
                "value": "['', 'model', 'model.layers.0', 'model.layers.0.mlp', 'mul_365']"
              },
              {
                "key": "[metadata] pkg.torch.onnx.stack_trace",
                "value": "File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 688, in forward\n    outputs: BaseModelOutputWithPast = self.model(\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 453, in forward\n    layer_outputs = decoder_layer(\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 324, in forward\n    hidden_states = self.mlp(hidden_states)\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 162, in forward\n    down_proj = self.down_proj(self.act_fn(self.gate_proj(x)) * self.up_proj(x))"
              }
            ],
            "incomingEdges": [
              {
                "sourceNodeId": "node_Mul_493",
                "sourceNodeOutputId": "0",
                "targetNodeInputId": "0"
              },
              {
                "sourceNodeId": "node_MatMul_495",
                "sourceNodeOutputId": "0",
                "targetNodeInputId": "1"
              }
            ],
            "outputsMetadata": [
              {
                "id": "0",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "mul_365"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "FLOAT[s34,s16,8192]"
                  },
                  {
                    "key": "param_name",
                    "value": "C"
                  }
                ]
              }
            ],
            "inputsMetadata": [
              {
                "id": "0",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "silu"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "FLOAT[s34,s16,8192]"
                  },
                  {
                    "key": "param_name",
                    "value": "A"
                  }
                ]
              },
              {
                "id": "1",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "linear_5"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "FLOAT[s34,s16,8192]"
                  },
                  {
                    "key": "param_name",
                    "value": "B"
                  }
                ]
              }
            ],
            "style": null,
            "config": null
          },
          {
            "id": "node_MatMul_498",
            "label": "MatMul",
            "namespace": "main_graph/: transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/model.layers.0: transformers.models.llama.modeling_llama.LlamaDecoderLayer/model.layers.0.mlp: transformers.models.llama.modeling_llama.LlamaMLP/model.layers.0.mlp.down_proj: torch.nn.modules.linear.Linear/linear_6: aten.linear.default",
            "subgraphIds": [],
            "attrs": [
              {
                "key": "[metadata] namespace",
                "value": ": transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/model.layers.0: transformers.models.llama.modeling_llama.LlamaDecoderLayer/model.layers.0.mlp: transformers.models.llama.modeling_llama.LlamaMLP/model.layers.0.mlp.down_proj: torch.nn.modules.linear.Linear/linear_6: aten.linear.default"
              },
              {
                "key": "[metadata] pkg.torch.onnx.class_hierarchy",
                "value": "['transformers.models.llama.modeling_llama.LlamaForCausalLM', 'transformers.models.llama.modeling_llama.LlamaModel', 'transformers.models.llama.modeling_llama.LlamaDecoderLayer', 'transformers.models.llama.modeling_llama.LlamaMLP', 'torch.nn.modules.linear.Linear', 'aten.linear.default']"
              },
              {
                "key": "[metadata] pkg.torch.onnx.fx_node",
                "value": "%linear_6 : [num_users=1] = call_function[target=torch.ops.aten.linear.default](args = (%mul_365, %p_model_layers_0_mlp_down_proj_weight), kwargs = {})"
              },
              {
                "key": "[metadata] pkg.torch.onnx.name_scopes",
                "value": "['', 'model', 'model.layers.0', 'model.layers.0.mlp', 'model.layers.0.mlp.down_proj', 'linear_6']"
              },
              {
                "key": "[metadata] pkg.torch.onnx.stack_trace",
                "value": "File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 688, in forward\n    outputs: BaseModelOutputWithPast = self.model(\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 453, in forward\n    layer_outputs = decoder_layer(\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 324, in forward\n    hidden_states = self.mlp(hidden_states)\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 162, in forward\n    down_proj = self.down_proj(self.act_fn(self.gate_proj(x)) * self.up_proj(x))\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/torch/nn/modules/linear.py\", line 125, in forward\n    return F.linear(input, self.weight, self.bias)"
              }
            ],
            "incomingEdges": [
              {
                "sourceNodeId": "node_Mul_496",
                "sourceNodeOutputId": "0",
                "targetNodeInputId": "0"
              },
              {
                "sourceNodeId": "[value] val_358",
                "sourceNodeOutputId": "0",
                "targetNodeInputId": "1"
              }
            ],
            "outputsMetadata": [
              {
                "id": "0",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "linear_6"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "FLOAT[s34,s16,2048]"
                  },
                  {
                    "key": "param_name",
                    "value": "Y"
                  }
                ]
              }
            ],
            "inputsMetadata": [
              {
                "id": "0",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "mul_365"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "FLOAT[s34,s16,8192]"
                  },
                  {
                    "key": "param_name",
                    "value": "A"
                  }
                ]
              },
              {
                "id": "1",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "val_358"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "FLOAT[8192,2048]"
                  },
                  {
                    "key": "param_name",
                    "value": "B"
                  }
                ]
              }
            ],
            "style": null,
            "config": null
          },
          {
            "id": "node_SkipSimplifiedLayerNormalization_22",
            "label": "com.microsoft::SkipSimplifiedLayerNormalization",
            "namespace": "main_graph",
            "subgraphIds": [],
            "attrs": [
              {
                "key": "epsilon",
                "value": "9.999999747378752e-06"
              }
            ],
            "incomingEdges": [
              {
                "sourceNodeId": "node_MatMul_498",
                "sourceNodeOutputId": "0",
                "targetNodeInputId": "0"
              },
              {
                "sourceNodeId": "node_SkipSimplifiedLayerNormalization_21",
                "sourceNodeOutputId": "3",
                "targetNodeInputId": "1"
              },
              {
                "sourceNodeId": "[value] model.layers.1.input_layernorm.weight",
                "sourceNodeOutputId": "0",
                "targetNodeInputId": "2"
              }
            ],
            "outputsMetadata": [
              {
                "id": "0",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "mul_388"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "FLOAT[s34,s16,2048]"
                  }
                ]
              },
              {
                "id": "1",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "val_4"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "?[?]"
                  },
                  {
                    "key": "unused",
                    "value": "True"
                  }
                ]
              },
              {
                "id": "2",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "val_7"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "?[?]"
                  },
                  {
                    "key": "unused",
                    "value": "True"
                  }
                ]
              },
              {
                "id": "3",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "add_463"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "FLOAT[s34,s16,2048]"
                  }
                ]
              }
            ],
            "inputsMetadata": [
              {
                "id": "0",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "linear_6"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "FLOAT[s34,s16,2048]"
                  }
                ]
              },
              {
                "id": "1",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "add_413"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "FLOAT[s34,s16,2048]"
                  }
                ]
              },
              {
                "id": "2",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "model.layers.1.input_layernorm.weight"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "FLOAT[2048]"
                  }
                ]
              }
            ],
            "style": null,
            "config": null
          },
          {
            "id": "node_MatMul_511",
            "label": "MatMul",
            "namespace": "main_graph/: transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/model.layers.1: transformers.models.llama.modeling_llama.LlamaDecoderLayer/model.layers.1.self_attn: transformers.models.llama.modeling_llama.LlamaAttention/model.layers.1.self_attn.q_proj: torch.nn.modules.linear.Linear/linear_7: aten.linear.default",
            "subgraphIds": [],
            "attrs": [
              {
                "key": "[metadata] namespace",
                "value": ": transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/model.layers.1: transformers.models.llama.modeling_llama.LlamaDecoderLayer/model.layers.1.self_attn: transformers.models.llama.modeling_llama.LlamaAttention/model.layers.1.self_attn.q_proj: torch.nn.modules.linear.Linear/linear_7: aten.linear.default"
              },
              {
                "key": "[metadata] pkg.torch.onnx.class_hierarchy",
                "value": "['transformers.models.llama.modeling_llama.LlamaForCausalLM', 'transformers.models.llama.modeling_llama.LlamaModel', 'transformers.models.llama.modeling_llama.LlamaDecoderLayer', 'transformers.models.llama.modeling_llama.LlamaAttention', 'torch.nn.modules.linear.Linear', 'aten.linear.default']"
              },
              {
                "key": "[metadata] pkg.torch.onnx.fx_node",
                "value": "%linear_7 : [num_users=1] = call_function[target=torch.ops.aten.linear.default](args = (%mul_388, %p_model_layers_1_self_attn_q_proj_weight), kwargs = {})"
              },
              {
                "key": "[metadata] pkg.torch.onnx.name_scopes",
                "value": "['', 'model', 'model.layers.1', 'model.layers.1.self_attn', 'model.layers.1.self_attn.q_proj', 'linear_7']"
              },
              {
                "key": "[metadata] pkg.torch.onnx.stack_trace",
                "value": "File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 688, in forward\n    outputs: BaseModelOutputWithPast = self.model(\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 453, in forward\n    layer_outputs = decoder_layer(\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 308, in forward\n    hidden_states, self_attn_weights = self.self_attn(\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 242, in forward\n    query_states = self.q_proj(hidden_states).view(hidden_shape).transpose(1, 2)\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/torch/nn/modules/linear.py\", line 125, in forward\n    return F.linear(input, self.weight, self.bias)"
              }
            ],
            "incomingEdges": [
              {
                "sourceNodeId": "node_SkipSimplifiedLayerNormalization_22",
                "sourceNodeOutputId": "0",
                "targetNodeInputId": "0"
              },
              {
                "sourceNodeId": "[value] val_363",
                "sourceNodeOutputId": "0",
                "targetNodeInputId": "1"
              }
            ],
            "outputsMetadata": [
              {
                "id": "0",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "linear_7"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "FLOAT[s34,s16,2048]"
                  },
                  {
                    "key": "param_name",
                    "value": "Y"
                  }
                ]
              }
            ],
            "inputsMetadata": [
              {
                "id": "0",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "mul_388"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "FLOAT[s34,s16,2048]"
                  },
                  {
                    "key": "param_name",
                    "value": "A"
                  }
                ]
              },
              {
                "id": "1",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "val_363"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "FLOAT[2048,2048]"
                  },
                  {
                    "key": "param_name",
                    "value": "B"
                  }
                ]
              }
            ],
            "style": null,
            "config": null
          },
          {
            "id": "node_MatMul_521",
            "label": "MatMul",
            "namespace": "main_graph/: transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/model.layers.1: transformers.models.llama.modeling_llama.LlamaDecoderLayer/model.layers.1.self_attn: transformers.models.llama.modeling_llama.LlamaAttention/model.layers.1.self_attn.k_proj: torch.nn.modules.linear.Linear/linear_8: aten.linear.default",
            "subgraphIds": [],
            "attrs": [
              {
                "key": "[metadata] namespace",
                "value": ": transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/model.layers.1: transformers.models.llama.modeling_llama.LlamaDecoderLayer/model.layers.1.self_attn: transformers.models.llama.modeling_llama.LlamaAttention/model.layers.1.self_attn.k_proj: torch.nn.modules.linear.Linear/linear_8: aten.linear.default"
              },
              {
                "key": "[metadata] pkg.torch.onnx.class_hierarchy",
                "value": "['transformers.models.llama.modeling_llama.LlamaForCausalLM', 'transformers.models.llama.modeling_llama.LlamaModel', 'transformers.models.llama.modeling_llama.LlamaDecoderLayer', 'transformers.models.llama.modeling_llama.LlamaAttention', 'torch.nn.modules.linear.Linear', 'aten.linear.default']"
              },
              {
                "key": "[metadata] pkg.torch.onnx.fx_node",
                "value": "%linear_8 : [num_users=1] = call_function[target=torch.ops.aten.linear.default](args = (%mul_388, %p_model_layers_1_self_attn_k_proj_weight), kwargs = {})"
              },
              {
                "key": "[metadata] pkg.torch.onnx.name_scopes",
                "value": "['', 'model', 'model.layers.1', 'model.layers.1.self_attn', 'model.layers.1.self_attn.k_proj', 'linear_8']"
              },
              {
                "key": "[metadata] pkg.torch.onnx.stack_trace",
                "value": "File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 688, in forward\n    outputs: BaseModelOutputWithPast = self.model(\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 453, in forward\n    layer_outputs = decoder_layer(\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 308, in forward\n    hidden_states, self_attn_weights = self.self_attn(\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 243, in forward\n    key_states = self.k_proj(hidden_states).view(hidden_shape).transpose(1, 2)\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/torch/nn/modules/linear.py\", line 125, in forward\n    return F.linear(input, self.weight, self.bias)"
              }
            ],
            "incomingEdges": [
              {
                "sourceNodeId": "node_SkipSimplifiedLayerNormalization_22",
                "sourceNodeOutputId": "0",
                "targetNodeInputId": "0"
              },
              {
                "sourceNodeId": "[value] val_370",
                "sourceNodeOutputId": "0",
                "targetNodeInputId": "1"
              }
            ],
            "outputsMetadata": [
              {
                "id": "0",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "linear_8"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "FLOAT[s34,s16,2048]"
                  },
                  {
                    "key": "param_name",
                    "value": "Y"
                  }
                ]
              }
            ],
            "inputsMetadata": [
              {
                "id": "0",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "mul_388"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "FLOAT[s34,s16,2048]"
                  },
                  {
                    "key": "param_name",
                    "value": "A"
                  }
                ]
              },
              {
                "id": "1",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "val_370"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "FLOAT[2048,2048]"
                  },
                  {
                    "key": "param_name",
                    "value": "B"
                  }
                ]
              }
            ],
            "style": null,
            "config": null
          },
          {
            "id": "node_MatMul_531",
            "label": "MatMul",
            "namespace": "main_graph/: transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/model.layers.1: transformers.models.llama.modeling_llama.LlamaDecoderLayer/model.layers.1.self_attn: transformers.models.llama.modeling_llama.LlamaAttention/model.layers.1.self_attn.v_proj: torch.nn.modules.linear.Linear/linear_9: aten.linear.default",
            "subgraphIds": [],
            "attrs": [
              {
                "key": "[metadata] namespace",
                "value": ": transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/model.layers.1: transformers.models.llama.modeling_llama.LlamaDecoderLayer/model.layers.1.self_attn: transformers.models.llama.modeling_llama.LlamaAttention/model.layers.1.self_attn.v_proj: torch.nn.modules.linear.Linear/linear_9: aten.linear.default"
              },
              {
                "key": "[metadata] pkg.torch.onnx.class_hierarchy",
                "value": "['transformers.models.llama.modeling_llama.LlamaForCausalLM', 'transformers.models.llama.modeling_llama.LlamaModel', 'transformers.models.llama.modeling_llama.LlamaDecoderLayer', 'transformers.models.llama.modeling_llama.LlamaAttention', 'torch.nn.modules.linear.Linear', 'aten.linear.default']"
              },
              {
                "key": "[metadata] pkg.torch.onnx.fx_node",
                "value": "%linear_9 : [num_users=1] = call_function[target=torch.ops.aten.linear.default](args = (%mul_388, %p_model_layers_1_self_attn_v_proj_weight), kwargs = {})"
              },
              {
                "key": "[metadata] pkg.torch.onnx.name_scopes",
                "value": "['', 'model', 'model.layers.1', 'model.layers.1.self_attn', 'model.layers.1.self_attn.v_proj', 'linear_9']"
              },
              {
                "key": "[metadata] pkg.torch.onnx.stack_trace",
                "value": "File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 688, in forward\n    outputs: BaseModelOutputWithPast = self.model(\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 453, in forward\n    layer_outputs = decoder_layer(\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 308, in forward\n    hidden_states, self_attn_weights = self.self_attn(\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 244, in forward\n    value_states = self.v_proj(hidden_states).view(hidden_shape).transpose(1, 2)\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/torch/nn/modules/linear.py\", line 125, in forward\n    return F.linear(input, self.weight, self.bias)"
              }
            ],
            "incomingEdges": [
              {
                "sourceNodeId": "node_SkipSimplifiedLayerNormalization_22",
                "sourceNodeOutputId": "0",
                "targetNodeInputId": "0"
              },
              {
                "sourceNodeId": "[value] val_377",
                "sourceNodeOutputId": "0",
                "targetNodeInputId": "1"
              }
            ],
            "outputsMetadata": [
              {
                "id": "0",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "linear_9"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "FLOAT[s34,s16,2048]"
                  },
                  {
                    "key": "param_name",
                    "value": "Y"
                  }
                ]
              }
            ],
            "inputsMetadata": [
              {
                "id": "0",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "mul_388"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "FLOAT[s34,s16,2048]"
                  },
                  {
                    "key": "param_name",
                    "value": "A"
                  }
                ]
              },
              {
                "id": "1",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "val_377"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "FLOAT[2048,2048]"
                  },
                  {
                    "key": "param_name",
                    "value": "B"
                  }
                ]
              }
            ],
            "style": null,
            "config": null
          },
          {
            "id": "node_Constant_977",
            "label": "Constant",
            "namespace": "main_graph/: transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/model.layers.1: transformers.models.llama.modeling_llama.LlamaDecoderLayer/model.layers.1.self_attn: transformers.models.llama.modeling_llama.LlamaAttention/slice_49: aten.slice.Tensor",
            "subgraphIds": [],
            "attrs": [
              {
                "key": "__value",
                "value": "[3]"
              },
              {
                "key": "value",
                "value": "TensorProtoTensor<INT64,[1]>(array([3]), name='val_448')"
              }
            ],
            "incomingEdges": [],
            "outputsMetadata": [
              {
                "id": "0",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "val_448"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "INT64[1]"
                  },
                  {
                    "key": "param_name",
                    "value": "output"
                  }
                ]
              }
            ],
            "inputsMetadata": [],
            "style": null,
            "config": null
          },
          {
            "id": "node_Slice_630",
            "label": "Slice",
            "namespace": "main_graph/: transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/model.layers.1: transformers.models.llama.modeling_llama.LlamaDecoderLayer/model.layers.1.self_attn: transformers.models.llama.modeling_llama.LlamaAttention/slice_49: aten.slice.Tensor",
            "subgraphIds": [],
            "attrs": [
              {
                "key": "[metadata] namespace",
                "value": ": transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/model.layers.1: transformers.models.llama.modeling_llama.LlamaDecoderLayer/model.layers.1.self_attn: transformers.models.llama.modeling_llama.LlamaAttention/slice_49: aten.slice.Tensor"
              },
              {
                "key": "[metadata] pkg.torch.onnx.class_hierarchy",
                "value": "['transformers.models.llama.modeling_llama.LlamaForCausalLM', 'transformers.models.llama.modeling_llama.LlamaModel', 'transformers.models.llama.modeling_llama.LlamaDecoderLayer', 'transformers.models.llama.modeling_llama.LlamaAttention', 'aten.slice.Tensor']"
              },
              {
                "key": "[metadata] pkg.torch.onnx.fx_node",
                "value": "%slice_49 : [num_users=1] = call_function[target=torch.ops.aten.slice.Tensor](args = (%slice_48, 3, None, %add_4), kwargs = {})"
              },
              {
                "key": "[metadata] pkg.torch.onnx.name_scopes",
                "value": "['', 'model', 'model.layers.1', 'model.layers.1.self_attn', 'slice_49']"
              },
              {
                "key": "[metadata] pkg.torch.onnx.stack_trace",
                "value": "File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 688, in forward\n    outputs: BaseModelOutputWithPast = self.model(\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 453, in forward\n    layer_outputs = decoder_layer(\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 308, in forward\n    hidden_states, self_attn_weights = self.self_attn(\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 265, in forward\n    attn_output, attn_weights = attention_interface("
              }
            ],
            "incomingEdges": [
              {
                "sourceNodeId": "node_ScatterND_279",
                "sourceNodeOutputId": "0",
                "targetNodeInputId": "0"
              },
              {
                "sourceNodeId": "node_Constant_118",
                "sourceNodeOutputId": "0",
                "targetNodeInputId": "1"
              },
              {
                "sourceNodeId": "node_Reshape_121",
                "sourceNodeOutputId": "0",
                "targetNodeInputId": "2"
              },
              {
                "sourceNodeId": "node_Constant_977",
                "sourceNodeOutputId": "0",
                "targetNodeInputId": "3"
              },
              {
                "sourceNodeId": "node_Constant_125",
                "sourceNodeOutputId": "0",
                "targetNodeInputId": "4"
              }
            ],
            "outputsMetadata": [
              {
                "id": "0",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "slice_49"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "FLOAT[s34,1,s16,s16 + s17]"
                  },
                  {
                    "key": "param_name",
                    "value": "output"
                  }
                ]
              }
            ],
            "inputsMetadata": [
              {
                "id": "0",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "slice_scatter_2"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "FLOAT[s34,1,s16,s16 + s17]"
                  },
                  {
                    "key": "param_name",
                    "value": "data"
                  }
                ]
              },
              {
                "id": "1",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "val_76"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "INT64[1]"
                  },
                  {
                    "key": "param_name",
                    "value": "starts"
                  }
                ]
              },
              {
                "id": "2",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "val_79"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "INT64[1]"
                  },
                  {
                    "key": "param_name",
                    "value": "ends"
                  }
                ]
              },
              {
                "id": "3",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "val_448"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "INT64[1]"
                  },
                  {
                    "key": "param_name",
                    "value": "axes"
                  }
                ]
              },
              {
                "id": "4",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "val_83"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "INT64[1]"
                  },
                  {
                    "key": "param_name",
                    "value": "steps"
                  }
                ]
              }
            ],
            "style": null,
            "config": null
          },
          {
            "id": "node_RotaryEmbedding_65",
            "label": "com.microsoft::RotaryEmbedding",
            "namespace": "main_graph",
            "subgraphIds": [],
            "attrs": [],
            "incomingEdges": [
              {
                "sourceNodeId": "node_MatMul_511",
                "sourceNodeOutputId": "0",
                "targetNodeInputId": "0"
              },
              {
                "sourceNodeId": "node_Unsqueeze_59",
                "sourceNodeOutputId": "0",
                "targetNodeInputId": "1"
              },
              {
                "sourceNodeId": "node_Cos_42",
                "sourceNodeOutputId": "0",
                "targetNodeInputId": "2"
              },
              {
                "sourceNodeId": "node_Sin_43",
                "sourceNodeOutputId": "0",
                "targetNodeInputId": "3"
              }
            ],
            "outputsMetadata": [
              {
                "id": "0",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "val_52"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "?[?]"
                  }
                ]
              }
            ],
            "inputsMetadata": [
              {
                "id": "0",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "linear_7"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "FLOAT[s34,s16,2048]"
                  }
                ]
              },
              {
                "id": "1",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "val_47"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "INT64[1,s16]"
                  }
                ]
              },
              {
                "id": "2",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "val_36"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "FLOAT[unk__26,32]"
                  }
                ]
              },
              {
                "id": "3",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "val_37"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "FLOAT[unk__26,32]"
                  }
                ]
              }
            ],
            "style": null,
            "config": null
          },
          {
            "id": "node_RotaryEmbedding_66",
            "label": "com.microsoft::RotaryEmbedding",
            "namespace": "main_graph",
            "subgraphIds": [],
            "attrs": [],
            "incomingEdges": [
              {
                "sourceNodeId": "node_MatMul_521",
                "sourceNodeOutputId": "0",
                "targetNodeInputId": "0"
              },
              {
                "sourceNodeId": "node_Unsqueeze_59",
                "sourceNodeOutputId": "0",
                "targetNodeInputId": "1"
              },
              {
                "sourceNodeId": "node_Cos_42",
                "sourceNodeOutputId": "0",
                "targetNodeInputId": "2"
              },
              {
                "sourceNodeId": "node_Sin_43",
                "sourceNodeOutputId": "0",
                "targetNodeInputId": "3"
              }
            ],
            "outputsMetadata": [
              {
                "id": "0",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "val_55"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "?[?]"
                  }
                ]
              }
            ],
            "inputsMetadata": [
              {
                "id": "0",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "linear_8"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "FLOAT[s34,s16,2048]"
                  }
                ]
              },
              {
                "id": "1",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "val_47"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "INT64[1,s16]"
                  }
                ]
              },
              {
                "id": "2",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "val_36"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "FLOAT[unk__26,32]"
                  }
                ]
              },
              {
                "id": "3",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "val_37"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "FLOAT[unk__26,32]"
                  }
                ]
              }
            ],
            "style": null,
            "config": null
          },
          {
            "id": "node_MultiHeadAttention_67",
            "label": "com.microsoft::MultiHeadAttention",
            "namespace": "main_graph",
            "subgraphIds": [],
            "attrs": [
              {
                "key": "num_heads",
                "value": "32"
              }
            ],
            "incomingEdges": [
              {
                "sourceNodeId": "node_RotaryEmbedding_65",
                "sourceNodeOutputId": "0",
                "targetNodeInputId": "0"
              },
              {
                "sourceNodeId": "node_RotaryEmbedding_66",
                "sourceNodeOutputId": "0",
                "targetNodeInputId": "1"
              },
              {
                "sourceNodeId": "node_MatMul_531",
                "sourceNodeOutputId": "0",
                "targetNodeInputId": "2"
              },
              {
                "sourceNodeId": "node_Slice_630",
                "sourceNodeOutputId": "0",
                "targetNodeInputId": "5"
              },
              {
                "sourceNodeId": "[value] past_key_values_key_cache_1",
                "sourceNodeOutputId": "0",
                "targetNodeInputId": "6"
              },
              {
                "sourceNodeId": "[value] past_key_values_value_cache_1",
                "sourceNodeOutputId": "0",
                "targetNodeInputId": "7"
              }
            ],
            "outputsMetadata": [
              {
                "id": "0",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "view_8"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "FLOAT[s34,s16,2048]"
                  }
                ]
              },
              {
                "id": "1",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "cat_7"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "FLOAT[s34,32,s16 + s17,64]"
                  }
                ]
              },
              {
                "id": "2",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "cat_8"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "FLOAT[s34,32,s16 + s17,64]"
                  }
                ]
              }
            ],
            "inputsMetadata": [
              {
                "id": "0",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "val_52"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "?[?]"
                  }
                ]
              },
              {
                "id": "1",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "val_55"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "?[?]"
                  }
                ]
              },
              {
                "id": "2",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "linear_9"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "FLOAT[s34,s16,2048]"
                  }
                ]
              },
              {
                "id": "3",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "None"
                  }
                ]
              },
              {
                "id": "4",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "None"
                  }
                ]
              },
              {
                "id": "5",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "slice_49"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "FLOAT[s34,1,s16,s16 + s17]"
                  }
                ]
              },
              {
                "id": "6",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "past_key_values_key_cache_1"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "FLOAT[s34,32,s17,64]"
                  },
                  {
                    "key": "[metadata] pkg.torch.export.graph_signature.InputSpec.kind",
                    "value": "USER_INPUT"
                  },
                  {
                    "key": "[metadata] pkg.torch.export.graph_signature.InputSpec.persistent",
                    "value": "None"
                  }
                ]
              },
              {
                "id": "7",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "past_key_values_value_cache_1"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "FLOAT[s34,32,s17,64]"
                  },
                  {
                    "key": "[metadata] pkg.torch.export.graph_signature.InputSpec.kind",
                    "value": "USER_INPUT"
                  },
                  {
                    "key": "[metadata] pkg.torch.export.graph_signature.InputSpec.persistent",
                    "value": "None"
                  }
                ]
              }
            ],
            "style": null,
            "config": null
          },
          {
            "id": "node_MatMul_646",
            "label": "MatMul",
            "namespace": "main_graph/: transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/model.layers.1: transformers.models.llama.modeling_llama.LlamaDecoderLayer/model.layers.1.self_attn: transformers.models.llama.modeling_llama.LlamaAttention/model.layers.1.self_attn.o_proj: torch.nn.modules.linear.Linear/linear_10: aten.linear.default",
            "subgraphIds": [],
            "attrs": [
              {
                "key": "[metadata] namespace",
                "value": ": transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/model.layers.1: transformers.models.llama.modeling_llama.LlamaDecoderLayer/model.layers.1.self_attn: transformers.models.llama.modeling_llama.LlamaAttention/model.layers.1.self_attn.o_proj: torch.nn.modules.linear.Linear/linear_10: aten.linear.default"
              },
              {
                "key": "[metadata] pkg.torch.onnx.class_hierarchy",
                "value": "['transformers.models.llama.modeling_llama.LlamaForCausalLM', 'transformers.models.llama.modeling_llama.LlamaModel', 'transformers.models.llama.modeling_llama.LlamaDecoderLayer', 'transformers.models.llama.modeling_llama.LlamaAttention', 'torch.nn.modules.linear.Linear', 'aten.linear.default']"
              },
              {
                "key": "[metadata] pkg.torch.onnx.fx_node",
                "value": "%linear_10 : [num_users=1] = call_function[target=torch.ops.aten.linear.default](args = (%view_8, %p_model_layers_1_self_attn_o_proj_weight), kwargs = {})"
              },
              {
                "key": "[metadata] pkg.torch.onnx.name_scopes",
                "value": "['', 'model', 'model.layers.1', 'model.layers.1.self_attn', 'model.layers.1.self_attn.o_proj', 'linear_10']"
              },
              {
                "key": "[metadata] pkg.torch.onnx.stack_trace",
                "value": "File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 688, in forward\n    outputs: BaseModelOutputWithPast = self.model(\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 453, in forward\n    layer_outputs = decoder_layer(\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 308, in forward\n    hidden_states, self_attn_weights = self.self_attn(\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 277, in forward\n    attn_output = self.o_proj(attn_output)\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/torch/nn/modules/linear.py\", line 125, in forward\n    return F.linear(input, self.weight, self.bias)"
              }
            ],
            "incomingEdges": [
              {
                "sourceNodeId": "node_MultiHeadAttention_67",
                "sourceNodeOutputId": "0",
                "targetNodeInputId": "0"
              },
              {
                "sourceNodeId": "[value] val_457",
                "sourceNodeOutputId": "0",
                "targetNodeInputId": "1"
              }
            ],
            "outputsMetadata": [
              {
                "id": "0",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "linear_10"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "FLOAT[s34,s16,2048]"
                  },
                  {
                    "key": "param_name",
                    "value": "Y"
                  }
                ]
              }
            ],
            "inputsMetadata": [
              {
                "id": "0",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "view_8"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "FLOAT[s34,s16,2048]"
                  },
                  {
                    "key": "param_name",
                    "value": "A"
                  }
                ]
              },
              {
                "id": "1",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "val_457"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "FLOAT[2048,2048]"
                  },
                  {
                    "key": "param_name",
                    "value": "B"
                  }
                ]
              }
            ],
            "style": null,
            "config": null
          },
          {
            "id": "node_SkipSimplifiedLayerNormalization_23",
            "label": "com.microsoft::SkipSimplifiedLayerNormalization",
            "namespace": "main_graph",
            "subgraphIds": [],
            "attrs": [
              {
                "key": "epsilon",
                "value": "9.999999747378752e-06"
              }
            ],
            "incomingEdges": [
              {
                "sourceNodeId": "node_MatMul_646",
                "sourceNodeOutputId": "0",
                "targetNodeInputId": "0"
              },
              {
                "sourceNodeId": "node_SkipSimplifiedLayerNormalization_22",
                "sourceNodeOutputId": "3",
                "targetNodeInputId": "1"
              },
              {
                "sourceNodeId": "[value] model.layers.1.post_attention_layernorm.weight",
                "sourceNodeOutputId": "0",
                "targetNodeInputId": "2"
              }
            ],
            "outputsMetadata": [
              {
                "id": "0",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "mul_567"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "FLOAT[s34,s16,2048]"
                  }
                ]
              },
              {
                "id": "1",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "val_8"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "?[?]"
                  },
                  {
                    "key": "unused",
                    "value": "True"
                  }
                ]
              },
              {
                "id": "2",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "val_9"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "?[?]"
                  },
                  {
                    "key": "unused",
                    "value": "True"
                  }
                ]
              },
              {
                "id": "3",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "add_697"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "FLOAT[s34,s16,2048]"
                  }
                ]
              }
            ],
            "inputsMetadata": [
              {
                "id": "0",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "linear_10"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "FLOAT[s34,s16,2048]"
                  }
                ]
              },
              {
                "id": "1",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "add_463"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "FLOAT[s34,s16,2048]"
                  }
                ]
              },
              {
                "id": "2",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "model.layers.1.post_attention_layernorm.weight"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "FLOAT[2048]"
                  }
                ]
              }
            ],
            "style": null,
            "config": null
          },
          {
            "id": "node_MatMul_659",
            "label": "MatMul",
            "namespace": "main_graph/: transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/model.layers.1: transformers.models.llama.modeling_llama.LlamaDecoderLayer/model.layers.1.mlp: transformers.models.llama.modeling_llama.LlamaMLP/model.layers.1.mlp.gate_proj: torch.nn.modules.linear.Linear/linear_11: aten.linear.default",
            "subgraphIds": [],
            "attrs": [
              {
                "key": "[metadata] namespace",
                "value": ": transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/model.layers.1: transformers.models.llama.modeling_llama.LlamaDecoderLayer/model.layers.1.mlp: transformers.models.llama.modeling_llama.LlamaMLP/model.layers.1.mlp.gate_proj: torch.nn.modules.linear.Linear/linear_11: aten.linear.default"
              },
              {
                "key": "[metadata] pkg.torch.onnx.class_hierarchy",
                "value": "['transformers.models.llama.modeling_llama.LlamaForCausalLM', 'transformers.models.llama.modeling_llama.LlamaModel', 'transformers.models.llama.modeling_llama.LlamaDecoderLayer', 'transformers.models.llama.modeling_llama.LlamaMLP', 'torch.nn.modules.linear.Linear', 'aten.linear.default']"
              },
              {
                "key": "[metadata] pkg.torch.onnx.fx_node",
                "value": "%linear_11 : [num_users=1] = call_function[target=torch.ops.aten.linear.default](args = (%mul_567, %p_model_layers_1_mlp_gate_proj_weight), kwargs = {})"
              },
              {
                "key": "[metadata] pkg.torch.onnx.name_scopes",
                "value": "['', 'model', 'model.layers.1', 'model.layers.1.mlp', 'model.layers.1.mlp.gate_proj', 'linear_11']"
              },
              {
                "key": "[metadata] pkg.torch.onnx.stack_trace",
                "value": "File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 688, in forward\n    outputs: BaseModelOutputWithPast = self.model(\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 453, in forward\n    layer_outputs = decoder_layer(\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 324, in forward\n    hidden_states = self.mlp(hidden_states)\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 162, in forward\n    down_proj = self.down_proj(self.act_fn(self.gate_proj(x)) * self.up_proj(x))\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/torch/nn/modules/linear.py\", line 125, in forward\n    return F.linear(input, self.weight, self.bias)"
              }
            ],
            "incomingEdges": [
              {
                "sourceNodeId": "node_SkipSimplifiedLayerNormalization_23",
                "sourceNodeOutputId": "0",
                "targetNodeInputId": "0"
              },
              {
                "sourceNodeId": "[value] val_462",
                "sourceNodeOutputId": "0",
                "targetNodeInputId": "1"
              }
            ],
            "outputsMetadata": [
              {
                "id": "0",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "linear_11"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "FLOAT[s34,s16,8192]"
                  },
                  {
                    "key": "param_name",
                    "value": "Y"
                  }
                ]
              }
            ],
            "inputsMetadata": [
              {
                "id": "0",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "mul_567"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "FLOAT[s34,s16,2048]"
                  },
                  {
                    "key": "param_name",
                    "value": "A"
                  }
                ]
              },
              {
                "id": "1",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "val_462"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "FLOAT[2048,8192]"
                  },
                  {
                    "key": "param_name",
                    "value": "B"
                  }
                ]
              }
            ],
            "style": null,
            "config": null
          },
          {
            "id": "node_Sigmoid_660",
            "label": "Sigmoid",
            "namespace": "main_graph/: transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/model.layers.1: transformers.models.llama.modeling_llama.LlamaDecoderLayer/model.layers.1.mlp: transformers.models.llama.modeling_llama.LlamaMLP/model.layers.1.mlp.act_fn: torch.nn.modules.activation.SiLU/silu_1: aten.silu.default",
            "subgraphIds": [],
            "attrs": [
              {
                "key": "[metadata] namespace",
                "value": ": transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/model.layers.1: transformers.models.llama.modeling_llama.LlamaDecoderLayer/model.layers.1.mlp: transformers.models.llama.modeling_llama.LlamaMLP/model.layers.1.mlp.act_fn: torch.nn.modules.activation.SiLU/silu_1: aten.silu.default"
              },
              {
                "key": "[metadata] pkg.torch.onnx.class_hierarchy",
                "value": "['transformers.models.llama.modeling_llama.LlamaForCausalLM', 'transformers.models.llama.modeling_llama.LlamaModel', 'transformers.models.llama.modeling_llama.LlamaDecoderLayer', 'transformers.models.llama.modeling_llama.LlamaMLP', 'torch.nn.modules.activation.SiLU', 'aten.silu.default']"
              },
              {
                "key": "[metadata] pkg.torch.onnx.fx_node",
                "value": "%silu_1 : [num_users=1] = call_function[target=torch.ops.aten.silu.default](args = (%linear_11,), kwargs = {})"
              },
              {
                "key": "[metadata] pkg.torch.onnx.name_scopes",
                "value": "['', 'model', 'model.layers.1', 'model.layers.1.mlp', 'model.layers.1.mlp.act_fn', 'silu_1']"
              },
              {
                "key": "[metadata] pkg.torch.onnx.stack_trace",
                "value": "File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 688, in forward\n    outputs: BaseModelOutputWithPast = self.model(\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 453, in forward\n    layer_outputs = decoder_layer(\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 324, in forward\n    hidden_states = self.mlp(hidden_states)\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 162, in forward\n    down_proj = self.down_proj(self.act_fn(self.gate_proj(x)) * self.up_proj(x))\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/torch/nn/modules/activation.py\", line 434, in forward\n    return F.silu(input, inplace=self.inplace)"
              }
            ],
            "incomingEdges": [
              {
                "sourceNodeId": "node_MatMul_659",
                "sourceNodeOutputId": "0",
                "targetNodeInputId": "0"
              }
            ],
            "outputsMetadata": [
              {
                "id": "0",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "val_463"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "FLOAT[s34,s16,8192]"
                  },
                  {
                    "key": "param_name",
                    "value": "Y"
                  }
                ]
              }
            ],
            "inputsMetadata": [
              {
                "id": "0",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "linear_11"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "FLOAT[s34,s16,8192]"
                  },
                  {
                    "key": "param_name",
                    "value": "X"
                  }
                ]
              }
            ],
            "style": null,
            "config": null
          },
          {
            "id": "node_Mul_661",
            "label": "Mul",
            "namespace": "main_graph/: transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/model.layers.1: transformers.models.llama.modeling_llama.LlamaDecoderLayer/model.layers.1.mlp: transformers.models.llama.modeling_llama.LlamaMLP/model.layers.1.mlp.act_fn: torch.nn.modules.activation.SiLU/silu_1: aten.silu.default",
            "subgraphIds": [],
            "attrs": [
              {
                "key": "[metadata] namespace",
                "value": ": transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/model.layers.1: transformers.models.llama.modeling_llama.LlamaDecoderLayer/model.layers.1.mlp: transformers.models.llama.modeling_llama.LlamaMLP/model.layers.1.mlp.act_fn: torch.nn.modules.activation.SiLU/silu_1: aten.silu.default"
              },
              {
                "key": "[metadata] pkg.torch.onnx.class_hierarchy",
                "value": "['transformers.models.llama.modeling_llama.LlamaForCausalLM', 'transformers.models.llama.modeling_llama.LlamaModel', 'transformers.models.llama.modeling_llama.LlamaDecoderLayer', 'transformers.models.llama.modeling_llama.LlamaMLP', 'torch.nn.modules.activation.SiLU', 'aten.silu.default']"
              },
              {
                "key": "[metadata] pkg.torch.onnx.fx_node",
                "value": "%silu_1 : [num_users=1] = call_function[target=torch.ops.aten.silu.default](args = (%linear_11,), kwargs = {})"
              },
              {
                "key": "[metadata] pkg.torch.onnx.name_scopes",
                "value": "['', 'model', 'model.layers.1', 'model.layers.1.mlp', 'model.layers.1.mlp.act_fn', 'silu_1']"
              },
              {
                "key": "[metadata] pkg.torch.onnx.stack_trace",
                "value": "File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 688, in forward\n    outputs: BaseModelOutputWithPast = self.model(\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 453, in forward\n    layer_outputs = decoder_layer(\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 324, in forward\n    hidden_states = self.mlp(hidden_states)\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 162, in forward\n    down_proj = self.down_proj(self.act_fn(self.gate_proj(x)) * self.up_proj(x))\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/torch/nn/modules/activation.py\", line 434, in forward\n    return F.silu(input, inplace=self.inplace)"
              }
            ],
            "incomingEdges": [
              {
                "sourceNodeId": "node_MatMul_659",
                "sourceNodeOutputId": "0",
                "targetNodeInputId": "0"
              },
              {
                "sourceNodeId": "node_Sigmoid_660",
                "sourceNodeOutputId": "0",
                "targetNodeInputId": "1"
              }
            ],
            "outputsMetadata": [
              {
                "id": "0",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "silu_1"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "FLOAT[s34,s16,8192]"
                  },
                  {
                    "key": "param_name",
                    "value": "C"
                  }
                ]
              }
            ],
            "inputsMetadata": [
              {
                "id": "0",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "linear_11"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "FLOAT[s34,s16,8192]"
                  },
                  {
                    "key": "param_name",
                    "value": "A"
                  }
                ]
              },
              {
                "id": "1",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "val_463"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "FLOAT[s34,s16,8192]"
                  },
                  {
                    "key": "param_name",
                    "value": "B"
                  }
                ]
              }
            ],
            "style": null,
            "config": null
          },
          {
            "id": "node_MatMul_663",
            "label": "MatMul",
            "namespace": "main_graph/: transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/model.layers.1: transformers.models.llama.modeling_llama.LlamaDecoderLayer/model.layers.1.mlp: transformers.models.llama.modeling_llama.LlamaMLP/model.layers.1.mlp.up_proj: torch.nn.modules.linear.Linear/linear_12: aten.linear.default",
            "subgraphIds": [],
            "attrs": [
              {
                "key": "[metadata] namespace",
                "value": ": transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/model.layers.1: transformers.models.llama.modeling_llama.LlamaDecoderLayer/model.layers.1.mlp: transformers.models.llama.modeling_llama.LlamaMLP/model.layers.1.mlp.up_proj: torch.nn.modules.linear.Linear/linear_12: aten.linear.default"
              },
              {
                "key": "[metadata] pkg.torch.onnx.class_hierarchy",
                "value": "['transformers.models.llama.modeling_llama.LlamaForCausalLM', 'transformers.models.llama.modeling_llama.LlamaModel', 'transformers.models.llama.modeling_llama.LlamaDecoderLayer', 'transformers.models.llama.modeling_llama.LlamaMLP', 'torch.nn.modules.linear.Linear', 'aten.linear.default']"
              },
              {
                "key": "[metadata] pkg.torch.onnx.fx_node",
                "value": "%linear_12 : [num_users=1] = call_function[target=torch.ops.aten.linear.default](args = (%mul_567, %p_model_layers_1_mlp_up_proj_weight), kwargs = {})"
              },
              {
                "key": "[metadata] pkg.torch.onnx.name_scopes",
                "value": "['', 'model', 'model.layers.1', 'model.layers.1.mlp', 'model.layers.1.mlp.up_proj', 'linear_12']"
              },
              {
                "key": "[metadata] pkg.torch.onnx.stack_trace",
                "value": "File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 688, in forward\n    outputs: BaseModelOutputWithPast = self.model(\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 453, in forward\n    layer_outputs = decoder_layer(\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 324, in forward\n    hidden_states = self.mlp(hidden_states)\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 162, in forward\n    down_proj = self.down_proj(self.act_fn(self.gate_proj(x)) * self.up_proj(x))\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/torch/nn/modules/linear.py\", line 125, in forward\n    return F.linear(input, self.weight, self.bias)"
              }
            ],
            "incomingEdges": [
              {
                "sourceNodeId": "node_SkipSimplifiedLayerNormalization_23",
                "sourceNodeOutputId": "0",
                "targetNodeInputId": "0"
              },
              {
                "sourceNodeId": "[value] val_464",
                "sourceNodeOutputId": "0",
                "targetNodeInputId": "1"
              }
            ],
            "outputsMetadata": [
              {
                "id": "0",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "linear_12"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "FLOAT[s34,s16,8192]"
                  },
                  {
                    "key": "param_name",
                    "value": "Y"
                  }
                ]
              }
            ],
            "inputsMetadata": [
              {
                "id": "0",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "mul_567"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "FLOAT[s34,s16,2048]"
                  },
                  {
                    "key": "param_name",
                    "value": "A"
                  }
                ]
              },
              {
                "id": "1",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "val_464"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "FLOAT[2048,8192]"
                  },
                  {
                    "key": "param_name",
                    "value": "B"
                  }
                ]
              }
            ],
            "style": null,
            "config": null
          },
          {
            "id": "node_Mul_664",
            "label": "Mul",
            "namespace": "main_graph/: transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/model.layers.1: transformers.models.llama.modeling_llama.LlamaDecoderLayer/model.layers.1.mlp: transformers.models.llama.modeling_llama.LlamaMLP/mul_580: aten.mul.Tensor",
            "subgraphIds": [],
            "attrs": [
              {
                "key": "[metadata] namespace",
                "value": ": transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/model.layers.1: transformers.models.llama.modeling_llama.LlamaDecoderLayer/model.layers.1.mlp: transformers.models.llama.modeling_llama.LlamaMLP/mul_580: aten.mul.Tensor"
              },
              {
                "key": "[metadata] pkg.torch.onnx.class_hierarchy",
                "value": "['transformers.models.llama.modeling_llama.LlamaForCausalLM', 'transformers.models.llama.modeling_llama.LlamaModel', 'transformers.models.llama.modeling_llama.LlamaDecoderLayer', 'transformers.models.llama.modeling_llama.LlamaMLP', 'aten.mul.Tensor']"
              },
              {
                "key": "[metadata] pkg.torch.onnx.fx_node",
                "value": "%mul_580 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%silu_1, %linear_12), kwargs = {})"
              },
              {
                "key": "[metadata] pkg.torch.onnx.name_scopes",
                "value": "['', 'model', 'model.layers.1', 'model.layers.1.mlp', 'mul_580']"
              },
              {
                "key": "[metadata] pkg.torch.onnx.stack_trace",
                "value": "File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 688, in forward\n    outputs: BaseModelOutputWithPast = self.model(\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 453, in forward\n    layer_outputs = decoder_layer(\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 324, in forward\n    hidden_states = self.mlp(hidden_states)\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 162, in forward\n    down_proj = self.down_proj(self.act_fn(self.gate_proj(x)) * self.up_proj(x))"
              }
            ],
            "incomingEdges": [
              {
                "sourceNodeId": "node_Mul_661",
                "sourceNodeOutputId": "0",
                "targetNodeInputId": "0"
              },
              {
                "sourceNodeId": "node_MatMul_663",
                "sourceNodeOutputId": "0",
                "targetNodeInputId": "1"
              }
            ],
            "outputsMetadata": [
              {
                "id": "0",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "mul_580"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "FLOAT[s34,s16,8192]"
                  },
                  {
                    "key": "param_name",
                    "value": "C"
                  }
                ]
              }
            ],
            "inputsMetadata": [
              {
                "id": "0",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "silu_1"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "FLOAT[s34,s16,8192]"
                  },
                  {
                    "key": "param_name",
                    "value": "A"
                  }
                ]
              },
              {
                "id": "1",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "linear_12"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "FLOAT[s34,s16,8192]"
                  },
                  {
                    "key": "param_name",
                    "value": "B"
                  }
                ]
              }
            ],
            "style": null,
            "config": null
          },
          {
            "id": "node_MatMul_666",
            "label": "MatMul",
            "namespace": "main_graph/: transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/model.layers.1: transformers.models.llama.modeling_llama.LlamaDecoderLayer/model.layers.1.mlp: transformers.models.llama.modeling_llama.LlamaMLP/model.layers.1.mlp.down_proj: torch.nn.modules.linear.Linear/linear_13: aten.linear.default",
            "subgraphIds": [],
            "attrs": [
              {
                "key": "[metadata] namespace",
                "value": ": transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/model.layers.1: transformers.models.llama.modeling_llama.LlamaDecoderLayer/model.layers.1.mlp: transformers.models.llama.modeling_llama.LlamaMLP/model.layers.1.mlp.down_proj: torch.nn.modules.linear.Linear/linear_13: aten.linear.default"
              },
              {
                "key": "[metadata] pkg.torch.onnx.class_hierarchy",
                "value": "['transformers.models.llama.modeling_llama.LlamaForCausalLM', 'transformers.models.llama.modeling_llama.LlamaModel', 'transformers.models.llama.modeling_llama.LlamaDecoderLayer', 'transformers.models.llama.modeling_llama.LlamaMLP', 'torch.nn.modules.linear.Linear', 'aten.linear.default']"
              },
              {
                "key": "[metadata] pkg.torch.onnx.fx_node",
                "value": "%linear_13 : [num_users=1] = call_function[target=torch.ops.aten.linear.default](args = (%mul_580, %p_model_layers_1_mlp_down_proj_weight), kwargs = {})"
              },
              {
                "key": "[metadata] pkg.torch.onnx.name_scopes",
                "value": "['', 'model', 'model.layers.1', 'model.layers.1.mlp', 'model.layers.1.mlp.down_proj', 'linear_13']"
              },
              {
                "key": "[metadata] pkg.torch.onnx.stack_trace",
                "value": "File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 688, in forward\n    outputs: BaseModelOutputWithPast = self.model(\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 453, in forward\n    layer_outputs = decoder_layer(\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 324, in forward\n    hidden_states = self.mlp(hidden_states)\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 162, in forward\n    down_proj = self.down_proj(self.act_fn(self.gate_proj(x)) * self.up_proj(x))\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/torch/nn/modules/linear.py\", line 125, in forward\n    return F.linear(input, self.weight, self.bias)"
              }
            ],
            "incomingEdges": [
              {
                "sourceNodeId": "node_Mul_664",
                "sourceNodeOutputId": "0",
                "targetNodeInputId": "0"
              },
              {
                "sourceNodeId": "[value] val_465",
                "sourceNodeOutputId": "0",
                "targetNodeInputId": "1"
              }
            ],
            "outputsMetadata": [
              {
                "id": "0",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "linear_13"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "FLOAT[s34,s16,2048]"
                  },
                  {
                    "key": "param_name",
                    "value": "Y"
                  }
                ]
              }
            ],
            "inputsMetadata": [
              {
                "id": "0",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "mul_580"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "FLOAT[s34,s16,8192]"
                  },
                  {
                    "key": "param_name",
                    "value": "A"
                  }
                ]
              },
              {
                "id": "1",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "val_465"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "FLOAT[8192,2048]"
                  },
                  {
                    "key": "param_name",
                    "value": "B"
                  }
                ]
              }
            ],
            "style": null,
            "config": null
          },
          {
            "id": "node_SkipSimplifiedLayerNormalization_24",
            "label": "com.microsoft::SkipSimplifiedLayerNormalization",
            "namespace": "main_graph",
            "subgraphIds": [],
            "attrs": [
              {
                "key": "epsilon",
                "value": "9.999999747378752e-06"
              }
            ],
            "incomingEdges": [
              {
                "sourceNodeId": "node_MatMul_666",
                "sourceNodeOutputId": "0",
                "targetNodeInputId": "0"
              },
              {
                "sourceNodeId": "node_SkipSimplifiedLayerNormalization_23",
                "sourceNodeOutputId": "3",
                "targetNodeInputId": "1"
              },
              {
                "sourceNodeId": "[value] model.norm.weight",
                "sourceNodeOutputId": "0",
                "targetNodeInputId": "2"
              }
            ],
            "outputsMetadata": [
              {
                "id": "0",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "mul_603"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "FLOAT[s34,s16,2048]"
                  }
                ]
              },
              {
                "id": "1",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "val_10"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "?[?]"
                  },
                  {
                    "key": "unused",
                    "value": "True"
                  }
                ]
              },
              {
                "id": "2",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "val_13"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "?[?]"
                  },
                  {
                    "key": "unused",
                    "value": "True"
                  }
                ]
              },
              {
                "id": "3",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "add_747"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "FLOAT[s34,s16,2048]"
                  },
                  {
                    "key": "unused",
                    "value": "True"
                  }
                ]
              }
            ],
            "inputsMetadata": [
              {
                "id": "0",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "linear_13"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "FLOAT[s34,s16,2048]"
                  }
                ]
              },
              {
                "id": "1",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "add_697"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "FLOAT[s34,s16,2048]"
                  }
                ]
              },
              {
                "id": "2",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "model.norm.weight"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "FLOAT[2048]"
                  }
                ]
              }
            ],
            "style": null,
            "config": null
          },
          {
            "id": "node_Transpose_701",
            "label": "Transpose",
            "namespace": "main_graph/: transformers.models.llama.modeling_llama.LlamaForCausalLM/lm_head: torch.nn.modules.linear.Linear/linear_14: aten.linear.default",
            "subgraphIds": [],
            "attrs": [
              {
                "key": "perm",
                "value": "[1, 0]"
              },
              {
                "key": "[metadata] namespace",
                "value": ": transformers.models.llama.modeling_llama.LlamaForCausalLM/lm_head: torch.nn.modules.linear.Linear/linear_14: aten.linear.default"
              },
              {
                "key": "[metadata] pkg.torch.onnx.class_hierarchy",
                "value": "['transformers.models.llama.modeling_llama.LlamaForCausalLM', 'torch.nn.modules.linear.Linear', 'aten.linear.default']"
              },
              {
                "key": "[metadata] pkg.torch.onnx.fx_node",
                "value": "%linear_14 : [num_users=1] = call_function[target=torch.ops.aten.linear.default](args = (%slice_52, %p_lm_head_weight), kwargs = {})"
              },
              {
                "key": "[metadata] pkg.torch.onnx.name_scopes",
                "value": "['', 'lm_head', 'linear_14']"
              },
              {
                "key": "[metadata] pkg.torch.onnx.stack_trace",
                "value": "File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 704, in forward\n    logits = self.lm_head(hidden_states[:, slice_indices, :])\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/torch/nn/modules/linear.py\", line 125, in forward\n    return F.linear(input, self.weight, self.bias)"
              }
            ],
            "incomingEdges": [
              {
                "sourceNodeId": "[value] lm_head.weight",
                "sourceNodeOutputId": "0",
                "targetNodeInputId": "0"
              }
            ],
            "outputsMetadata": [
              {
                "id": "0",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "val_490"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "FLOAT[2048,49152]"
                  },
                  {
                    "key": "param_name",
                    "value": "transposed"
                  }
                ]
              }
            ],
            "inputsMetadata": [
              {
                "id": "0",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "lm_head.weight"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "FLOAT[49152,2048]"
                  },
                  {
                    "key": "param_name",
                    "value": "data"
                  }
                ]
              }
            ],
            "style": null,
            "config": null
          },
          {
            "id": "node_MatMul_702",
            "label": "MatMul",
            "namespace": "main_graph/: transformers.models.llama.modeling_llama.LlamaForCausalLM/lm_head: torch.nn.modules.linear.Linear/linear_14: aten.linear.default",
            "subgraphIds": [],
            "attrs": [
              {
                "key": "[metadata] namespace",
                "value": ": transformers.models.llama.modeling_llama.LlamaForCausalLM/lm_head: torch.nn.modules.linear.Linear/linear_14: aten.linear.default"
              },
              {
                "key": "[metadata] pkg.torch.onnx.class_hierarchy",
                "value": "['transformers.models.llama.modeling_llama.LlamaForCausalLM', 'torch.nn.modules.linear.Linear', 'aten.linear.default']"
              },
              {
                "key": "[metadata] pkg.torch.onnx.fx_node",
                "value": "%linear_14 : [num_users=1] = call_function[target=torch.ops.aten.linear.default](args = (%slice_52, %p_lm_head_weight), kwargs = {})"
              },
              {
                "key": "[metadata] pkg.torch.onnx.name_scopes",
                "value": "['', 'lm_head', 'linear_14']"
              },
              {
                "key": "[metadata] pkg.torch.onnx.stack_trace",
                "value": "File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 704, in forward\n    logits = self.lm_head(hidden_states[:, slice_indices, :])\n  File \"/opt/conda/envs/ptca/lib/python3.10/site-packages/torch/nn/modules/linear.py\", line 125, in forward\n    return F.linear(input, self.weight, self.bias)"
              }
            ],
            "incomingEdges": [
              {
                "sourceNodeId": "node_SkipSimplifiedLayerNormalization_24",
                "sourceNodeOutputId": "0",
                "targetNodeInputId": "0"
              },
              {
                "sourceNodeId": "node_Transpose_701",
                "sourceNodeOutputId": "0",
                "targetNodeInputId": "1"
              }
            ],
            "outputsMetadata": [
              {
                "id": "0",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "linear_14"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "FLOAT[s34,s16,49152]"
                  },
                  {
                    "key": "[metadata] pkg.torch.export.graph_signature.OutputSpec.kind",
                    "value": "USER_OUTPUT"
                  },
                  {
                    "key": "param_name",
                    "value": "Y"
                  }
                ]
              }
            ],
            "inputsMetadata": [
              {
                "id": "0",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "mul_603"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "FLOAT[s34,s16,2048]"
                  },
                  {
                    "key": "param_name",
                    "value": "A"
                  }
                ]
              },
              {
                "id": "1",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "val_490"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "FLOAT[2048,49152]"
                  },
                  {
                    "key": "param_name",
                    "value": "B"
                  }
                ]
              }
            ],
            "style": null,
            "config": null
          },
          {
            "id": "[value] model.layers.0.input_layernorm.weight",
            "label": "Initializer",
            "namespace": "main_graph",
            "subgraphIds": [],
            "attrs": [],
            "incomingEdges": [],
            "outputsMetadata": [
              {
                "id": "0",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "model.layers.0.input_layernorm.weight"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "FLOAT[2048]"
                  },
                  {
                    "key": "value",
                    "value": "ExternalTensor<FLOAT,[2048]>(location='model_SmolLM17b_optimized.onnx.data', name='model.layers.0.input_layernorm.weight', offset=0, length=8192, base_dir='')"
                  }
                ]
              }
            ],
            "inputsMetadata": [],
            "style": null,
            "config": null
          },
          {
            "id": "[value] model.layers.0.post_attention_layernorm.weight",
            "label": "Initializer",
            "namespace": "main_graph",
            "subgraphIds": [],
            "attrs": [],
            "incomingEdges": [],
            "outputsMetadata": [
              {
                "id": "0",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "model.layers.0.post_attention_layernorm.weight"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "FLOAT[2048]"
                  },
                  {
                    "key": "value",
                    "value": "ExternalTensor<FLOAT,[2048]>(location='model_SmolLM17b_optimized.onnx.data', name='model.layers.0.post_attention_layernorm.weight', offset=8192, length=8192, base_dir='')"
                  }
                ]
              }
            ],
            "inputsMetadata": [],
            "style": null,
            "config": null
          },
          {
            "id": "[value] model.layers.1.input_layernorm.weight",
            "label": "Initializer",
            "namespace": "main_graph",
            "subgraphIds": [],
            "attrs": [],
            "incomingEdges": [],
            "outputsMetadata": [
              {
                "id": "0",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "model.layers.1.input_layernorm.weight"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "FLOAT[2048]"
                  },
                  {
                    "key": "value",
                    "value": "ExternalTensor<FLOAT,[2048]>(location='model_SmolLM17b_optimized.onnx.data', name='model.layers.1.input_layernorm.weight', offset=16384, length=8192, base_dir='')"
                  }
                ]
              }
            ],
            "inputsMetadata": [],
            "style": null,
            "config": null
          },
          {
            "id": "[value] model.layers.1.post_attention_layernorm.weight",
            "label": "Initializer",
            "namespace": "main_graph",
            "subgraphIds": [],
            "attrs": [],
            "incomingEdges": [],
            "outputsMetadata": [
              {
                "id": "0",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "model.layers.1.post_attention_layernorm.weight"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "FLOAT[2048]"
                  },
                  {
                    "key": "value",
                    "value": "ExternalTensor<FLOAT,[2048]>(location='model_SmolLM17b_optimized.onnx.data', name='model.layers.1.post_attention_layernorm.weight', offset=24576, length=8192, base_dir='')"
                  }
                ]
              }
            ],
            "inputsMetadata": [],
            "style": null,
            "config": null
          },
          {
            "id": "[value] model.norm.weight",
            "label": "Initializer",
            "namespace": "main_graph",
            "subgraphIds": [],
            "attrs": [],
            "incomingEdges": [],
            "outputsMetadata": [
              {
                "id": "0",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "model.norm.weight"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "FLOAT[2048]"
                  },
                  {
                    "key": "value",
                    "value": "ExternalTensor<FLOAT,[2048]>(location='model_SmolLM17b_optimized.onnx.data', name='model.norm.weight', offset=32768, length=8192, base_dir='')"
                  }
                ]
              }
            ],
            "inputsMetadata": [],
            "style": null,
            "config": null
          },
          {
            "id": "[value] lm_head.weight",
            "label": "Initializer",
            "namespace": "main_graph/: transformers.models.llama.modeling_llama.LlamaForCausalLM",
            "subgraphIds": [],
            "attrs": [],
            "incomingEdges": [],
            "outputsMetadata": [
              {
                "id": "0",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "lm_head.weight"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "FLOAT[49152,2048]"
                  },
                  {
                    "key": "value",
                    "value": "ExternalTensor<FLOAT,[49152,2048]>(location='model_SmolLM17b_optimized.onnx.data', name='lm_head.weight', offset=536936448, length=402653184, base_dir='')"
                  }
                ]
              }
            ],
            "inputsMetadata": [],
            "style": null,
            "config": null
          },
          {
            "id": "[value] val_253",
            "label": "Initializer",
            "namespace": "main_graph/: transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/model.layers.0: transformers.models.llama.modeling_llama.LlamaDecoderLayer/model.layers.0.self_attn: transformers.models.llama.modeling_llama.LlamaAttention/model.layers.0.self_attn.q_proj: torch.nn.modules.linear.Linear/linear: aten.linear.default",
            "subgraphIds": [],
            "attrs": [],
            "incomingEdges": [],
            "outputsMetadata": [
              {
                "id": "0",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "val_253"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "FLOAT[2048,2048]"
                  },
                  {
                    "key": "value",
                    "value": "ExternalTensor<FLOAT,[2048,2048]>(location='model_SmolLM17b_optimized.onnx.data', name='val_253', offset=65536, length=16777216, base_dir='')"
                  }
                ]
              }
            ],
            "inputsMetadata": [],
            "style": null,
            "config": null
          },
          {
            "id": "[value] val_261",
            "label": "Initializer",
            "namespace": "main_graph/: transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/model.layers.0: transformers.models.llama.modeling_llama.LlamaDecoderLayer/model.layers.0.self_attn: transformers.models.llama.modeling_llama.LlamaAttention/model.layers.0.self_attn.k_proj: torch.nn.modules.linear.Linear/linear_1: aten.linear.default",
            "subgraphIds": [],
            "attrs": [],
            "incomingEdges": [],
            "outputsMetadata": [
              {
                "id": "0",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "val_261"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "FLOAT[2048,2048]"
                  },
                  {
                    "key": "value",
                    "value": "ExternalTensor<FLOAT,[2048,2048]>(location='model_SmolLM17b_optimized.onnx.data', name='val_261', offset=16842752, length=16777216, base_dir='')"
                  }
                ]
              }
            ],
            "inputsMetadata": [],
            "style": null,
            "config": null
          },
          {
            "id": "[value] val_268",
            "label": "Initializer",
            "namespace": "main_graph/: transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/model.layers.0: transformers.models.llama.modeling_llama.LlamaDecoderLayer/model.layers.0.self_attn: transformers.models.llama.modeling_llama.LlamaAttention/model.layers.0.self_attn.v_proj: torch.nn.modules.linear.Linear/linear_2: aten.linear.default",
            "subgraphIds": [],
            "attrs": [],
            "incomingEdges": [],
            "outputsMetadata": [
              {
                "id": "0",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "val_268"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "FLOAT[2048,2048]"
                  },
                  {
                    "key": "value",
                    "value": "ExternalTensor<FLOAT,[2048,2048]>(location='model_SmolLM17b_optimized.onnx.data', name='val_268', offset=33619968, length=16777216, base_dir='')"
                  }
                ]
              }
            ],
            "inputsMetadata": [],
            "style": null,
            "config": null
          },
          {
            "id": "[value] val_350",
            "label": "Initializer",
            "namespace": "main_graph/: transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/model.layers.0: transformers.models.llama.modeling_llama.LlamaDecoderLayer/model.layers.0.self_attn: transformers.models.llama.modeling_llama.LlamaAttention/model.layers.0.self_attn.o_proj: torch.nn.modules.linear.Linear/linear_3: aten.linear.default",
            "subgraphIds": [],
            "attrs": [],
            "incomingEdges": [],
            "outputsMetadata": [
              {
                "id": "0",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "val_350"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "FLOAT[2048,2048]"
                  },
                  {
                    "key": "value",
                    "value": "ExternalTensor<FLOAT,[2048,2048]>(location='model_SmolLM17b_optimized.onnx.data', name='val_350', offset=50397184, length=16777216, base_dir='')"
                  }
                ]
              }
            ],
            "inputsMetadata": [],
            "style": null,
            "config": null
          },
          {
            "id": "[value] val_355",
            "label": "Initializer",
            "namespace": "main_graph/: transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/model.layers.0: transformers.models.llama.modeling_llama.LlamaDecoderLayer/model.layers.0.mlp: transformers.models.llama.modeling_llama.LlamaMLP/model.layers.0.mlp.gate_proj: torch.nn.modules.linear.Linear/linear_4: aten.linear.default",
            "subgraphIds": [],
            "attrs": [],
            "incomingEdges": [],
            "outputsMetadata": [
              {
                "id": "0",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "val_355"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "FLOAT[2048,8192]"
                  },
                  {
                    "key": "value",
                    "value": "ExternalTensor<FLOAT,[2048,8192]>(location='model_SmolLM17b_optimized.onnx.data', name='val_355', offset=134283264, length=67108864, base_dir='')"
                  }
                ]
              }
            ],
            "inputsMetadata": [],
            "style": null,
            "config": null
          },
          {
            "id": "[value] val_357",
            "label": "Initializer",
            "namespace": "main_graph/: transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/model.layers.0: transformers.models.llama.modeling_llama.LlamaDecoderLayer/model.layers.0.mlp: transformers.models.llama.modeling_llama.LlamaMLP/model.layers.0.mlp.up_proj: torch.nn.modules.linear.Linear/linear_5: aten.linear.default",
            "subgraphIds": [],
            "attrs": [],
            "incomingEdges": [],
            "outputsMetadata": [
              {
                "id": "0",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "val_357"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "FLOAT[2048,8192]"
                  },
                  {
                    "key": "value",
                    "value": "ExternalTensor<FLOAT,[2048,8192]>(location='model_SmolLM17b_optimized.onnx.data', name='val_357', offset=201392128, length=67108864, base_dir='')"
                  }
                ]
              }
            ],
            "inputsMetadata": [],
            "style": null,
            "config": null
          },
          {
            "id": "[value] val_358",
            "label": "Initializer",
            "namespace": "main_graph/: transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/model.layers.0: transformers.models.llama.modeling_llama.LlamaDecoderLayer/model.layers.0.mlp: transformers.models.llama.modeling_llama.LlamaMLP/model.layers.0.mlp.down_proj: torch.nn.modules.linear.Linear/linear_6: aten.linear.default",
            "subgraphIds": [],
            "attrs": [],
            "incomingEdges": [],
            "outputsMetadata": [
              {
                "id": "0",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "val_358"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "FLOAT[8192,2048]"
                  },
                  {
                    "key": "value",
                    "value": "ExternalTensor<FLOAT,[8192,2048]>(location='model_SmolLM17b_optimized.onnx.data', name='val_358', offset=268500992, length=67108864, base_dir='')"
                  }
                ]
              }
            ],
            "inputsMetadata": [],
            "style": null,
            "config": null
          },
          {
            "id": "[value] val_363",
            "label": "Initializer",
            "namespace": "main_graph/: transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/model.layers.1: transformers.models.llama.modeling_llama.LlamaDecoderLayer/model.layers.1.self_attn: transformers.models.llama.modeling_llama.LlamaAttention/model.layers.1.self_attn.q_proj: torch.nn.modules.linear.Linear/linear_7: aten.linear.default",
            "subgraphIds": [],
            "attrs": [],
            "incomingEdges": [],
            "outputsMetadata": [
              {
                "id": "0",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "val_363"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "FLOAT[2048,2048]"
                  },
                  {
                    "key": "value",
                    "value": "ExternalTensor<FLOAT,[2048,2048]>(location='model_SmolLM17b_optimized.onnx.data', name='val_363', offset=67174400, length=16777216, base_dir='')"
                  }
                ]
              }
            ],
            "inputsMetadata": [],
            "style": null,
            "config": null
          },
          {
            "id": "[value] val_370",
            "label": "Initializer",
            "namespace": "main_graph/: transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/model.layers.1: transformers.models.llama.modeling_llama.LlamaDecoderLayer/model.layers.1.self_attn: transformers.models.llama.modeling_llama.LlamaAttention/model.layers.1.self_attn.k_proj: torch.nn.modules.linear.Linear/linear_8: aten.linear.default",
            "subgraphIds": [],
            "attrs": [],
            "incomingEdges": [],
            "outputsMetadata": [
              {
                "id": "0",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "val_370"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "FLOAT[2048,2048]"
                  },
                  {
                    "key": "value",
                    "value": "ExternalTensor<FLOAT,[2048,2048]>(location='model_SmolLM17b_optimized.onnx.data', name='val_370', offset=83951616, length=16777216, base_dir='')"
                  }
                ]
              }
            ],
            "inputsMetadata": [],
            "style": null,
            "config": null
          },
          {
            "id": "[value] val_377",
            "label": "Initializer",
            "namespace": "main_graph/: transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/model.layers.1: transformers.models.llama.modeling_llama.LlamaDecoderLayer/model.layers.1.self_attn: transformers.models.llama.modeling_llama.LlamaAttention/model.layers.1.self_attn.v_proj: torch.nn.modules.linear.Linear/linear_9: aten.linear.default",
            "subgraphIds": [],
            "attrs": [],
            "incomingEdges": [],
            "outputsMetadata": [
              {
                "id": "0",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "val_377"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "FLOAT[2048,2048]"
                  },
                  {
                    "key": "value",
                    "value": "ExternalTensor<FLOAT,[2048,2048]>(location='model_SmolLM17b_optimized.onnx.data', name='val_377', offset=100728832, length=16777216, base_dir='')"
                  }
                ]
              }
            ],
            "inputsMetadata": [],
            "style": null,
            "config": null
          },
          {
            "id": "[value] val_457",
            "label": "Initializer",
            "namespace": "main_graph/: transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/model.layers.1: transformers.models.llama.modeling_llama.LlamaDecoderLayer/model.layers.1.self_attn: transformers.models.llama.modeling_llama.LlamaAttention/model.layers.1.self_attn.o_proj: torch.nn.modules.linear.Linear/linear_10: aten.linear.default",
            "subgraphIds": [],
            "attrs": [],
            "incomingEdges": [],
            "outputsMetadata": [
              {
                "id": "0",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "val_457"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "FLOAT[2048,2048]"
                  },
                  {
                    "key": "value",
                    "value": "ExternalTensor<FLOAT,[2048,2048]>(location='model_SmolLM17b_optimized.onnx.data', name='val_457', offset=117506048, length=16777216, base_dir='')"
                  }
                ]
              }
            ],
            "inputsMetadata": [],
            "style": null,
            "config": null
          },
          {
            "id": "[value] val_462",
            "label": "Initializer",
            "namespace": "main_graph/: transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/model.layers.1: transformers.models.llama.modeling_llama.LlamaDecoderLayer/model.layers.1.mlp: transformers.models.llama.modeling_llama.LlamaMLP/model.layers.1.mlp.gate_proj: torch.nn.modules.linear.Linear/linear_11: aten.linear.default",
            "subgraphIds": [],
            "attrs": [],
            "incomingEdges": [],
            "outputsMetadata": [
              {
                "id": "0",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "val_462"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "FLOAT[2048,8192]"
                  },
                  {
                    "key": "value",
                    "value": "ExternalTensor<FLOAT,[2048,8192]>(location='model_SmolLM17b_optimized.onnx.data', name='val_462', offset=335609856, length=67108864, base_dir='')"
                  }
                ]
              }
            ],
            "inputsMetadata": [],
            "style": null,
            "config": null
          },
          {
            "id": "[value] val_464",
            "label": "Initializer",
            "namespace": "main_graph/: transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/model.layers.1: transformers.models.llama.modeling_llama.LlamaDecoderLayer/model.layers.1.mlp: transformers.models.llama.modeling_llama.LlamaMLP/model.layers.1.mlp.up_proj: torch.nn.modules.linear.Linear/linear_12: aten.linear.default",
            "subgraphIds": [],
            "attrs": [],
            "incomingEdges": [],
            "outputsMetadata": [
              {
                "id": "0",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "val_464"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "FLOAT[2048,8192]"
                  },
                  {
                    "key": "value",
                    "value": "ExternalTensor<FLOAT,[2048,8192]>(location='model_SmolLM17b_optimized.onnx.data', name='val_464', offset=402718720, length=67108864, base_dir='')"
                  }
                ]
              }
            ],
            "inputsMetadata": [],
            "style": null,
            "config": null
          },
          {
            "id": "[value] val_465",
            "label": "Initializer",
            "namespace": "main_graph/: transformers.models.llama.modeling_llama.LlamaForCausalLM/model: transformers.models.llama.modeling_llama.LlamaModel/model.layers.1: transformers.models.llama.modeling_llama.LlamaDecoderLayer/model.layers.1.mlp: transformers.models.llama.modeling_llama.LlamaMLP/model.layers.1.mlp.down_proj: torch.nn.modules.linear.Linear/linear_13: aten.linear.default",
            "subgraphIds": [],
            "attrs": [],
            "incomingEdges": [],
            "outputsMetadata": [
              {
                "id": "0",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "val_465"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "FLOAT[8192,2048]"
                  },
                  {
                    "key": "value",
                    "value": "ExternalTensor<FLOAT,[8192,2048]>(location='model_SmolLM17b_optimized.onnx.data', name='val_465', offset=469827584, length=67108864, base_dir='')"
                  }
                ]
              }
            ],
            "inputsMetadata": [],
            "style": null,
            "config": null
          },
          {
            "id": "[value] val_16",
            "label": "Initializer",
            "namespace": "main_graph",
            "subgraphIds": [],
            "attrs": [
              {
                "key": "__value",
                "value": "[1.0,0.7498942017555237,0.5623413324356079,0.4216965138912201,0.3162277638912201,0.23713736236095428,0.17782793939113617,0.1333521455526352,0.10000000149011612,0.07498941570520401,0.05623412877321243,0.04216964915394783,0.03162277862429619,0.0237137358635664,0.017782794311642647,0.01333521492779255]"
              }
            ],
            "incomingEdges": [],
            "outputsMetadata": [
              {
                "id": "0",
                "attrs": [
                  {
                    "key": "__tensor_tag",
                    "value": "val_16"
                  },
                  {
                    "key": "tensor_shape",
                    "value": "FLOAT[1,32]"
                  },
                  {
                    "key": "value",
                    "value": "TensorProtoTensor<FLOAT,[1,32]>(name='val_16')"
                  }
                ]
              }
            ],
            "inputsMetadata": [],
            "style": null,
            "config": null
          },
          {
            "id": "[value] linear_14",
            "label": "Output",
            "namespace": "",
            "subgraphIds": [],
            "attrs": [
              {
                "key": "name",
                "value": "linear_14"
              },
              {
                "key": "index",
                "value": "0"
              }
            ],
            "incomingEdges": [
              {
                "sourceNodeId": "node_MatMul_702",
                "sourceNodeOutputId": "0",
                "targetNodeInputId": "0"
              }
            ],
            "outputsMetadata": [],
            "inputsMetadata": [],
            "style": null,
            "config": null
          },
          {
            "id": "[value] cat_3",
            "label": "Output",
            "namespace": "",
            "subgraphIds": [],
            "attrs": [
              {
                "key": "name",
                "value": "cat_3"
              },
              {
                "key": "index",
                "value": "1"
              }
            ],
            "incomingEdges": [
              {
                "sourceNodeId": "node_MultiHeadAttention_62",
                "sourceNodeOutputId": "1",
                "targetNodeInputId": "0"
              }
            ],
            "outputsMetadata": [],
            "inputsMetadata": [],
            "style": null,
            "config": null
          },
          {
            "id": "[value] cat_7",
            "label": "Output",
            "namespace": "",
            "subgraphIds": [],
            "attrs": [
              {
                "key": "name",
                "value": "cat_7"
              },
              {
                "key": "index",
                "value": "2"
              }
            ],
            "incomingEdges": [
              {
                "sourceNodeId": "node_MultiHeadAttention_67",
                "sourceNodeOutputId": "1",
                "targetNodeInputId": "0"
              }
            ],
            "outputsMetadata": [],
            "inputsMetadata": [],
            "style": null,
            "config": null
          },
          {
            "id": "[value] cat_4",
            "label": "Output",
            "namespace": "",
            "subgraphIds": [],
            "attrs": [
              {
                "key": "name",
                "value": "cat_4"
              },
              {
                "key": "index",
                "value": "3"
              }
            ],
            "incomingEdges": [
              {
                "sourceNodeId": "node_MultiHeadAttention_62",
                "sourceNodeOutputId": "2",
                "targetNodeInputId": "0"
              }
            ],
            "outputsMetadata": [],
            "inputsMetadata": [],
            "style": null,
            "config": null
          },
          {
            "id": "[value] cat_8",
            "label": "Output",
            "namespace": "",
            "subgraphIds": [],
            "attrs": [
              {
                "key": "name",
                "value": "cat_8"
              },
              {
                "key": "index",
                "value": "4"
              }
            ],
            "incomingEdges": [
              {
                "sourceNodeId": "node_MultiHeadAttention_67",
                "sourceNodeOutputId": "2",
                "targetNodeInputId": "0"
              }
            ],
            "outputsMetadata": [],
            "inputsMetadata": [],
            "style": null,
            "config": null
          }
        ],
        "groupNodeAttributes": {
          "": {
            "opset_imports": "{'': 18, 'com.microsoft': 1}",
            "producer_name": "pytorch",
            "producer_version": "2.8.0.dev20250530+cu126",
            "domain": "None",
            "model_version": "None",
            "doc_string": "None"
          },
          "main_graph": {
            "[metadata] pkg.torch.export.ExportedProgram.graph_signature": "\n# inputs\np_model_embed_tokens_weight: PARAMETER target='model.embed_tokens.weight'\np_model_layers_0_self_attn_q_proj_weight: PARAMETER target='model.layers.0.self_attn.q_proj.weight'\np_model_layers_0_self_attn_k_proj_weight: PARAMETER target='model.layers.0.self_attn.k_proj.weight'\np_model_layers_0_self_attn_v_proj_weight: PARAMETER target='model.layers.0.self_attn.v_proj.weight'\np_model_layers_0_self_attn_o_proj_weight: PARAMETER target='model.layers.0.self_attn.o_proj.weight'\np_model_layers_0_mlp_gate_proj_weight: PARAMETER target='model.layers.0.mlp.gate_proj.weight'\np_model_layers_0_mlp_up_proj_weight: PARAMETER target='model.layers.0.mlp.up_proj.weight'\np_model_layers_0_mlp_down_proj_weight: PARAMETER target='model.layers.0.mlp.down_proj.weight'\np_model_layers_0_input_layernorm_weight: PARAMETER target='model.layers.0.input_layernorm.weight'\np_model_layers_0_post_attention_layernorm_weight: PARAMETER target='model.layers.0.post_attention_layernorm.weight'\np_model_layers_1_self_attn_q_proj_weight: PARAMETER target='model.layers.1.self_attn.q_proj.weight'\np_model_layers_1_self_attn_k_proj_weight: PARAMETER target='model.layers.1.self_attn.k_proj.weight'\np_model_layers_1_self_attn_v_proj_weight: PARAMETER target='model.layers.1.self_attn.v_proj.weight'\np_model_layers_1_self_attn_o_proj_weight: PARAMETER target='model.layers.1.self_attn.o_proj.weight'\np_model_layers_1_mlp_gate_proj_weight: PARAMETER target='model.layers.1.mlp.gate_proj.weight'\np_model_layers_1_mlp_up_proj_weight: PARAMETER target='model.layers.1.mlp.up_proj.weight'\np_model_layers_1_mlp_down_proj_weight: PARAMETER target='model.layers.1.mlp.down_proj.weight'\np_model_layers_1_input_layernorm_weight: PARAMETER target='model.layers.1.input_layernorm.weight'\np_model_layers_1_post_attention_layernorm_weight: PARAMETER target='model.layers.1.post_attention_layernorm.weight'\np_model_norm_weight: PARAMETER target='model.norm.weight'\np_lm_head_weight: PARAMETER target='lm_head.weight'\nb_model_rotary_emb_inv_freq: BUFFER target='model.rotary_emb.inv_freq' persistent=False\ninput_ids: USER_INPUT\nattention_mask: USER_INPUT\nposition_ids: USER_INPUT\npast_key_values_key_cache_0: USER_INPUT\npast_key_values_key_cache_1: USER_INPUT\npast_key_values_value_cache_0: USER_INPUT\npast_key_values_value_cache_1: USER_INPUT\ninputs_embeds: USER_INPUT\nlabels: USER_INPUT\nuse_cache: USER_INPUT\noutput_attentions: USER_INPUT\noutput_hidden_states: USER_INPUT\ncache_position: USER_INPUT\nlogits_to_keep: USER_INPUT\n\n# outputs\nlinear_14: USER_OUTPUT\ncat_3: USER_OUTPUT\ncat_7: USER_OUTPUT\ncat_4: USER_OUTPUT\ncat_8: USER_OUTPUT\n",
            "[metadata] pkg.torch.export.ExportedProgram.range_constraints": "{s34: VR[1, 1024], s16: VR[8, 32768], s16 + s17: VR[10, 36864], s17: VR[1, 4096], s61: VR[2, int_oo], s75: VR[2, int_oo], s54: VR[2, int_oo]}"
          }
        },
        "collectionLabel": "model_SmolLM17b_optimized.onnx"
      },
      "level": 0
    }
  ]
}